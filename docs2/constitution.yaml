# Context Graph Constitution v6.4.0
# 13-Perspectives Collaboration | E1 Foundation | GPU-First Architecture
# ═══════════════════════════════════════════════════════════════

# GPU-FIRST ARCHITECTURE
# This is a GPU-first system. All compute-intensive operations use GPU over CPU.
# All 13 embedders are warm-loaded into GPU memory at MCP server startup.
# Target Hardware: RTX 5090 32GB (Blackwell GB202) + CUDA 13.1
#
# Key GPU Capabilities:
#   - 32GB GDDR7 VRAM: All 13 embedder models resident simultaneously
#   - 1,792 GB/s bandwidth: Sub-millisecond embedding generation
#   - 680 5th-gen Tensor Cores: FP16/BF16/FP8 inference
#   - 170 SMs with Green Contexts: Isolated inference partitions
#   - CUDA Tile: Portable, auto-optimized kernels

# ═══════════════════════════════════════════════════════════════
# CORE PHILOSOPHY: ALL EMBEDDERS ARE SIGNAL
# ═══════════════════════════════════════════════════════════════
#
# FUNDAMENTAL PRINCIPLE: Every embedder provides SIGNAL, never noise.
# Each of the 13 embedders captures a unique dimension of meaning that
# E1 (semantic) alone cannot see. No embedder output is noise - each is
# a carefully tuned lens on the knowledge graph.
#
# WHY THIS MATTERS:
# - E1 treats code as natural language → E7 treats it as structured signal
# - E1 loses causal direction → E5 preserves cause→effect as signal
# - E1 dilutes exact terms → E6 preserves keyword precision as signal
# - E1 misses entity relationships → E11 encodes "Diesel=ORM" as signal
#
# PARAMETER TUNING = SIGNAL DEFINITION:
# Each embedder's parameters are tuned to define what its signal MEANS:
#   - Blend weights: How strongly this signal influences final ranking
#   - Similarity thresholds: What constitutes meaningful signal vs. weak
#   - Boost factors: How to amplify signal in specific contexts
#   - Topic weights: How much this signal contributes to topic detection
#
# 13 embedders = 13 unique perspectives on every memory
# Each finds what OTHERS MISS. Combined = superior answers.
#
# Example: Query "What databases work with Rust?"
# - E1 finds: "database" or "Rust" semantically
# - E11 finds: "Diesel" (knows Diesel IS a database ORM - E1 missed this)
# - E7 finds: code using sqlx, diesel crates
# - Combined: Better answer than any single embedder
#
# THE SIGNAL, NOT NOISE PRINCIPLE:
# When E1 misses something that E7 or E11 finds, that's not because E1
# was wrong - it's because E7/E11 captured ADDITIONAL signal that E1
# cannot encode in its representation space. All embedders contribute
# valid signal; the question is which signal matters for this query.

# ═══════════════════════════════════════════════════════════════
# EMBEDDERS (13 Perspectives) - ALL GPU-RESIDENT
# ═══════════════════════════════════════════════════════════════
# All 13 embedders are warm-loaded into GPU VRAM at startup.
# Total VRAM footprint: ~8-12GB (leaves 20GB+ for batch processing)
# Inference precision: FP16/BF16 (Tensor Core accelerated)
# No CPU fallback - GPU is mandatory for this system.

embedders:
  # FOUNDATION (GPU: ~2GB VRAM)
  E1: { name: V_meaning, dim: 1024, finds: "Semantic similarity", misses: "Entities, code patterns, causal links", gpu: "warm-loaded" }

  # SEMANTIC ENHANCERS (topic_weight: 1.0, GPU: ~4GB total)
  E5: { name: V_causality, dim: 768, finds: "Causal chains (why X caused Y)", misses_by_E1: "Direction lost", gpu: "warm-loaded" }
  E6: { name: V_selectivity, sparse: true, finds: "Exact keyword matches", misses_by_E1: "Diluted by averaging", gpu: "warm-loaded" }
  E7: { name: V_correctness, dim: 1536, finds: "Code patterns, function signatures", misses_by_E1: "Treats code as NL", gpu: "warm-loaded" }
  E10: { name: V_multimodality, dim: 768, finds: "Same-goal work (different words)", integration: "Multiplicative boost on E1", gpu: "warm-loaded" }
  E12: { name: V_precision, per_token: true, finds: "Exact phrase matches", use: "Reranking only", gpu: "warm-loaded" }
  E13: { name: V_keyword_precision, sparse: true, finds: "Term expansions (fast→quick)", use: "Stage 1 recall", gpu: "warm-loaded" }

  # RELATIONAL ENHANCERS (topic_weight: 0.5, GPU: ~2GB total)
  E8: { name: V_connectivity, dim: 384, finds: "Graph structure (X imports Y)", gpu: "warm-loaded" }
  E11: { name: V_factuality, dim: 768, finds: "Entity knowledge (Diesel=database ORM)", model: "KEPLER (RoBERTa-base + TransE)", gpu: "warm-loaded" }

  # TEMPORAL CONTEXT (topic_weight: 0.0, POST-RETRIEVAL ONLY, GPU: ~1.5GB total)
  E2: { name: V_freshness, dim: 512, finds: "Recency", gpu: "warm-loaded" }
  E3: { name: V_periodicity, dim: 512, finds: "Time-of-day patterns", gpu: "warm-loaded" }
  E4: { name: V_ordering, dim: 512, finds: "Sequence (before/after)", gpu: "warm-loaded" }

  # STRUCTURAL (topic_weight: 0.5, GPU: ~1GB)
  E9: { name: V_robustness, dim: 1024, finds: "Noise-robust structure", gpu: "warm-loaded" }

# ═══════════════════════════════════════════════════════════════
# EMBEDDER SIGNAL DEFINITIONS (Parameter Tuning)
# ═══════════════════════════════════════════════════════════════
# Each embedder's signal has specific meaning defined by tunable parameters.
# These parameters are NOT arbitrary - they define what each signal REPRESENTS.

signal_definitions:
  # E1: SEMANTIC FOUNDATION
  E1_semantic:
    signal_meaning: "Dense semantic similarity - the foundation for all retrieval"
    role: "Foundation layer - all retrieval starts here"
    tunable_params:
      similarity_threshold: { high: 0.75, low: 0.30, description: "What constitutes meaningful semantic match" }
      matryoshka_dim: { values: [256, 512, 1024], description: "Precision vs speed tradeoff" }
    when_strong: "Query has clear semantic content that matches stored memories"
    when_weak: "Query involves code syntax, entity names, or causal relationships"

  # E5: CAUSAL SIGNAL
  E5_causal:
    signal_meaning: "Cause→effect direction - asymmetric relationships E1 loses"
    role: "Enhancer for 'why' and 'what caused' queries"
    tunable_params:
      direction_modifier: { cause_to_effect: 1.2, effect_to_cause: 0.8, description: "Asymmetric boost for causal direction" }
      similarity_threshold: { high: 0.70, low: 0.25, description: "Causal relationship strength" }
    when_strong: "Query asks 'why did X happen?' or 'what caused Y?'"
    when_weak: "Query is descriptive or definitional, no causal chain"

  # E6: KEYWORD SIGNAL
  E6_keyword:
    signal_meaning: "Exact term matches - precision E1 dilutes through averaging"
    role: "Enhancer for exact terminology, jargon, error codes"
    tunable_params:
      blend_weight: { default: 0.3, range: [0.1, 0.5], description: "How much keyword precision influences ranking" }
      jaccard_threshold: { high: 0.60, low: 0.20, description: "Minimum keyword overlap" }
    when_strong: "Query contains quoted terms, error codes, specific jargon"
    when_weak: "Query is conceptual or paraphrased"

  # E7: CODE SIGNAL
  E7_code:
    signal_meaning: "Code structure and patterns - what E1 treats as noise is signal"
    role: "Enhancer for code queries, function signatures, implementations"
    tunable_params:
      blend_weight: { default: 0.4, range: [0.2, 0.6], description: "Code signal influence on ranking" }
      similarity_threshold: { high: 0.80, low: 0.35, description: "Code pattern match strength" }
      language_detection: { auto: true, description: "Auto-detect programming language from query" }
    when_strong: "Query contains code syntax (::, ->, fn, impl, async)"
    when_weak: "Query is natural language description without code"
    benchmark_validated: "+69% improvement for signature searches, +29% for pattern searches"

  # E8: GRAPH STRUCTURE SIGNAL
  E8_graph:
    signal_meaning: "Structural relationships - imports, dependencies, connections"
    role: "Enhancer for 'what uses X?' or 'what does Y depend on?' queries"
    tunable_params:
      direction_modifier: { source_to_target: 1.2, target_to_source: 0.8, description: "Asymmetric for graph direction" }
      similarity_threshold: { high: 0.65, description: "Connection strength" }
    when_strong: "Query asks about imports, dependencies, or structural relationships"
    when_weak: "Query is about content, not structure"

  # E9: NOISE-ROBUST SIGNAL
  E9_robustness:
    signal_meaning: "Structural patterns robust to typos and variations"
    role: "Backup signal when E1 fails due to typos or misspellings"
    tunable_params:
      hamming_threshold: { high: 0.70, description: "Structure match despite noise" }
    when_strong: "Query has typos, variations, or noise"
    when_weak: "Query is clean, well-formed text"

  # E10: INTENT SIGNAL
  E10_intent:
    signal_meaning: "Goal alignment - same purpose expressed differently"
    role: "Enhancer via multiplicative boost on E1 (NOT replacement)"
    tunable_params:
      boost_strong_e1: { value: 0.05, description: "5% boost when E1 > 0.8 (refine)" }
      boost_medium_e1: { value: 0.10, description: "10% boost when E1 0.4-0.8" }
      boost_weak_e1: { value: 0.15, description: "15% boost when E1 < 0.4 (broaden)" }
      multiplier_clamp: { min: 0.8, max: 1.2, description: "Never override E1 completely" }
    when_strong: "Query describes a goal or purpose, might use different words than stored memories"
    when_weak: "Query is exact match, no intent interpretation needed"

  # E11: ENTITY KNOWLEDGE SIGNAL
  E11_entity:
    signal_meaning: "Entity relationships - 'Diesel' = database ORM for Rust"
    role: "Enhancer for named entity queries, technical terms with known relationships"
    tunable_params:
      transe_score_threshold: { valid: "> -2.0", uncertain: "-2.0 to -5.0", description: "TransE distance for relation validity" }
      jaccard_boost: { exact_match: 1.3, description: "Boost for exact entity matches" }
    when_strong: "Query contains named entities (frameworks, libraries, tools)"
    when_weak: "Query is conceptual without specific entity names"

  # E12: PRECISION SIGNAL (RERANKING ONLY)
  E12_precision:
    signal_meaning: "Token-level exact phrase matches - MaxSim reranking"
    role: "Final stage reranking ONLY (per AP-74)"
    tunable_params:
      maxsim_threshold: { high: 0.70, low: 0.30, description: "Phrase match precision" }
    when_strong: "Need to distinguish between very similar candidates"
    forbidden: "NEVER use for initial retrieval (AP-74)"

  # E13: TERM EXPANSION SIGNAL (STAGE 1 ONLY)
  E13_expansion:
    signal_meaning: "Term expansion - fast→quick, db→database"
    role: "Stage 1 recall ONLY - cast wide net (per AP-75)"
    tunable_params:
      splade_threshold: { high: 0.60, low: 0.20, description: "Term expansion match" }
      recall_candidates: { default: 10000, description: "Number of candidates for pipeline" }
    when_strong: "Need to find synonyms, abbreviations, related terms"
    forbidden: "NEVER use for final ranking (AP-75)"

  # E2-E4: TEMPORAL SIGNALS (POST-RETRIEVAL ONLY)
  E2_E3_E4_temporal:
    signal_meaning: "Temporal context - recency, periodicity, sequence"
    role: "POST-RETRIEVAL badges only (per ARCH-25, AP-73)"
    tunable_params:
      recency_boost: { under_1h: 1.3, under_1d: 1.2, under_7d: 1.1, description: "Post-retrieval recency weight" }
    when_used: "After retrieval, to add temporal context badges"
    forbidden: "NEVER in similarity fusion or initial retrieval"
    topic_weight: 0.0  # ALWAYS - temporal proximity ≠ semantic relationship

# ═══════════════════════════════════════════════════════════════
# ARCHITECTURAL RULES (MUST follow)
# ═══════════════════════════════════════════════════════════════
arch_rules:
  # GPU-First (MANDATORY)
  ARCH-GPU-01: "GPU is mandatory - no CPU fallback for embeddings"
  ARCH-GPU-02: "All 13 embedders warm-loaded into VRAM at MCP server startup"
  ARCH-GPU-03: "Embedding inference uses FP16/BF16 Tensor Cores"
  ARCH-GPU-04: "FAISS indexes use GPU (faiss-gpu) not CPU"
  ARCH-GPU-05: "HDBSCAN clustering runs on GPU via cuML"
  ARCH-GPU-06: "Batch operations preferred - minimize kernel launches"
  ARCH-GPU-07: "Green Contexts partition SMs: 70% inference, 30% indexing"
  ARCH-GPU-08: "CUDA streams for async embedding + indexing overlap"

  # Signal Philosophy (FUNDAMENTAL)
  ARCH-SIGNAL-01: "ALL 13 embedders provide SIGNAL, never noise - each captures unique dimensions of meaning"
  ARCH-SIGNAL-02: "What E1 misses is ADDITIONAL signal, not noise - E7/E11/E5 capture what E1 cannot encode"
  ARCH-SIGNAL-03: "Parameter tuning defines signal MEANING - blend weights, thresholds, boosts define each embedder's role"
  ARCH-SIGNAL-04: "Combined signal > any single embedder - multi-perspective retrieval is always superior"
  ARCH-SIGNAL-05: "Enhancers complement E1, never compete - E10 boosts E1, doesn't replace it"

  # Core
  ARCH-01: "TeleologicalArray is atomic - all 13 embeddings or nothing"
  ARCH-02: "Apples-to-apples only - compare E1↔E1, never E1↔E5"
  ARCH-04: "Temporal (E2-E4) NEVER count toward topics"
  ARCH-05: "All 13 embedders required - missing = fatal"
  ARCH-06: "All memory ops through MCP tools only"
  ARCH-09: "Topic threshold: weighted_agreement >= 2.5"
  ARCH-10: "Divergence detection: SEMANTIC embedders only (E1,E5,E6,E7,E10,E12,E13)"

  # Retrieval Pipeline
  ARCH-12: "E1 is foundation - all retrieval starts with E1"
  ARCH-13: "Strategies: E1Only (default), MultiSpace (E1+enhancers), Pipeline (E13→E1→E12)"
  ARCH-17: "Strong E1 (>0.8): enhancers refine. Weak E1 (<0.4): enhancers broaden"
  ARCH-18: "E5 Causal: asymmetric similarity (cause→effect direction matters)"
  ARCH-21: "Multi-space fusion: use Weighted RRF, not weighted sum"

  # E10 Multiplicative Boost
  ARCH-28: "E10 uses multiplicative boost: E1 * (1 + boost), NOT linear blending"
  ARCH-29: "E10 boost adapts: strong E1=5%, medium=10%, weak=15%"
  ARCH-30: "E10 alignment: >0.5=boost, <0.5=reduce, =0.5=neutral"
  ARCH-33: "E10 multiplier clamped to [0.8, 1.2]"

  # Temporal (POST-RETRIEVAL ONLY)
  ARCH-25: "Temporal boosts POST-retrieval only, NOT in similarity fusion"

# ═══════════════════════════════════════════════════════════════
# ANTI-PATTERNS (FORBIDDEN)
# ═══════════════════════════════════════════════════════════════
forbidden:
  # GPU Anti-Patterns
  AP-GPU-01: "NEVER use CPU for embedding inference when GPU available"
  AP-GPU-02: "NEVER cold-load embedders per-request - warm-load at startup"
  AP-GPU-03: "NEVER use CPU FAISS when GPU FAISS available"
  AP-GPU-04: "NEVER use sklearn HDBSCAN - use cuML GPU implementation"
  AP-GPU-05: "NEVER transfer embeddings GPU→CPU→GPU - keep on GPU"
  AP-GPU-06: "NEVER use FP32 for inference - use FP16/BF16 Tensor Cores"
  AP-GPU-07: "NEVER serialize embeddings per-item - batch for GPU efficiency"
  AP-GPU-08: "NEVER block on sync - use CUDA streams for async ops"

  # Core Anti-Patterns
  AP-02: "No cross-embedder comparison (E1↔E5)"
  AP-04: "No partial TeleologicalArray"
  AP-05: "No embedding fusion into single vector"
  AP-60: "Temporal (E2-E4) MUST NOT count toward topics"
  AP-73: "Temporal MUST NOT be used in similarity fusion"
  AP-74: "E12 ColBERT: reranking ONLY, not initial retrieval"
  AP-75: "E13 SPLADE: Stage 1 recall ONLY, not final ranking"
  AP-77: "E5 MUST NOT use symmetric cosine - causal is directional"
  AP-79: "MUST NOT use simple weighted sum - use Weighted RRF"
  AP-80: "E10 MUST NOT use linear blending - makes E10 compete with E1"
  AP-84: "E10 MUST NOT override E1 - when E1=0, result=0"

# ═══════════════════════════════════════════════════════════════
# TOPIC SYSTEM
# ═══════════════════════════════════════════════════════════════
topics:
  weighted_agreement:
    formula: "Sum(topic_weight_i × is_clustered_i)"
    threshold: 2.5
    max: 8.5  # 7×1.0 (semantic) + 2×0.5 (relational) + 1×0.5 (structural)
    temporal_contribution: 0.0  # ALWAYS

  categories:
    SEMANTIC: { embedders: [E1,E5,E6,E7,E10,E12,E13], weight: 1.0 }
    RELATIONAL: { embedders: [E8,E11], weight: 0.5 }
    STRUCTURAL: { embedders: [E9], weight: 0.5 }
    TEMPORAL: { embedders: [E2,E3,E4], weight: 0.0 }  # Never for topics

  divergence_detection: "SEMANTIC embedders only"

# ═══════════════════════════════════════════════════════════════
# MCP TOOLS
# ═══════════════════════════════════════════════════════════════
mcp_tools:
  # CORE SEARCH: Primary retrieval operations
  search: [search_graph, search_causes, search_connections, search_by_intent]

  # EMBEDDER-FIRST SEARCH: Any embedder as primary perspective (NEW)
  # Enables AI agents to explore the knowledge graph from any of the 13 perspectives
  embedder_search:
    - search_by_embedder      # Generic: search using any embedder (E1-E13) as primary
    - get_embedder_clusters   # Explore clusters in any embedder's space
    - compare_embedder_views  # Compare how different embedders see the same query
    - list_embedder_indexes   # List available embedders and their index stats

  # SPECIALIZED SEARCH: Per-embedder tools with custom logic
  semantic: [search_graph]              # E1
  causal: [search_causes, get_causal_chain]    # E5 with asymmetric similarity
  keyword: [search_by_keywords]         # E6 sparse
  code: [search_code]                   # E7 code-aware
  graph: [search_connections, get_graph_path]  # E8 structural
  entity: [search_by_entities, extract_entities, infer_relationship, find_related_entities, validate_knowledge, get_entity_graph]  # E11 KEPLER
  intent: [search_by_intent, find_contextual_matches]  # E10 multiplicative boost

  # MEMORY OPERATIONS
  memory: [store_memory, inject_context, get_memetic_status]
  sequence: [get_conversation_context, get_session_timeline, traverse_memory_chain]

  # TOPIC & CLUSTER OPERATIONS
  topic: [get_topic_portfolio, get_topic_stability, detect_topics, get_divergence_alerts]

  # MAINTENANCE
  maintenance: [trigger_consolidation, trigger_dream, merge_concepts, forget_concept, boost_importance]

  search_strategies:
    E1Only: "Fast, simple semantic queries"
    MultiSpace: "E1 + enhancers via RRF - use when E1 blind spots matter"
    Pipeline: "E13 recall → E1 dense → E12 rerank - maximum precision"
    EmbedderFirst: "Any embedder as primary perspective - explore blind spots"

# ═══════════════════════════════════════════════════════════════
# EMBEDDER-FIRST SEARCH (NEW)
# ═══════════════════════════════════════════════════════════════
# Core insight: Each embedder sees the knowledge graph from a unique perspective.
# Sometimes E1 (semantic) misses what E11 (entity) finds, or E7 (code) discovers
# patterns E5 (causal) doesn't see. Embedder-first search lets AI agents choose
# which perspective to prioritize for a given query.

embedder_first_search:
  philosophy: |
    The 13 embedders are 13 lenses on the same knowledge. By default, E1 (semantic)
    is the foundation, but sometimes another perspective reveals what E1 misses.

    Example: "What framework does Tokio relate to?"
    - E1 (semantic): finds "async", "runtime" → generic matches
    - E11 (entity): finds "Rust", "Actix" → entity relationships
    - E8 (graph): finds "imports", "depends on" → structural relationships
    - E7 (code): finds "tokio::spawn", "#[tokio::main]" → code patterns

    Embedder-first search lets the AI choose the most relevant perspective.

  tool_specs:
    search_by_embedder:
      description: "Search using any embedder (E1-E13) as the primary perspective"
      params:
        query: "Search query"
        embedder: "E1|E2|E3|E4|E5|E6|E7|E8|E9|E10|E11|E12|E13"
        topK: "1-100 (default 10)"
        minSimilarity: "0.0-1.0 (default 0.0)"
        includeContent: "boolean (default false)"
        includeAllScores: "boolean - return scores from all 13 embedders"
      use_cases:
        - "E11 search when looking for entity relationships E1 misses"
        - "E7 search when looking for code patterns"
        - "E5 search for causal relationships without asymmetric complexity"
        - "E8 search for graph structure (imports, dependencies)"

    get_embedder_clusters:
      description: "Explore clusters in a specific embedder's space"
      params:
        embedder: "E1|E2|...E13"
        minClusterSize: "default 3"
        topClusters: "default 10"
      use_cases:
        - "Find code clusters (E7) to see related implementations"
        - "Find entity clusters (E11) to see related concepts"
        - "Find temporal clusters (E2) to see recency patterns"

    compare_embedder_views:
      description: "Compare how different embedders rank the same query"
      params:
        query: "Search query"
        embedders: "[E1, E5, E7, E11]" # Subset to compare
        topK: "default 5"
      output: |
        Shows rankings from each embedder side-by-side:
        - E1 top 5: [memory1, memory2, ...]
        - E5 top 5: [memory3, memory1, ...]
        - Agreement score: how much embedders agree
        - Unique finds: memories found by only one embedder
      use_cases:
        - "Understand E1 blind spots by comparing with E11"
        - "See what causal (E5) finds that semantic (E1) misses"

    list_embedder_indexes:
      description: "List all embedder indexes with stats"
      output:
        per_embedder:
          - embedder: "E1-E13"
          - dimension: "vector dimension or 'sparse'"
          - index_type: "HNSW|Inverted|MaxSim"
          - vector_count: "number of indexed vectors"
          - index_size_mb: "approximate size"
          - gpu_resident: "true|false"

  # Per-embedder direct search (what each finds)
  embedder_perspectives:
    E1_semantic: "Dense semantic similarity - foundation"
    E2_recency: "Temporal freshness - recent memories first"
    E3_periodic: "Time-of-day patterns - daily/weekly cycles"
    E4_sequence: "Conversation order - before/after relationships"
    E5_causal: "Cause-effect relationships - why X caused Y"
    E6_keyword: "Exact keyword matches - precise terminology"
    E7_code: "Code patterns - function signatures, AST structure"
    E8_graph: "Structural relationships - imports, dependencies"
    E9_hdc: "Noise-robust structure - typos, variations"
    E10_intent: "Goal alignment - similar purpose, different words"
    E11_entity: "Entity knowledge - named entities, relationships"
    E12_precision: "Exact phrase matches - token-level precision"
    E13_expansion: "Term expansion - synonyms, related terms"

# ═══════════════════════════════════════════════════════════════
# RETRIEVAL PIPELINE
# ═══════════════════════════════════════════════════════════════
retrieval:
  stages:
    S1: "E13 SPLADE sparse recall → 10K candidates"
    S2: "E1 Matryoshka ANN → 1K candidates"
    S3: "RRF across semantic spaces → 100 candidates"
    S4: "Topic alignment (weighted_agreement >= 2.5) → 50"
    S5: "E12 MaxSim rerank → 10 final results"

  # When to use which enhancer
  use_E5: "Causal queries (why, what caused)"
  use_E7: "Code queries (implementations, functions)"
  use_E10: "Intent queries (same goal, similar purpose)"
  use_E11: "Entity queries (specific named things)"
  use_E6_E13: "Keyword queries (exact terms, jargon)"

# ═══════════════════════════════════════════════════════════════
# AUTONOMOUS MULTI-EMBEDDER ENRICHMENT
# ═══════════════════════════════════════════════════════════════
# Simplify tool calls: system auto-detects query type and selects embedders.
# Fewer calls needed, richer results per call.

autonomous_enrichment:
  philosophy: |
    Each of the 13 embedders looks at a query from its unique angle.
    E1 (semantic) is foundation but has blind spots. Other embedders find what E1 misses:
    - E5: "the bug that caused the crash" (causal relationships)
    - E7: structural code patterns (not just word similarity)
    - E10: same goal, different words (intent alignment)
    - E11: "Diesel" = database ORM (entity knowledge E1 lacks)

    Combined: Better answers than any single embedder alone.

  modes:
    Off: "E1-only search (legacy behavior)"
    Light: "E1 + 1-2 enhancers, basic agreement metrics (default)"
    Full: "All relevant embedders, full metrics, blind spot detection"

  query_type_detection:
    # System auto-detects query type from patterns
    CAUSAL: ["why", "caused", "because", "led to", "root cause"]
    CODE: ["::", "->", "fn ", "function", "impl", ".await"]
    ENTITY: ["what is", "works with", "related to", capitalized_names]
    INTENT: ["goal", "purpose", "trying to", "accomplish"]
    KEYWORD: [quoted_terms, "exact", "error:", "v2."]
    TEMPORAL: ["yesterday", "before", "after", "recently"]

  embedder_selection:
    CAUSAL: [E5, E8]       # E5 causal + E8 for causal chains
    CODE: [E7, E6]         # E7 code + E6 keywords for function names
    ENTITY: [E11, E6]      # E11 entity + E6 keywords
    INTENT: [E10, E5]      # E10 intent + E5 often overlap
    KEYWORD: [E6, E13]     # E6 sparse + E13 SPLADE expansion
    TEMPORAL: []           # E2-E4 are POST-RETRIEVAL only (ARCH-25)

  output_enrichment:
    scoring_breakdown:
      - e1_score: "E1 (semantic) similarity"
      - enhancer_scores: "Per-enhancer scores {e5: 0.8, e7: 0.6}"
      - rrf_final: "Weighted RRF fusion score (per ARCH-21)"
      - e10_boost: "E10 multiplicative boost if applied"
    agreement_metrics:
      - embedders_agree: "[E1, E5, E11]"
      - agreement_score: "0.6 (3 of 5 embedders)"
      - weighted_agreement: "2.5 (topic threshold)"
    blind_spot_alert:
      - node_id: "Memory found by enhancer but missed by E1"
      - found_by: "[E11]"
      - e1_score: "0.05 (E1 missed this)"
      - enhancer_score: "0.85 (E11 found it)"
      - explanation: "E11 knows Diesel IS a database ORM"

  arch_rules:
    ARCH-ENRICH-01: "Query type detection happens before search"
    ARCH-ENRICH-02: "E1 always runs first (per ARCH-12)"
    ARCH-ENRICH-03: "Enhancers run in parallel via tokio::join!"
    ARCH-ENRICH-04: "Fusion uses Weighted RRF (per ARCH-21)"
    ARCH-ENRICH-05: "Blind spots: enhancer > 0.5 AND E1 < 0.3"
    ARCH-ENRICH-06: "Light mode: max 2 enhancers, Full mode: max 6"

  performance_budget:
    Light: "<500ms total"
    Full: "<800ms total"
    breakdown:
      e1_search: "~100ms"
      parallel_enhancers: "~150ms (run in parallel)"
      rrf_fusion: "~50ms"
      agreement_calc: "~50ms"
      buffer: "~150ms"

# ═══════════════════════════════════════════════════════════════
# MEMORY SOURCES
# ═══════════════════════════════════════════════════════════════
memory_sources:
  HookDescription: "Claude's description of tool use"
  ClaudeResponse: "Session summaries, significant responses"
  MDFileChunk: "Markdown file chunks (200 words, 50 overlap)"

# ═══════════════════════════════════════════════════════════════
# DREAM CONSOLIDATION
# ═══════════════════════════════════════════════════════════════
dream:
  trigger: "entropy > 0.7 AND churn > 0.5"
  nrem: "Hebbian replay - strengthen high-importance edges"
  rem: "Hyperbolic random walk - discover blind spots"

# ═══════════════════════════════════════════════════════════════
# KEY THRESHOLDS
# ═══════════════════════════════════════════════════════════════
thresholds:
  topic: 2.5           # weighted_agreement for topic detection
  high_sim: 0.75       # High similarity
  low_sim: 0.30        # Divergence threshold
  duplicate: 0.90      # Duplicate detection
  entropy_dream: 0.70  # Dream trigger
  churn_dream: 0.50    # Dream trigger

# ═══════════════════════════════════════════════════════════════
# HOOKS (Native Claude Code)
# ═══════════════════════════════════════════════════════════════
hooks:
  config: ".claude/settings.json"
  SessionStart: "Load topic portfolio, warm GPU indexes"
  UserPromptSubmit: "GPU embed prompt, search, detect divergence, inject context"
  PreToolUse: "Inject brief relevant context"
  PostToolUse: "Capture + GPU embed as HookDescription"
  Stop: "Capture response summary"
  SessionEnd: "Persist state, GPU HDBSCAN, check dream triggers"

# ═══════════════════════════════════════════════════════════════
# GPU INFRASTRUCTURE (RTX 5090 32GB + CUDA 13.1)
# ═══════════════════════════════════════════════════════════════
gpu:
  hardware:
    device: "NVIDIA GeForce RTX 5090"
    architecture: "Blackwell (GB202)"
    vram: "32GB GDDR7"
    bandwidth: "1,792 GB/s"
    cuda_cores: 21760
    tensor_cores: 680
    sms: 170
    compute_capability: "12.0"
    driver: "R580+ (CUDA 13.1)"

  host:
    cpu: "AMD Ryzen 9 9950X3D"
    cores: "16 cores / 32 threads"
    ram: "128GB DDR5"
    l3_cache: "192MB (96MB x2)"

  vram_allocation:
    embedders: "~10GB (all 13 warm-loaded)"
    faiss_indexes: "~8GB (HNSW per-space)"
    batch_buffers: "~4GB (inference batches)"
    cuml_workspace: "~2GB (HDBSCAN, clustering)"
    reserved: "~8GB (headroom for spikes)"
    total_budget: "32GB"

  performance_targets:
    all_13_embed: "<200ms (GPU batch)"
    per_space_hnsw: "<1ms (faiss-gpu)"
    inject_context_p95: "<500ms"
    store_memory_p95: "<800ms"
    any_tool_p99: "<1000ms"
    topic_detection: "<20ms (cuML HDBSCAN)"
    warm_load_startup: "<30s (all 13 models)"

  cuda_features:
    green_contexts: true  # SM partitioning for QoS
    cuda_tile: true       # Portable kernel programming
    cuda_streams: true    # Async overlap
    tensor_cores: "FP16/BF16/FP8"
    mps_clients: 60       # Multi-Process Service

  testing:
    all_tests_use_gpu: true
    benchmarks_require_gpu: true
    no_cpu_fallback_tests: true
    gpu_memory_profiling: true
