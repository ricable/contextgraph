[package]
name = "context-graph-mcp"
version = "0.1.0"
edition = "2021"
authors = ["Context Graph Team"]
description = "MCP JSON-RPC server for Context Graph"
license = "MIT"
repository = "https://github.com/contextgraph/contextgraph"
keywords = ["mcp", "jsonrpc", "server", "context-graph"]

[lib]
name = "context_graph_mcp"
path = "src/lib.rs"

[[bin]]
name = "context-graph-mcp"
path = "src/main.rs"

[dependencies]
context-graph-core = { path = "../context-graph-core" }
context-graph-cuda = { path = "../context-graph-cuda" }
context-graph-embeddings = { path = "../context-graph-embeddings" }
context-graph-utl = { path = "../context-graph-utl" }

# Async runtime
tokio = { workspace = true }

# Serialization
serde = { workspace = true }
serde_json = "1.0"

# Configuration
config = { workspace = true }

# Error handling
thiserror = { workspace = true }
anyhow = "1.0"
async-trait = { workspace = true }

# Logging
tracing = { workspace = true }
tracing-subscriber = { version = "0.3", features = ["env-filter", "json"] }

# UUID
uuid = { workspace = true }

# Synchronization
parking_lot = "0.12"

# Time
chrono = { workspace = true }

# Hashing and encoding for content hashes
sha2 = "0.10"
hex = "0.4"

[dev-dependencies]
tokio-test = "0.4"
tempfile = "3.10"

[features]
# GPU-first architecture: CUDA is REQUIRED (RTX 5090 / Blackwell)
# No fallback stubs - system fails fast if CUDA unavailable
default = ["cuda"]
candle = ["context-graph-embeddings/candle"]
cuda = ["context-graph-cuda/cuda", "candle"]
# Integration tests requiring real GPU/model files
integration = []
