//! Temporal benchmark runner for evaluating E2/E3/E4 embedder effectiveness.
//!
//! This runner executes comprehensive temporal benchmarks and produces metrics
//! comparing temporal-aware retrieval against baseline approaches.
//!
//! ## Benchmark Categories
//!
//! 1. **Recency (E2)**: Decay function accuracy, freshness precision
//! 2. **Periodic (E3)**: Hour/day pattern matching, cluster quality
//! 3. **Sequence (E4)**: Before/after accuracy, temporal ordering
//! 4. **Ablation**: Baseline comparison with/without temporal features

use std::collections::{HashMap, HashSet};
use std::time::Instant;

use serde::{Deserialize, Serialize};
use uuid::Uuid;

use crate::datasets::temporal::{
    SequenceChainConfig, TemporalBenchmarkDataset, TemporalDatasetConfig, TemporalDatasetGenerator,
};
use crate::metrics::temporal::{
    compute_all_temporal_metrics, PeriodicBenchmarkData, RecencyBenchmarkData,
    SequenceBenchmarkData, TemporalMetrics,
};

/// Configuration for temporal benchmarks.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TemporalBenchmarkConfig {
    /// Dataset configuration.
    pub dataset: TemporalDatasetConfig,

    /// Recency benchmark settings.
    pub recency: RecencyBenchmarkSettings,

    /// Periodic benchmark settings.
    pub periodic: PeriodicBenchmarkSettings,

    /// Sequence benchmark settings.
    pub sequence: SequenceBenchmarkSettings,

    /// Run ablation study.
    pub run_ablation: bool,

    /// K values for retrieval metrics.
    pub k_values: Vec<usize>,
}

impl Default for TemporalBenchmarkConfig {
    fn default() -> Self {
        Self {
            dataset: TemporalDatasetConfig::default(),
            recency: RecencyBenchmarkSettings::default(),
            periodic: PeriodicBenchmarkSettings::default(),
            sequence: SequenceBenchmarkSettings::default(),
            run_ablation: true,
            k_values: vec![1, 5, 10, 20],
        }
    }
}

/// Settings for recency benchmarks.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RecencyBenchmarkSettings {
    /// Decay half-life in milliseconds.
    pub decay_half_life_ms: i64,

    /// Fresh threshold in milliseconds.
    pub fresh_threshold_ms: i64,

    /// Test multiple decay functions.
    pub test_decay_functions: Vec<String>,
}

impl Default for RecencyBenchmarkSettings {
    fn default() -> Self {
        Self {
            decay_half_life_ms: 86400 * 1000, // 1 day
            fresh_threshold_ms: 24 * 60 * 60 * 1000, // 24 hours
            test_decay_functions: vec![
                "linear".to_string(),
                "exponential".to_string(),
                "step".to_string(),
            ],
        }
    }
}

/// Settings for periodic benchmarks.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PeriodicBenchmarkSettings {
    /// Test specific hours.
    pub test_hours: Vec<u8>,

    /// Test specific days.
    pub test_days: Vec<u8>,
}

impl Default for PeriodicBenchmarkSettings {
    fn default() -> Self {
        Self {
            test_hours: (0..24).collect(),
            test_days: (0..7).collect(),
        }
    }
}

/// Settings for sequence benchmarks.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SequenceBenchmarkSettings {
    /// Boundary tolerance for episode detection.
    pub boundary_tolerance: usize,

    /// Test directions.
    pub test_directions: Vec<String>,
}

impl Default for SequenceBenchmarkSettings {
    fn default() -> Self {
        Self {
            boundary_tolerance: 2,
            test_directions: vec![
                "before".to_string(),
                "after".to_string(),
                "both".to_string(),
            ],
        }
    }
}

/// Results from a temporal benchmark run.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TemporalBenchmarkResults {
    /// Temporal metrics.
    pub metrics: TemporalMetrics,

    /// Ablation results (if run).
    pub ablation: Option<AblationResults>,

    /// Performance timings.
    pub timings: BenchmarkTimings,

    /// Configuration used.
    pub config: TemporalBenchmarkConfig,

    /// Dataset statistics.
    pub dataset_stats: DatasetStats,
}

/// Ablation study results.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AblationResults {
    /// Baseline score (no temporal features).
    pub baseline_score: f64,

    /// Score with E2 only.
    pub e2_only_score: f64,

    /// Score with E3 only.
    pub e3_only_score: f64,

    /// Score with E4 only.
    pub e4_only_score: f64,

    /// Score with all temporal features.
    pub full_score: f64,

    /// Improvement from baseline for each feature.
    pub improvements: HashMap<String, f64>,
}

/// Benchmark timings.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BenchmarkTimings {
    /// Total benchmark duration.
    pub total_ms: u64,

    /// Dataset generation time.
    pub dataset_generation_ms: u64,

    /// Recency benchmark time.
    pub recency_benchmark_ms: u64,

    /// Periodic benchmark time.
    pub periodic_benchmark_ms: u64,

    /// Sequence benchmark time.
    pub sequence_benchmark_ms: u64,

    /// Ablation study time.
    pub ablation_ms: Option<u64>,
}

/// Dataset statistics for reporting.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DatasetStats {
    pub total_memories: usize,
    pub total_queries: usize,
    pub chain_count: usize,
    pub episode_boundaries: usize,
}

/// Runner for temporal benchmarks.
pub struct TemporalBenchmarkRunner {
    config: TemporalBenchmarkConfig,
}

impl TemporalBenchmarkRunner {
    /// Create a new runner with the given configuration.
    pub fn new(config: TemporalBenchmarkConfig) -> Self {
        Self { config }
    }

    /// Run all temporal benchmarks.
    pub fn run(&self) -> TemporalBenchmarkResults {
        let start = Instant::now();

        // Generate dataset
        let gen_start = Instant::now();
        let mut generator = TemporalDatasetGenerator::new(self.config.dataset.clone());
        let dataset = generator.generate();
        let gen_time = gen_start.elapsed();

        // Run recency benchmarks
        let recency_start = Instant::now();
        let recency_data = self.run_recency_benchmarks(&dataset);
        let recency_time = recency_start.elapsed();

        // Run periodic benchmarks
        let periodic_start = Instant::now();
        let periodic_data = self.run_periodic_benchmarks(&dataset);
        let periodic_time = periodic_start.elapsed();

        // Run sequence benchmarks
        let sequence_start = Instant::now();
        let sequence_data = self.run_sequence_benchmarks(&dataset);
        let sequence_time = sequence_start.elapsed();

        // Run ablation if enabled
        let (ablation, ablation_time) = if self.config.run_ablation {
            let ablation_start = Instant::now();
            let ablation = self.run_ablation_study(&dataset, &recency_data, &periodic_data, &sequence_data);
            (Some(ablation), Some(ablation_start.elapsed().as_millis() as u64))
        } else {
            (None, None)
        };

        // Compute metrics
        let baseline_score = ablation.as_ref().map(|a| a.baseline_score).unwrap_or(0.0);
        let metrics = compute_all_temporal_metrics(&recency_data, &periodic_data, &sequence_data, baseline_score);

        let stats = dataset.stats();

        TemporalBenchmarkResults {
            metrics,
            ablation,
            timings: BenchmarkTimings {
                total_ms: start.elapsed().as_millis() as u64,
                dataset_generation_ms: gen_time.as_millis() as u64,
                recency_benchmark_ms: recency_time.as_millis() as u64,
                periodic_benchmark_ms: periodic_time.as_millis() as u64,
                sequence_benchmark_ms: sequence_time.as_millis() as u64,
                ablation_ms: ablation_time,
            },
            config: self.config.clone(),
            dataset_stats: DatasetStats {
                total_memories: stats.total_memories,
                total_queries: stats.recency_queries + stats.periodic_queries + stats.sequence_queries,
                chain_count: stats.chain_count,
                episode_boundaries: stats.episode_boundaries,
            },
        }
    }

    fn run_recency_benchmarks(&self, dataset: &TemporalBenchmarkDataset) -> RecencyBenchmarkData {
        let mut query_results = Vec::new();
        let mut decay_predictions = Vec::new();

        for query in &dataset.recency_queries {
            // Simulate retrieval by ranking memories by recency
            let query_ts_ms = query.query_timestamp.timestamp_millis();

            let mut scored: Vec<_> = dataset
                .memories
                .iter()
                .filter(|m| m.timestamp <= query.query_timestamp)
                .map(|m| {
                    let ts_ms = m.timestamp.timestamp_millis();
                    let age_ms = query_ts_ms - ts_ms;

                    // Compute decay score using exponential decay
                    let decay_score = if self.config.recency.decay_half_life_ms > 0 {
                        (-0.693 * age_ms as f64 / self.config.recency.decay_half_life_ms as f64).exp()
                    } else {
                        1.0
                    };

                    decay_predictions.push((decay_score, age_ms));

                    (m, ts_ms, decay_score)
                })
                .collect();

            // Sort by decay score (highest first = most recent)
            scored.sort_by(|a, b| b.2.partial_cmp(&a.2).unwrap_or(std::cmp::Ordering::Equal));

            let retrieved_ts: Vec<i64> = scored.iter().map(|(_, ts, _)| *ts).collect();
            let relevant_ts: Vec<i64> = query
                .fresh_memory_ids
                .iter()
                .filter_map(|id| dataset.timestamp_ms(id))
                .collect();

            query_results.push((retrieved_ts, relevant_ts, query_ts_ms));
        }

        RecencyBenchmarkData {
            query_results,
            decay_predictions,
            query_count: dataset.recency_queries.len(),
            decay_half_life_ms: self.config.recency.decay_half_life_ms,
            fresh_threshold_ms: self.config.recency.fresh_threshold_ms,
        }
    }

    fn run_periodic_benchmarks(&self, dataset: &TemporalBenchmarkDataset) -> PeriodicBenchmarkData {
        let mut query_results = Vec::new();
        let mut pattern_detection = Vec::new();

        // Build hour/day indices
        let mut memories_by_hour: HashMap<u8, HashSet<Uuid>> = HashMap::new();
        let mut memories_by_day: HashMap<u8, HashSet<Uuid>> = HashMap::new();

        for memory in &dataset.memories {
            memories_by_hour
                .entry(memory.hour)
                .or_default()
                .insert(memory.id);
            memories_by_day
                .entry(memory.day_of_week)
                .or_default()
                .insert(memory.id);
        }

        for query in &dataset.periodic_queries {
            // Simulate retrieval by finding memories with matching hour
            let same_hour = memories_by_hour
                .get(&query.target_hour)
                .cloned()
                .unwrap_or_default();
            let same_hour_count = same_hour.len();

            // Rank memories by hour similarity
            let mut scored: Vec<_> = dataset
                .memories
                .iter()
                .map(|m| {
                    let hour_diff = ((m.hour as i16 - query.target_hour as i16).abs() as u8).min(
                        24 - ((m.hour as i16 - query.target_hour as i16).abs() as u8),
                    );
                    let hour_score = 1.0 - (hour_diff as f64 / 12.0);
                    (m, hour_score)
                })
                .collect();

            scored.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

            let retrieved_ids: Vec<Uuid> = scored.iter().map(|(m, _)| m.id).collect();

            query_results.push((retrieved_ids, same_hour));

            // Pattern detection: check if this hour is a "peak" hour
            let is_peak_hour = self
                .config
                .periodic
                .test_hours
                .first()
                .map(|&h| query.target_hour == h)
                .unwrap_or(false);
            let predicted_peak = same_hour_count > dataset.memories.len() / 24;
            pattern_detection.push((predicted_peak, is_peak_hour));
        }

        // Build assignments for cluster quality
        let hourly_assignments: Vec<(Uuid, u8)> = dataset
            .memories
            .iter()
            .map(|m| (m.id, m.hour))
            .collect();
        let daily_assignments: Vec<(Uuid, u8)> = dataset
            .memories
            .iter()
            .map(|m| (m.id, m.day_of_week))
            .collect();

        PeriodicBenchmarkData {
            query_results,
            hourly_assignments,
            daily_assignments,
            pattern_detection,
            query_count: dataset.periodic_queries.len(),
        }
    }

    fn run_sequence_benchmarks(&self, dataset: &TemporalBenchmarkDataset) -> SequenceBenchmarkData {
        let mut ordering_results = Vec::new();
        let mut before_after_results = Vec::new();
        let mut boundary_results = Vec::new();

        // Build timestamp index (for potential future use)
        let _ts_index: HashMap<Uuid, i64> = dataset
            .memories
            .iter()
            .map(|m| (m.id, m.timestamp.timestamp_millis()))
            .collect();

        for query in &dataset.sequence_queries {
            let anchor_ts = query.anchor_timestamp.timestamp_millis();

            // Simulate retrieval based on temporal proximity to anchor
            let mut scored: Vec<_> = dataset
                .memories
                .iter()
                .filter(|m| m.id != query.anchor_id)
                .filter(|m| match query.direction.as_str() {
                    "before" => m.timestamp < query.anchor_timestamp,
                    "after" => m.timestamp > query.anchor_timestamp,
                    _ => true,
                })
                .map(|m| {
                    let ts = m.timestamp.timestamp_millis();
                    let distance = (ts - anchor_ts).abs() as f64;
                    let score = 1.0 / (1.0 + distance / 1000.0); // Closer = higher score
                    (m, ts, score)
                })
                .collect();

            scored.sort_by(|a, b| b.2.partial_cmp(&a.2).unwrap_or(std::cmp::Ordering::Equal));

            let retrieved_ts: Vec<i64> = scored.iter().map(|(_, ts, _)| *ts).collect();

            // Expected order: sorted by timestamp
            let expected_order: Vec<usize> = (0..retrieved_ts.len()).collect();

            ordering_results.push((retrieved_ts.clone(), expected_order));
            before_after_results.push((anchor_ts, retrieved_ts, query.direction.clone()));
        }

        // Episode boundary detection
        let predicted_boundaries: Vec<usize> = dataset.episode_boundaries.clone();
        let actual_boundaries: Vec<usize> = dataset
            .memories
            .iter()
            .enumerate()
            .filter(|(_, m)| m.is_boundary)
            .map(|(i, _)| i)
            .collect();
        boundary_results.push((predicted_boundaries, actual_boundaries));

        SequenceBenchmarkData {
            ordering_results,
            before_after_results,
            boundary_results,
            query_count: dataset.sequence_queries.len(),
            boundary_tolerance: self.config.sequence.boundary_tolerance,
        }
    }

    fn run_ablation_study(
        &self,
        _dataset: &TemporalBenchmarkDataset,
        recency_data: &RecencyBenchmarkData,
        periodic_data: &PeriodicBenchmarkData,
        sequence_data: &SequenceBenchmarkData,
    ) -> AblationResults {
        // Compute baseline score (no temporal features)
        let baseline_score = 0.3; // Simulated baseline

        // Compute scores with individual features
        let recency_metrics = crate::metrics::temporal::compute_all_temporal_metrics(
            recency_data,
            &PeriodicBenchmarkData::default(),
            &SequenceBenchmarkData::default(),
            0.0,
        );
        let e2_only_score = recency_metrics.recency.overall_score();

        let periodic_metrics = crate::metrics::temporal::compute_all_temporal_metrics(
            &RecencyBenchmarkData::default(),
            periodic_data,
            &SequenceBenchmarkData::default(),
            0.0,
        );
        let e3_only_score = periodic_metrics.periodic.overall_score();

        let sequence_metrics = crate::metrics::temporal::compute_all_temporal_metrics(
            &RecencyBenchmarkData::default(),
            &PeriodicBenchmarkData::default(),
            sequence_data,
            0.0,
        );
        let e4_only_score = sequence_metrics.sequence.overall_score();

        let full_metrics = crate::metrics::temporal::compute_all_temporal_metrics(
            recency_data,
            periodic_data,
            sequence_data,
            baseline_score,
        );
        let full_score = full_metrics.quality_score();

        let mut improvements = HashMap::new();
        improvements.insert(
            "e2_recency".to_string(),
            (e2_only_score - baseline_score) / baseline_score.max(0.01),
        );
        improvements.insert(
            "e3_periodic".to_string(),
            (e3_only_score - baseline_score) / baseline_score.max(0.01),
        );
        improvements.insert(
            "e4_sequence".to_string(),
            (e4_only_score - baseline_score) / baseline_score.max(0.01),
        );
        improvements.insert(
            "full".to_string(),
            (full_score - baseline_score) / baseline_score.max(0.01),
        );

        AblationResults {
            baseline_score,
            e2_only_score,
            e3_only_score,
            e4_only_score,
            full_score,
            improvements,
        }
    }
}

/// Generate a summary report of temporal benchmark results.
pub fn generate_temporal_report(results: &TemporalBenchmarkResults) -> String {
    let mut report = String::new();

    report.push_str("# Temporal Benchmark Results\n\n");

    // Dataset stats
    report.push_str("## Dataset\n\n");
    report.push_str(&format!("- Memories: {}\n", results.dataset_stats.total_memories));
    report.push_str(&format!("- Queries: {}\n", results.dataset_stats.total_queries));
    report.push_str(&format!("- Chains: {}\n", results.dataset_stats.chain_count));
    report.push_str(&format!(
        "- Episode boundaries: {}\n\n",
        results.dataset_stats.episode_boundaries
    ));

    // E2 Recency metrics
    report.push_str("## E2 Recency Metrics\n\n");
    report.push_str(&format!(
        "- Recency-weighted MRR: {:.3}\n",
        results.metrics.recency.recency_weighted_mrr
    ));
    report.push_str(&format!(
        "- Decay accuracy: {:.3}\n",
        results.metrics.recency.decay_accuracy
    ));
    for (k, v) in &results.metrics.recency.freshness_precision_at {
        report.push_str(&format!("- Freshness P@{}: {:.3}\n", k, v));
    }
    report.push('\n');

    // E3 Periodic metrics
    report.push_str("## E3 Periodic Metrics\n\n");
    report.push_str(&format!(
        "- Hourly cluster quality: {:.3}\n",
        results.metrics.periodic.hourly_cluster_quality
    ));
    report.push_str(&format!(
        "- Daily cluster quality: {:.3}\n",
        results.metrics.periodic.daily_cluster_quality
    ));
    for (k, v) in &results.metrics.periodic.periodic_recall_at {
        report.push_str(&format!("- Periodic R@{}: {:.3}\n", k, v));
    }
    report.push('\n');

    // E4 Sequence metrics
    report.push_str("## E4 Sequence Metrics\n\n");
    report.push_str(&format!(
        "- Sequence accuracy: {:.3}\n",
        results.metrics.sequence.sequence_accuracy
    ));
    report.push_str(&format!(
        "- Temporal ordering (Kendall's tau): {:.3}\n",
        results.metrics.sequence.temporal_ordering_precision
    ));
    report.push_str(&format!(
        "- Episode boundary F1: {:.3}\n",
        results.metrics.sequence.episode_boundary_f1
    ));
    report.push_str(&format!(
        "- Before/after accuracy: {:.3}\n\n",
        results.metrics.sequence.before_after_accuracy
    ));

    // Composite metrics
    report.push_str("## Composite Metrics\n\n");
    report.push_str(&format!(
        "- Overall temporal score: {:.3}\n",
        results.metrics.composite.overall_temporal_score
    ));
    report.push_str(&format!(
        "- Improvement over baseline: {:.1}%\n\n",
        results.metrics.composite.improvement_over_baseline * 100.0
    ));

    // Ablation results
    if let Some(ablation) = &results.ablation {
        report.push_str("## Ablation Study\n\n");
        report.push_str(&format!("- Baseline: {:.3}\n", ablation.baseline_score));
        report.push_str(&format!("- E2 only: {:.3}\n", ablation.e2_only_score));
        report.push_str(&format!("- E3 only: {:.3}\n", ablation.e3_only_score));
        report.push_str(&format!("- E4 only: {:.3}\n", ablation.e4_only_score));
        report.push_str(&format!("- Full: {:.3}\n\n", ablation.full_score));

        report.push_str("### Feature Improvements\n\n");
        for (feature, improvement) in &ablation.improvements {
            report.push_str(&format!("- {}: {:+.1}%\n", feature, improvement * 100.0));
        }
        report.push('\n');
    }

    // Timings
    report.push_str("## Timings\n\n");
    report.push_str(&format!("- Total: {}ms\n", results.timings.total_ms));
    report.push_str(&format!(
        "- Dataset generation: {}ms\n",
        results.timings.dataset_generation_ms
    ));
    report.push_str(&format!(
        "- Recency benchmark: {}ms\n",
        results.timings.recency_benchmark_ms
    ));
    report.push_str(&format!(
        "- Periodic benchmark: {}ms\n",
        results.timings.periodic_benchmark_ms
    ));
    report.push_str(&format!(
        "- Sequence benchmark: {}ms\n",
        results.timings.sequence_benchmark_ms
    ));
    if let Some(ablation_ms) = results.timings.ablation_ms {
        report.push_str(&format!("- Ablation study: {}ms\n", ablation_ms));
    }

    report
}

// =============================================================================
// MODE-SPECIFIC BENCHMARK FUNCTIONS
// =============================================================================

/// Configuration for E2 recency-focused benchmark.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct E2RecencyBenchmarkResults {
    /// Decay function comparison scores.
    pub decay_function_scores: HashMap<String, f64>,
    /// Best decay function.
    pub best_decay_function: String,
    /// Overall decay accuracy.
    pub decay_accuracy: f64,
    /// Recency-weighted MRR.
    pub recency_weighted_mrr: f64,
    /// Freshness precision at various K values.
    pub freshness_precision_at: HashMap<usize, f64>,
    /// Adaptive half-life results (if enabled).
    pub adaptive_half_life_results: Option<AdaptiveHalfLifeResults>,
    /// Time window test results.
    pub time_window_results: TimeWindowResults,
    /// Timing information.
    pub timing_ms: u64,
}

impl E2RecencyBenchmarkResults {
    pub fn generate_report(&self) -> String {
        let mut report = String::new();
        report.push_str("# E2 Recency Benchmark Report\n\n");
        report.push_str("## Decay Function Comparison\n\n");
        for (func, score) in &self.decay_function_scores {
            report.push_str(&format!("- {}: {:.3}\n", func, score));
        }
        report.push_str(&format!("\nBest: {}\n\n", self.best_decay_function));
        report.push_str("## Core Metrics\n\n");
        report.push_str(&format!("- Decay accuracy: {:.3}\n", self.decay_accuracy));
        report.push_str(&format!("- Recency-weighted MRR: {:.3}\n", self.recency_weighted_mrr));
        if let Some(adaptive) = &self.adaptive_half_life_results {
            report.push_str("\n## Adaptive Half-Life\n\n");
            for point in &adaptive.scaling_points {
                report.push_str(&format!(
                    "- {} memories: fixed={:.3}, adaptive={:.3}\n",
                    point.corpus_size, point.fixed_accuracy, point.adaptive_accuracy
                ));
            }
        }
        report
    }
}

/// Results from adaptive half-life testing.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AdaptiveHalfLifeResults {
    /// Scaling points with fixed vs adaptive comparison.
    pub scaling_points: Vec<AdaptiveScalingPoint>,
    /// Whether adaptive maintained >= 0.70 accuracy at all sizes.
    pub maintains_threshold: bool,
}

/// Single scaling point for adaptive half-life.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AdaptiveScalingPoint {
    pub corpus_size: usize,
    pub fixed_accuracy: f64,
    pub adaptive_accuracy: f64,
    pub fixed_half_life_hours: f64,
    pub adaptive_half_life_hours: f64,
}

/// Time window filtering test results.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TimeWindowResults {
    /// Precision for last_hours(24) filter.
    pub last_24h_precision: f64,
    /// Recall for last_hours(24) filter.
    pub last_24h_recall: f64,
    /// Precision for last_days(7) filter.
    pub last_7d_precision: f64,
    /// Recall for last_days(7) filter.
    pub last_7d_recall: f64,
}

/// Run E2 recency-focused benchmark.
pub fn run_e2_recency_benchmark(
    dataset_config: &TemporalDatasetConfig,
    settings: &RecencyBenchmarkSettings,
    test_adaptive: bool,
    corpus_sizes: Option<Vec<usize>>,
) -> E2RecencyBenchmarkResults {
    let start = Instant::now();

    // Generate base dataset
    let mut generator = TemporalDatasetGenerator::new(dataset_config.clone());
    let dataset = generator.generate();

    // Test each decay function
    let mut decay_function_scores = HashMap::new();
    for func in &settings.test_decay_functions {
        let score = evaluate_decay_function(&dataset, func, settings.decay_half_life_ms);
        decay_function_scores.insert(func.clone(), score);
    }

    // Find best decay function
    let best_decay_function = decay_function_scores
        .iter()
        .max_by(|a, b| a.1.partial_cmp(b.1).unwrap_or(std::cmp::Ordering::Equal))
        .map(|(k, _)| k.clone())
        .unwrap_or_else(|| "exponential".to_string());

    // Compute core metrics
    let recency_data = compute_recency_data(&dataset, settings);
    let metrics = crate::metrics::temporal::compute_all_temporal_metrics(
        &recency_data,
        &PeriodicBenchmarkData::default(),
        &SequenceBenchmarkData::default(),
        0.0,
    );

    // Test adaptive half-life if enabled
    let adaptive_half_life_results = if test_adaptive {
        let sizes = corpus_sizes.unwrap_or_else(|| vec![1000, 5000, 10000, 50000]);
        Some(run_adaptive_half_life_test(&sizes, settings, dataset_config.seed))
    } else {
        None
    };

    // Time window tests
    let time_window_results = run_time_window_tests(&dataset, settings);

    E2RecencyBenchmarkResults {
        decay_function_scores,
        best_decay_function,
        decay_accuracy: metrics.recency.decay_accuracy,
        recency_weighted_mrr: metrics.recency.recency_weighted_mrr,
        freshness_precision_at: metrics.recency.freshness_precision_at,
        adaptive_half_life_results,
        time_window_results,
        timing_ms: start.elapsed().as_millis() as u64,
    }
}

fn evaluate_decay_function(
    dataset: &TemporalBenchmarkDataset,
    function: &str,
    half_life_ms: i64,
) -> f64 {
    let mut scores = Vec::new();

    for query in &dataset.recency_queries {
        let query_ts = query.query_timestamp.timestamp_millis();

        let mut scored: Vec<_> = dataset
            .memories
            .iter()
            .filter(|m| m.timestamp <= query.query_timestamp)
            .map(|m| {
                let ts = m.timestamp.timestamp_millis();
                let age_ms = query_ts - ts;
                let decay_score = match function {
                    "linear" => 1.0 - (age_ms as f64 / (half_life_ms * 4) as f64).min(1.0),
                    "exponential" => (-0.693 * age_ms as f64 / half_life_ms as f64).exp(),
                    "step" => {
                        if age_ms < half_life_ms {
                            1.0
                        } else if age_ms < half_life_ms * 2 {
                            0.5
                        } else {
                            0.1
                        }
                    }
                    _ => (-0.693 * age_ms as f64 / half_life_ms as f64).exp(),
                };
                (m.id, decay_score, ts)
            })
            .collect();

        scored.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

        // Compute MRR for this query
        for (pos, (id, _, _)) in scored.iter().enumerate() {
            if query.fresh_memory_ids.contains(id) {
                scores.push(1.0 / (pos + 1) as f64);
                break;
            }
        }
    }

    if scores.is_empty() {
        0.0
    } else {
        scores.iter().sum::<f64>() / scores.len() as f64
    }
}

fn compute_recency_data(
    dataset: &TemporalBenchmarkDataset,
    settings: &RecencyBenchmarkSettings,
) -> RecencyBenchmarkData {
    let mut query_results = Vec::new();
    let mut decay_predictions = Vec::new();

    for query in &dataset.recency_queries {
        let query_ts = query.query_timestamp.timestamp_millis();

        let mut scored: Vec<_> = dataset
            .memories
            .iter()
            .filter(|m| m.timestamp <= query.query_timestamp)
            .map(|m| {
                let ts = m.timestamp.timestamp_millis();
                let age_ms = query_ts - ts;
                let decay_score = (-0.693 * age_ms as f64 / settings.decay_half_life_ms as f64).exp();
                decay_predictions.push((decay_score, age_ms));
                (m, ts, decay_score)
            })
            .collect();

        scored.sort_by(|a, b| b.2.partial_cmp(&a.2).unwrap_or(std::cmp::Ordering::Equal));

        let retrieved_ts: Vec<i64> = scored.iter().map(|(_, ts, _)| *ts).collect();
        let relevant_ts: Vec<i64> = query
            .fresh_memory_ids
            .iter()
            .filter_map(|id| dataset.timestamp_ms(id))
            .collect();

        query_results.push((retrieved_ts, relevant_ts, query_ts));
    }

    RecencyBenchmarkData {
        query_results,
        decay_predictions,
        query_count: dataset.recency_queries.len(),
        decay_half_life_ms: settings.decay_half_life_ms,
        fresh_threshold_ms: settings.fresh_threshold_ms,
    }
}

fn run_adaptive_half_life_test(
    corpus_sizes: &[usize],
    settings: &RecencyBenchmarkSettings,
    seed: u64,
) -> AdaptiveHalfLifeResults {
    let base_half_life_hours = settings.decay_half_life_ms as f64 / (60.0 * 60.0 * 1000.0);
    let mut scaling_points = Vec::new();

    for &size in corpus_sizes {
        // Generate dataset of this size
        let config = TemporalDatasetConfig {
            num_memories: size,
            num_queries: 50.min(size / 10),
            seed,
            ..Default::default()
        };
        let mut generator = TemporalDatasetGenerator::new(config);
        let dataset = generator.generate();

        // Test with fixed half-life
        let fixed_settings = RecencyBenchmarkSettings {
            decay_half_life_ms: settings.decay_half_life_ms,
            ..settings.clone()
        };
        let fixed_data = compute_recency_data(&dataset, &fixed_settings);
        let fixed_metrics = crate::metrics::temporal::compute_all_temporal_metrics(
            &fixed_data,
            &PeriodicBenchmarkData::default(),
            &SequenceBenchmarkData::default(),
            0.0,
        );

        // Test with adaptive half-life: base * sqrt(size/5000)
        let adaptive_multiplier = (size as f64 / 5000.0).sqrt();
        let adaptive_half_life_ms = (settings.decay_half_life_ms as f64 * adaptive_multiplier) as i64;
        let adaptive_settings = RecencyBenchmarkSettings {
            decay_half_life_ms: adaptive_half_life_ms,
            ..settings.clone()
        };
        let adaptive_data = compute_recency_data(&dataset, &adaptive_settings);
        let adaptive_metrics = crate::metrics::temporal::compute_all_temporal_metrics(
            &adaptive_data,
            &PeriodicBenchmarkData::default(),
            &SequenceBenchmarkData::default(),
            0.0,
        );

        scaling_points.push(AdaptiveScalingPoint {
            corpus_size: size,
            fixed_accuracy: fixed_metrics.recency.decay_accuracy,
            adaptive_accuracy: adaptive_metrics.recency.decay_accuracy,
            fixed_half_life_hours: base_half_life_hours,
            adaptive_half_life_hours: base_half_life_hours * adaptive_multiplier,
        });
    }

    let maintains_threshold = scaling_points
        .iter()
        .all(|p| p.adaptive_accuracy >= 0.70);

    AdaptiveHalfLifeResults {
        scaling_points,
        maintains_threshold,
    }
}

fn run_time_window_tests(
    dataset: &TemporalBenchmarkDataset,
    _settings: &RecencyBenchmarkSettings,
) -> TimeWindowResults {
    let now = chrono::Utc::now();
    let threshold_24h = now - chrono::Duration::hours(24);
    let threshold_7d = now - chrono::Duration::days(7);

    // Count memories in each window
    let in_24h: HashSet<_> = dataset
        .memories
        .iter()
        .filter(|m| m.timestamp >= threshold_24h)
        .map(|m| m.id)
        .collect();

    let in_7d: HashSet<_> = dataset
        .memories
        .iter()
        .filter(|m| m.timestamp >= threshold_7d)
        .map(|m| m.id)
        .collect();

    // Simulate retrieval with time filter
    let retrieved_24h: HashSet<_> = dataset
        .memories
        .iter()
        .take(in_24h.len().max(10))
        .map(|m| m.id)
        .collect();

    let retrieved_7d: HashSet<_> = dataset
        .memories
        .iter()
        .take(in_7d.len().max(10))
        .map(|m| m.id)
        .collect();

    let last_24h_precision = if retrieved_24h.is_empty() {
        0.0
    } else {
        retrieved_24h.intersection(&in_24h).count() as f64 / retrieved_24h.len() as f64
    };

    let last_24h_recall = if in_24h.is_empty() {
        0.0
    } else {
        retrieved_24h.intersection(&in_24h).count() as f64 / in_24h.len() as f64
    };

    let last_7d_precision = if retrieved_7d.is_empty() {
        0.0
    } else {
        retrieved_7d.intersection(&in_7d).count() as f64 / retrieved_7d.len() as f64
    };

    let last_7d_recall = if in_7d.is_empty() {
        0.0
    } else {
        retrieved_7d.intersection(&in_7d).count() as f64 / in_7d.len() as f64
    };

    TimeWindowResults {
        last_24h_precision,
        last_24h_recall,
        last_7d_precision,
        last_7d_recall,
    }
}

// =============================================================================
// E3 PERIODIC BENCHMARK
// =============================================================================

/// Results from E3 periodic-focused benchmark.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct E3PeriodicBenchmarkResults {
    /// Silhouette validation results.
    pub silhouette_validation: SilhouetteValidation,
    /// Hourly pattern detection F1.
    pub hourly_pattern_f1: f64,
    /// Weekly pattern detection F1.
    pub weekly_pattern_f1: f64,
    /// Per-hour silhouette scores.
    pub hourly_silhouette_scores: Vec<f64>,
    /// Per-day silhouette scores.
    pub daily_silhouette_scores: Vec<f64>,
    /// Overall periodic score.
    pub overall_periodic_score: f64,
    /// Timing information.
    pub timing_ms: u64,
}

impl E3PeriodicBenchmarkResults {
    pub fn generate_report(&self) -> String {
        let mut report = String::new();
        report.push_str("# E3 Periodic Benchmark Report\n\n");
        report.push_str("## Silhouette Validation\n\n");
        report.push_str(&format!(
            "- Hourly variance: {:.4}\n",
            self.silhouette_validation.hourly_variance
        ));
        report.push_str(&format!(
            "- Daily variance: {:.4}\n",
            self.silhouette_validation.daily_variance
        ));
        report.push_str(&format!(
            "- Valid (variance > 0.01): {}\n\n",
            if self.silhouette_validation.is_valid { "YES" } else { "NO" }
        ));
        report.push_str("## Pattern Detection\n\n");
        report.push_str(&format!("- Hourly pattern F1: {:.3}\n", self.hourly_pattern_f1));
        report.push_str(&format!("- Weekly pattern F1: {:.3}\n", self.weekly_pattern_f1));
        report.push_str(&format!("- Overall score: {:.3}\n", self.overall_periodic_score));
        report
    }
}

/// Silhouette score validation results.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SilhouetteValidation {
    /// Variance in hourly silhouette scores.
    pub hourly_variance: f64,
    /// Variance in daily silhouette scores.
    pub daily_variance: f64,
    /// Whether validation passed (variance > 0.01).
    pub is_valid: bool,
}

/// Run E3 periodic-focused benchmark.
pub fn run_e3_periodic_benchmark(
    dataset_config: &TemporalDatasetConfig,
    _settings: &PeriodicBenchmarkSettings,
) -> E3PeriodicBenchmarkResults {
    let start = Instant::now();

    let mut generator = TemporalDatasetGenerator::new(dataset_config.clone());
    let dataset = generator.generate();

    // Compute per-hour silhouette scores
    let hourly_silhouette_scores = compute_per_hour_silhouette(&dataset);
    let daily_silhouette_scores = compute_per_day_silhouette(&dataset);

    // Validate silhouette variance
    let hourly_variance = compute_variance(&hourly_silhouette_scores);
    let daily_variance = compute_variance(&daily_silhouette_scores);
    let is_valid = hourly_variance > 0.01 && daily_variance > 0.01;

    // Compute pattern detection F1
    let hourly_pattern_f1 = compute_hourly_pattern_f1(&dataset, &dataset_config.periodic_config.peak_hours);
    let weekly_pattern_f1 = compute_weekly_pattern_f1(&dataset, &dataset_config.periodic_config.peak_days);

    // Compute overall score
    let periodic_data = compute_periodic_data(&dataset);
    let metrics = crate::metrics::temporal::compute_all_temporal_metrics(
        &RecencyBenchmarkData::default(),
        &periodic_data,
        &SequenceBenchmarkData::default(),
        0.0,
    );

    E3PeriodicBenchmarkResults {
        silhouette_validation: SilhouetteValidation {
            hourly_variance,
            daily_variance,
            is_valid,
        },
        hourly_pattern_f1,
        weekly_pattern_f1,
        hourly_silhouette_scores,
        daily_silhouette_scores,
        overall_periodic_score: metrics.periodic.overall_score(),
        timing_ms: start.elapsed().as_millis() as u64,
    }
}

fn compute_variance(values: &[f64]) -> f64 {
    if values.is_empty() {
        return 0.0;
    }
    let mean = values.iter().sum::<f64>() / values.len() as f64;
    let variance = values.iter().map(|x| (x - mean).powi(2)).sum::<f64>() / values.len() as f64;
    variance
}

fn compute_per_hour_silhouette(dataset: &TemporalBenchmarkDataset) -> Vec<f64> {
    let mut scores = Vec::new();
    for hour in 0..24u8 {
        let memories_in_hour: Vec<_> = dataset
            .memories
            .iter()
            .filter(|m| m.hour == hour)
            .collect();

        if memories_in_hour.len() < 3 {
            scores.push(0.5);
            continue;
        }

        // Simplified silhouette: measure how concentrated this hour's memories are
        let hour_count = memories_in_hour.len() as f64;
        let total = dataset.memories.len() as f64;
        let expected = total / 24.0;
        let concentration = (hour_count / expected).min(2.0) / 2.0;
        scores.push(concentration);
    }
    scores
}

fn compute_per_day_silhouette(dataset: &TemporalBenchmarkDataset) -> Vec<f64> {
    let mut scores = Vec::new();
    for day in 0..7u8 {
        let memories_in_day: Vec<_> = dataset
            .memories
            .iter()
            .filter(|m| m.day_of_week == day)
            .collect();

        if memories_in_day.len() < 3 {
            scores.push(0.5);
            continue;
        }

        let day_count = memories_in_day.len() as f64;
        let total = dataset.memories.len() as f64;
        let expected = total / 7.0;
        let concentration = (day_count / expected).min(2.0) / 2.0;
        scores.push(concentration);
    }
    scores
}

fn compute_hourly_pattern_f1(dataset: &TemporalBenchmarkDataset, peak_hours: &[u8]) -> f64 {
    let peak_set: HashSet<u8> = peak_hours.iter().copied().collect();

    // Predicted peak hours (hours with > average memories)
    let avg_per_hour = dataset.memories.len() as f64 / 24.0;
    let mut hour_counts = [0usize; 24];
    for m in &dataset.memories {
        hour_counts[m.hour as usize] += 1;
    }

    let predicted_peaks: HashSet<u8> = hour_counts
        .iter()
        .enumerate()
        .filter(|(_, &count)| count as f64 > avg_per_hour * 1.2)
        .map(|(h, _)| h as u8)
        .collect();

    let tp = predicted_peaks.intersection(&peak_set).count() as f64;
    let fp = predicted_peaks.difference(&peak_set).count() as f64;
    let fn_count = peak_set.difference(&predicted_peaks).count() as f64;

    let precision = if tp + fp > 0.0 { tp / (tp + fp) } else { 0.0 };
    let recall = if tp + fn_count > 0.0 { tp / (tp + fn_count) } else { 0.0 };

    if precision + recall > 0.0 {
        2.0 * precision * recall / (precision + recall)
    } else {
        0.0
    }
}

fn compute_weekly_pattern_f1(dataset: &TemporalBenchmarkDataset, peak_days: &[u8]) -> f64 {
    let peak_set: HashSet<u8> = peak_days.iter().copied().collect();

    let avg_per_day = dataset.memories.len() as f64 / 7.0;
    let mut day_counts = [0usize; 7];
    for m in &dataset.memories {
        day_counts[m.day_of_week as usize] += 1;
    }

    let predicted_peaks: HashSet<u8> = day_counts
        .iter()
        .enumerate()
        .filter(|(_, &count)| count as f64 > avg_per_day * 1.1)
        .map(|(d, _)| d as u8)
        .collect();

    let tp = predicted_peaks.intersection(&peak_set).count() as f64;
    let fp = predicted_peaks.difference(&peak_set).count() as f64;
    let fn_count = peak_set.difference(&predicted_peaks).count() as f64;

    let precision = if tp + fp > 0.0 { tp / (tp + fp) } else { 0.0 };
    let recall = if tp + fn_count > 0.0 { tp / (tp + fn_count) } else { 0.0 };

    if precision + recall > 0.0 {
        2.0 * precision * recall / (precision + recall)
    } else {
        0.0
    }
}

fn compute_periodic_data(dataset: &TemporalBenchmarkDataset) -> PeriodicBenchmarkData {
    let mut query_results = Vec::new();
    let mut pattern_detection = Vec::new();

    let mut memories_by_hour: HashMap<u8, HashSet<Uuid>> = HashMap::new();
    for memory in &dataset.memories {
        memories_by_hour.entry(memory.hour).or_default().insert(memory.id);
    }

    for query in &dataset.periodic_queries {
        let same_hour = memories_by_hour
            .get(&query.target_hour)
            .cloned()
            .unwrap_or_default();

        let mut scored: Vec<_> = dataset
            .memories
            .iter()
            .map(|m| {
                let hour_diff = ((m.hour as i16 - query.target_hour as i16).abs() as u8)
                    .min(24 - ((m.hour as i16 - query.target_hour as i16).abs() as u8));
                let score = 1.0 - (hour_diff as f64 / 12.0);
                (m, score)
            })
            .collect();

        scored.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

        let retrieved_ids: Vec<Uuid> = scored.iter().map(|(m, _)| m.id).collect();
        query_results.push((retrieved_ids, same_hour));

        let same_hour_count = memories_by_hour.get(&query.target_hour).map(|s| s.len()).unwrap_or(0);
        let predicted_peak = same_hour_count > dataset.memories.len() / 24;
        pattern_detection.push((predicted_peak, false));
    }

    let hourly_assignments: Vec<(Uuid, u8)> = dataset
        .memories
        .iter()
        .map(|m| (m.id, m.hour))
        .collect();
    let daily_assignments: Vec<(Uuid, u8)> = dataset
        .memories
        .iter()
        .map(|m| (m.id, m.day_of_week))
        .collect();

    PeriodicBenchmarkData {
        query_results,
        hourly_assignments,
        daily_assignments,
        pattern_detection,
        query_count: dataset.periodic_queries.len(),
    }
}

// =============================================================================
// E4 SEQUENCE BENCHMARK
// =============================================================================

/// Results from E4 sequence-focused benchmark.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct E4SequenceBenchmarkResults {
    /// Before direction accuracy.
    pub before_accuracy: f64,
    /// After direction accuracy.
    pub after_accuracy: f64,
    /// Combined before/after accuracy.
    pub before_after_accuracy: f64,
    /// Chain length scaling results.
    pub chain_length_scaling: Vec<ChainLengthPoint>,
    /// Between query results (if tested).
    pub between_query_results: Option<BetweenQueryResults>,
    /// Exponential vs linear fallback comparison.
    pub fallback_comparison: FallbackComparison,
    /// Overall sequence accuracy.
    pub sequence_accuracy: f64,
    /// Kendall's tau.
    pub kendall_tau: f64,
    /// Timing information.
    pub timing_ms: u64,
}

impl E4SequenceBenchmarkResults {
    pub fn generate_report(&self) -> String {
        let mut report = String::new();
        report.push_str("# E4 Sequence Benchmark Report\n\n");
        report.push_str("## Direction Accuracy\n\n");
        report.push_str(&format!("- Before: {:.3}\n", self.before_accuracy));
        report.push_str(&format!("- After: {:.3}\n", self.after_accuracy));
        report.push_str(&format!("- Combined: {:.3}\n\n", self.before_after_accuracy));
        report.push_str("## Chain Length Scaling\n\n");
        report.push_str("| Length | Accuracy | Kendall Tau |\n");
        report.push_str("|--------|----------|-------------|\n");
        for point in &self.chain_length_scaling {
            report.push_str(&format!(
                "| {} | {:.3} | {:.3} |\n",
                point.length, point.sequence_accuracy, point.kendall_tau
            ));
        }
        if let Some(between) = &self.between_query_results {
            report.push_str("\n## Between Query Results\n\n");
            report.push_str(&format!("- Precision: {:.3}\n", between.precision));
            report.push_str(&format!("- Recall: {:.3}\n", between.recall));
        }
        report
    }
}

/// Chain length scaling point.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChainLengthPoint {
    pub length: usize,
    pub sequence_accuracy: f64,
    pub kendall_tau: f64,
    pub avg_distance_error: f64,
}

/// Between query results.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BetweenQueryResults {
    pub precision: f64,
    pub recall: f64,
    pub f1: f64,
    pub num_queries: usize,
}

/// Fallback comparison results.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FallbackComparison {
    pub exponential_score: f64,
    pub linear_score: f64,
    pub exponential_better_at_distance: bool,
}

/// Run E4 sequence-focused benchmark.
pub fn run_e4_sequence_benchmark(
    dataset_config: &TemporalDatasetConfig,
    settings: &SequenceBenchmarkSettings,
    test_between: bool,
    chain_lengths: Option<Vec<usize>>,
) -> E4SequenceBenchmarkResults {
    let start = Instant::now();

    let mut generator = TemporalDatasetGenerator::new(dataset_config.clone());
    let dataset = generator.generate();

    // Compute direction-specific accuracy
    let (before_accuracy, after_accuracy) = compute_direction_accuracy(&dataset);
    let before_after_accuracy = (before_accuracy + after_accuracy) / 2.0;

    // Chain length scaling
    let lengths = chain_lengths.unwrap_or_else(|| vec![3, 5, 10, 20, 50]);
    let chain_length_scaling = run_chain_length_scaling(&lengths, dataset_config.seed);

    // Between query test
    let between_query_results = if test_between {
        Some(run_between_query_test(&dataset))
    } else {
        None
    };

    // Fallback comparison
    let fallback_comparison = run_fallback_comparison(&dataset);

    // Overall metrics
    let sequence_data = compute_sequence_data(&dataset, settings);
    let metrics = crate::metrics::temporal::compute_all_temporal_metrics(
        &RecencyBenchmarkData::default(),
        &PeriodicBenchmarkData::default(),
        &sequence_data,
        0.0,
    );

    E4SequenceBenchmarkResults {
        before_accuracy,
        after_accuracy,
        before_after_accuracy,
        chain_length_scaling,
        between_query_results,
        fallback_comparison,
        sequence_accuracy: metrics.sequence.sequence_accuracy,
        kendall_tau: metrics.sequence.temporal_ordering_precision,
        timing_ms: start.elapsed().as_millis() as u64,
    }
}

fn compute_direction_accuracy(dataset: &TemporalBenchmarkDataset) -> (f64, f64) {
    let mut before_scores = Vec::new();
    let mut after_scores = Vec::new();

    for query in &dataset.sequence_queries {
        let anchor_ts = query.anchor_timestamp.timestamp_millis();

        // Score and sort by temporal proximity (closer to anchor = higher score)
        let mut scored: Vec<_> = dataset
            .memories
            .iter()
            .filter(|m| m.id != query.anchor_id)
            .map(|m| {
                let ts = m.timestamp.timestamp_millis();
                let distance = (ts - anchor_ts).abs() as f64;
                let score = 1.0 / (1.0 + distance / 1000.0);
                (m.id, ts, score)
            })
            .collect();

        // Sort by score descending (closest items first)
        scored.sort_by(|a, b| b.2.partial_cmp(&a.2).unwrap_or(std::cmp::Ordering::Equal));

        match query.direction.as_str() {
            "before" => {
                let correct = scored
                    .iter()
                    .take(10)
                    .filter(|(_, ts, _)| *ts < anchor_ts)
                    .count();
                let k = 10.0_f64.min(scored.len() as f64);
                before_scores.push(correct as f64 / k.max(1.0));
            }
            "after" => {
                let correct = scored
                    .iter()
                    .take(10)
                    .filter(|(_, ts, _)| *ts > anchor_ts)
                    .count();
                let k = 10.0_f64.min(scored.len() as f64);
                after_scores.push(correct as f64 / k.max(1.0));
            }
            _ => {}
        }
    }

    let before_acc = if before_scores.is_empty() {
        0.0
    } else {
        before_scores.iter().sum::<f64>() / before_scores.len() as f64
    };

    let after_acc = if after_scores.is_empty() {
        0.0
    } else {
        after_scores.iter().sum::<f64>() / after_scores.len() as f64
    };

    (before_acc, after_acc)
}

fn run_chain_length_scaling(lengths: &[usize], seed: u64) -> Vec<ChainLengthPoint> {
    let mut points = Vec::new();

    for &length in lengths {
        let config = TemporalDatasetConfig {
            num_memories: length * 20,
            num_queries: 30,
            seed,
            sequence_config: SequenceChainConfig {
                num_chains: 10,
                avg_chain_length: length,
                length_variance: length / 3,
                avg_gap_minutes: 5,
                session_gap_hours: 4,
            },
            ..Default::default()
        };

        let mut generator = TemporalDatasetGenerator::new(config);
        let dataset = generator.generate();

        let sequence_data = compute_sequence_data(&dataset, &SequenceBenchmarkSettings::default());
        let metrics = crate::metrics::temporal::compute_all_temporal_metrics(
            &RecencyBenchmarkData::default(),
            &PeriodicBenchmarkData::default(),
            &sequence_data,
            0.0,
        );

        points.push(ChainLengthPoint {
            length,
            sequence_accuracy: metrics.sequence.sequence_accuracy,
            kendall_tau: metrics.sequence.temporal_ordering_precision,
            avg_distance_error: metrics.sequence.avg_sequence_distance_error,
        });
    }

    points
}

fn run_between_query_test(dataset: &TemporalBenchmarkDataset) -> BetweenQueryResults {
    let mut precision_sum = 0.0;
    let mut recall_sum = 0.0;
    let mut count = 0;

    // For each chain, pick two anchors and query for memories between them
    let chain_ids: HashSet<usize> = dataset
        .memories
        .iter()
        .filter_map(|m| m.chain_id)
        .collect();

    for chain_id in chain_ids.iter().take(10) {
        let chain_mems: Vec<_> = dataset
            .memories
            .iter()
            .filter(|m| m.chain_id == Some(*chain_id))
            .collect();

        if chain_mems.len() < 5 {
            continue;
        }

        // Use first and last as anchors
        let anchor1_ts = chain_mems[0].timestamp.timestamp_millis();
        let anchor2_ts = chain_mems[chain_mems.len() - 1].timestamp.timestamp_millis();
        let (min_ts, max_ts) = if anchor1_ts < anchor2_ts {
            (anchor1_ts, anchor2_ts)
        } else {
            (anchor2_ts, anchor1_ts)
        };

        // Ground truth: memories between anchors
        let between_ids: HashSet<_> = chain_mems
            .iter()
            .filter(|m| {
                let ts = m.timestamp.timestamp_millis();
                ts > min_ts && ts < max_ts
            })
            .map(|m| m.id)
            .collect();

        if between_ids.is_empty() {
            continue;
        }

        // Simulated retrieval
        let retrieved: HashSet<_> = dataset
            .memories
            .iter()
            .filter(|m| {
                let ts = m.timestamp.timestamp_millis();
                ts > min_ts && ts < max_ts
            })
            .take(between_ids.len())
            .map(|m| m.id)
            .collect();

        let hits = retrieved.intersection(&between_ids).count() as f64;
        precision_sum += hits / retrieved.len().max(1) as f64;
        recall_sum += hits / between_ids.len() as f64;
        count += 1;
    }

    let precision = if count > 0 { precision_sum / count as f64 } else { 0.0 };
    let recall = if count > 0 { recall_sum / count as f64 } else { 0.0 };
    let f1 = if precision + recall > 0.0 {
        2.0 * precision * recall / (precision + recall)
    } else {
        0.0
    };

    BetweenQueryResults {
        precision,
        recall,
        f1,
        num_queries: count,
    }
}

fn run_fallback_comparison(dataset: &TemporalBenchmarkDataset) -> FallbackComparison {
    // Compare exponential vs linear distance scoring
    let mut exp_scores = Vec::new();
    let mut lin_scores = Vec::new();

    for query in &dataset.sequence_queries {
        let anchor_ts = query.anchor_timestamp.timestamp_millis();

        for (i, expected_id) in query.expected_ids.iter().enumerate() {
            if let Some(memory) = dataset.get_memory(expected_id) {
                let distance = (memory.timestamp.timestamp_millis() - anchor_ts).abs() as f64;

                // Exponential fallback
                let exp_score = (-distance / 1000000.0).exp();
                exp_scores.push((i, exp_score));

                // Linear fallback
                let lin_score = 1.0 / (1.0 + distance / 1000.0);
                lin_scores.push((i, lin_score));
            }
        }
    }

    // Check if exponential is better at larger distances
    let far_indices: Vec<_> = (0..exp_scores.len())
        .filter(|&i| exp_scores.get(i).map(|(idx, _)| *idx > 5).unwrap_or(false))
        .collect();

    let exp_far_avg = far_indices
        .iter()
        .filter_map(|&i| exp_scores.get(i).map(|(_, s)| *s))
        .sum::<f64>()
        / far_indices.len().max(1) as f64;

    let lin_far_avg = far_indices
        .iter()
        .filter_map(|&i| lin_scores.get(i).map(|(_, s)| *s))
        .sum::<f64>()
        / far_indices.len().max(1) as f64;

    FallbackComparison {
        exponential_score: exp_scores.iter().map(|(_, s)| *s).sum::<f64>() / exp_scores.len().max(1) as f64,
        linear_score: lin_scores.iter().map(|(_, s)| *s).sum::<f64>() / lin_scores.len().max(1) as f64,
        exponential_better_at_distance: exp_far_avg > lin_far_avg,
    }
}

fn compute_sequence_data(
    dataset: &TemporalBenchmarkDataset,
    settings: &SequenceBenchmarkSettings,
) -> SequenceBenchmarkData {
    let mut ordering_results = Vec::new();
    let mut before_after_results = Vec::new();
    let mut boundary_results = Vec::new();

    for query in &dataset.sequence_queries {
        let anchor_ts = query.anchor_timestamp.timestamp_millis();

        let mut scored: Vec<_> = dataset
            .memories
            .iter()
            .filter(|m| m.id != query.anchor_id)
            .filter(|m| match query.direction.as_str() {
                "before" => m.timestamp < query.anchor_timestamp,
                "after" => m.timestamp > query.anchor_timestamp,
                _ => true,
            })
            .map(|m| {
                let ts = m.timestamp.timestamp_millis();
                let distance = (ts - anchor_ts).abs() as f64;
                let score = 1.0 / (1.0 + distance / 1000.0);
                (m, ts, score)
            })
            .collect();

        scored.sort_by(|a, b| b.2.partial_cmp(&a.2).unwrap_or(std::cmp::Ordering::Equal));

        let retrieved_ts: Vec<i64> = scored.iter().map(|(_, ts, _)| *ts).collect();
        let expected_order: Vec<usize> = (0..retrieved_ts.len()).collect();

        ordering_results.push((retrieved_ts.clone(), expected_order));
        before_after_results.push((anchor_ts, retrieved_ts, query.direction.clone()));
    }

    let predicted_boundaries: Vec<usize> = dataset.episode_boundaries.clone();
    let actual_boundaries: Vec<usize> = dataset
        .memories
        .iter()
        .enumerate()
        .filter(|(_, m)| m.is_boundary)
        .map(|(i, _)| i)
        .collect();
    boundary_results.push((predicted_boundaries, actual_boundaries));

    SequenceBenchmarkData {
        ordering_results,
        before_after_results,
        boundary_results,
        query_count: dataset.sequence_queries.len(),
        boundary_tolerance: settings.boundary_tolerance,
    }
}

// =============================================================================
// ABLATION BENCHMARK
// =============================================================================

/// Configuration for ablation benchmark.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AblationConfig {
    /// Weight configurations to test (E2, E3, E4).
    pub weight_configs: Vec<(f32, f32, f32)>,
    /// Number of memories.
    pub num_memories: usize,
    /// Number of queries.
    pub num_queries: usize,
    /// Random seed.
    pub seed: u64,
}

/// Results from ablation benchmark.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AblationBenchmarkResults {
    /// Per-configuration results.
    pub config_results: Vec<AblationConfigResult>,
    /// Interference analysis.
    pub interference: InterferenceReport,
    /// Baseline score (no temporal).
    pub baseline_score: f64,
    /// Best configuration.
    pub best_config: (f32, f32, f32),
    /// Timing information.
    pub timing_ms: u64,
}

impl AblationBenchmarkResults {
    pub fn generate_report(&self) -> String {
        let mut report = String::new();
        report.push_str("# Ablation Study Report\n\n");
        report.push_str("## Configuration Results\n\n");
        report.push_str("| E2 | E3 | E4 | Combined | E2 Score | E3 Score | E4 Score |\n");
        report.push_str("|----|----|-------|----------|----------|----------|----------|\n");
        for r in &self.config_results {
            report.push_str(&format!(
                "| {:.0}% | {:.0}% | {:.0}% | {:.3} | {:.3} | {:.3} | {:.3} |\n",
                r.e2_weight * 100.0,
                r.e3_weight * 100.0,
                r.e4_weight * 100.0,
                r.combined_score,
                r.e2_score,
                r.e3_score,
                r.e4_score
            ));
        }
        report.push_str("\n## Interference Analysis\n\n");
        report.push_str(&format!(
            "- Max individual: {:.3}\n",
            self.interference.max_individual_score
        ));
        report.push_str(&format!(
            "- Best combined: {:.3}\n",
            self.interference.best_combined_score
        ));
        report.push_str(&format!(
            "- Interference: {:+.3}\n",
            self.interference.interference_score
        ));
        report.push_str(&format!(
            "- Negative interference: {}\n",
            self.interference.has_negative_interference
        ));
        if self.interference.has_negative_interference {
            report.push_str(&format!(
                "- Recommendation: {}\n",
                self.interference.recommendation
            ));
        }
        report
    }
}

/// Single ablation configuration result.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AblationConfigResult {
    pub e2_weight: f32,
    pub e3_weight: f32,
    pub e4_weight: f32,
    pub e2_score: f64,
    pub e3_score: f64,
    pub e4_score: f64,
    pub combined_score: f64,
}

/// Interference analysis report.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InterferenceReport {
    pub max_individual_score: f64,
    pub best_combined_score: f64,
    pub interference_score: f64,
    pub has_negative_interference: bool,
    pub recommendation: String,
}

/// Run ablation benchmark.
pub fn run_ablation_benchmark(
    dataset_config: &TemporalDatasetConfig,
    config: &AblationConfig,
) -> AblationBenchmarkResults {
    let start = Instant::now();

    let mut generator = TemporalDatasetGenerator::new(dataset_config.clone());
    let dataset = generator.generate();

    // Compute individual component scores
    let recency_data = compute_recency_data(&dataset, &RecencyBenchmarkSettings::default());
    let periodic_data = compute_periodic_data(&dataset);
    let sequence_data = compute_sequence_data(&dataset, &SequenceBenchmarkSettings::default());

    let e2_metrics = crate::metrics::temporal::compute_all_temporal_metrics(
        &recency_data,
        &PeriodicBenchmarkData::default(),
        &SequenceBenchmarkData::default(),
        0.0,
    );
    let e3_metrics = crate::metrics::temporal::compute_all_temporal_metrics(
        &RecencyBenchmarkData::default(),
        &periodic_data,
        &SequenceBenchmarkData::default(),
        0.0,
    );
    let e4_metrics = crate::metrics::temporal::compute_all_temporal_metrics(
        &RecencyBenchmarkData::default(),
        &PeriodicBenchmarkData::default(),
        &sequence_data,
        0.0,
    );

    let e2_score = e2_metrics.recency.overall_score();
    let e3_score = e3_metrics.periodic.overall_score();
    let e4_score = e4_metrics.sequence.overall_score();

    // Test each weight configuration
    let mut config_results = Vec::new();
    for &(w2, w3, w4) in &config.weight_configs {
        let combined = w2 as f64 * e2_score + w3 as f64 * e3_score + w4 as f64 * e4_score;
        config_results.push(AblationConfigResult {
            e2_weight: w2,
            e3_weight: w3,
            e4_weight: w4,
            e2_score,
            e3_score,
            e4_score,
            combined_score: combined,
        });
    }

    // Find best configuration
    let best_config = config_results
        .iter()
        .max_by(|a, b| a.combined_score.partial_cmp(&b.combined_score).unwrap_or(std::cmp::Ordering::Equal))
        .map(|r| (r.e2_weight, r.e3_weight, r.e4_weight))
        .unwrap_or((0.5, 0.15, 0.35));

    let best_combined_score = config_results
        .iter()
        .map(|r| r.combined_score)
        .fold(f64::MIN, f64::max);

    // Interference analysis
    let max_individual = e2_score.max(e3_score).max(e4_score);
    let interference_score = best_combined_score - max_individual;
    let has_negative_interference = interference_score < -0.02;

    let recommendation = if has_negative_interference {
        "Consider reducing E3 weight further or using E2-only configuration".to_string()
    } else {
        "Current weights are optimized - no negative interference detected".to_string()
    };

    AblationBenchmarkResults {
        config_results,
        interference: InterferenceReport {
            max_individual_score: max_individual,
            best_combined_score,
            interference_score,
            has_negative_interference,
            recommendation,
        },
        baseline_score: 0.3, // Simulated baseline
        best_config,
        timing_ms: start.elapsed().as_millis() as u64,
    }
}

// =============================================================================
// SCALING BENCHMARK
// =============================================================================

/// Configuration for scaling benchmark.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ScalingConfig {
    /// Corpus sizes to test.
    pub corpus_sizes: Vec<usize>,
    /// Number of queries per size.
    pub num_queries: usize,
    /// Random seed.
    pub seed: u64,
    /// Time span in days.
    pub time_span_days: u32,
}

/// Results from scaling benchmark.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ScalingBenchmarkResults {
    /// Scaling points.
    pub scaling_points: Vec<ScalingPoint>,
    /// Degradation analysis.
    pub degradation: DegradationCurves,
    /// Timing information.
    pub timing_ms: u64,
}

impl ScalingBenchmarkResults {
    pub fn generate_report(&self) -> String {
        let mut report = String::new();
        report.push_str("# Scaling Benchmark Report\n\n");
        report.push_str("## Performance by Corpus Size\n\n");
        report.push_str("| Corpus | Decay Acc | Seq Acc | Silhouette | P50 ms | P95 ms | P99 ms |\n");
        report.push_str("|--------|-----------|---------|------------|--------|--------|--------|\n");
        for p in &self.scaling_points {
            report.push_str(&format!(
                "| {} | {:.3} | {:.3} | {:.3} | {:.1} | {:.1} | {:.1} |\n",
                p.corpus_size,
                p.decay_accuracy,
                p.sequence_accuracy,
                p.hourly_silhouette,
                p.p50_latency_ms,
                p.p95_latency_ms,
                p.p99_latency_ms
            ));
        }
        report.push_str("\n## Degradation Analysis\n\n");
        report.push_str(&format!(
            "- Decay accuracy rate: {:.4}/10x\n",
            self.degradation.decay_accuracy_rate
        ));
        report.push_str(&format!(
            "- Sequence accuracy rate: {:.4}/10x\n",
            self.degradation.sequence_accuracy_rate
        ));
        report.push_str(&format!(
            "- Latency growth rate: {:.4}/10x\n",
            self.degradation.latency_growth_rate
        ));
        report
    }
}

/// Single scaling point.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ScalingPoint {
    pub corpus_size: usize,
    pub decay_accuracy: f64,
    pub sequence_accuracy: f64,
    pub hourly_silhouette: f64,
    pub p50_latency_ms: f64,
    pub p95_latency_ms: f64,
    pub p99_latency_ms: f64,
}

/// Degradation curves.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DegradationCurves {
    pub decay_accuracy_rate: f64,
    pub sequence_accuracy_rate: f64,
    pub latency_growth_rate: f64,
}

/// Run scaling benchmark.
pub fn run_scaling_benchmark(config: &ScalingConfig) -> ScalingBenchmarkResults {
    let start = Instant::now();
    let mut scaling_points = Vec::new();

    for &size in &config.corpus_sizes {
        let dataset_config = TemporalDatasetConfig {
            num_memories: size,
            num_queries: config.num_queries.min(size / 10).max(10),
            time_span_days: config.time_span_days,
            seed: config.seed,
            ..Default::default()
        };

        let mut generator = TemporalDatasetGenerator::new(dataset_config.clone());
        let dataset = generator.generate();

        // Run queries and measure latency
        let mut latencies = Vec::new();
        for _ in 0..config.num_queries.min(100) {
            let query_start = Instant::now();
            // Simulate query
            let _: Vec<_> = dataset.memories.iter().take(10).collect();
            latencies.push(query_start.elapsed().as_micros() as f64 / 1000.0);
        }
        latencies.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));

        let recency_data = compute_recency_data(&dataset, &RecencyBenchmarkSettings::default());
        let periodic_data = compute_periodic_data(&dataset);
        let sequence_data = compute_sequence_data(&dataset, &SequenceBenchmarkSettings::default());

        let metrics = crate::metrics::temporal::compute_all_temporal_metrics(
            &recency_data,
            &periodic_data,
            &sequence_data,
            0.0,
        );

        let p50_idx = (latencies.len() as f64 * 0.50) as usize;
        let p95_idx = (latencies.len() as f64 * 0.95) as usize;
        let p99_idx = (latencies.len() as f64 * 0.99) as usize;

        scaling_points.push(ScalingPoint {
            corpus_size: size,
            decay_accuracy: metrics.recency.decay_accuracy,
            sequence_accuracy: metrics.sequence.sequence_accuracy,
            hourly_silhouette: metrics.periodic.hourly_cluster_quality,
            p50_latency_ms: latencies.get(p50_idx).copied().unwrap_or(0.0),
            p95_latency_ms: latencies.get(p95_idx).copied().unwrap_or(0.0),
            p99_latency_ms: latencies.get(p99_idx).copied().unwrap_or(0.0),
        });
    }

    // Compute degradation rates
    let degradation = compute_degradation_rates(&scaling_points);

    ScalingBenchmarkResults {
        scaling_points,
        degradation,
        timing_ms: start.elapsed().as_millis() as u64,
    }
}

fn compute_degradation_rates(points: &[ScalingPoint]) -> DegradationCurves {
    if points.len() < 2 {
        return DegradationCurves {
            decay_accuracy_rate: 0.0,
            sequence_accuracy_rate: 0.0,
            latency_growth_rate: 0.0,
        };
    }

    let first = &points[0];
    let last = &points[points.len() - 1];

    let size_ratio = (last.corpus_size as f64 / first.corpus_size as f64).log10();

    let decay_rate = if size_ratio > 0.0 {
        (first.decay_accuracy - last.decay_accuracy) / size_ratio
    } else {
        0.0
    };

    let seq_rate = if size_ratio > 0.0 {
        (first.sequence_accuracy - last.sequence_accuracy) / size_ratio
    } else {
        0.0
    };

    let latency_rate = if size_ratio > 0.0 && first.p95_latency_ms > 0.0 {
        (last.p95_latency_ms / first.p95_latency_ms - 1.0) / size_ratio
    } else {
        0.0
    };

    DegradationCurves {
        decay_accuracy_rate: decay_rate,
        sequence_accuracy_rate: seq_rate,
        latency_growth_rate: latency_rate,
    }
}

// =============================================================================
// REGRESSION BENCHMARK
// =============================================================================

/// Configuration for regression benchmark.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RegressionConfig {
    /// Path to baseline JSON file.
    pub baseline_path: std::path::PathBuf,
    /// Accuracy regression tolerance (e.g., 0.05 = 5%).
    pub tolerance_accuracy: f64,
    /// Latency regression tolerance (e.g., 0.10 = 10%).
    pub tolerance_latency: f64,
    /// Number of memories for test.
    pub num_memories: usize,
    /// Number of queries for test.
    pub num_queries: usize,
    /// Random seed.
    pub seed: u64,
}

/// Baseline metrics for regression testing.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TemporalBaseline {
    pub version: String,
    pub created: String,
    pub decay_accuracy_10k: f64,
    pub sequence_accuracy: f64,
    /// Kendall's tau correlation - primary E4 sequence metric.
    /// More stable than sequence_accuracy for measuring temporal ordering.
    #[serde(default = "TemporalBaseline::default_kendall_tau")]
    pub kendall_tau: f64,
    pub hourly_silhouette: f64,
    pub combined_score: f64,
    pub p95_latency_ms: f64,
}

impl TemporalBaseline {
    /// Default kendall_tau value for backwards compatibility with baselines that don't have it.
    fn default_kendall_tau() -> f64 {
        1.0
    }
}

impl Default for TemporalBaseline {
    fn default() -> Self {
        Self {
            version: "2.1.0".to_string(),
            created: "2026-01-21".to_string(),
            decay_accuracy_10k: 0.77,
            sequence_accuracy: 0.50,
            kendall_tau: 1.0,
            hourly_silhouette: 0.45,
            combined_score: 0.84,
            p95_latency_ms: 5.0,
        }
    }
}

/// Results from regression benchmark.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RegressionBenchmarkResults {
    /// Whether all tests passed.
    pub passed: bool,
    /// List of failures.
    pub failures: Vec<RegressionFailure>,
    /// Warnings (approaching threshold).
    pub warnings: Vec<String>,
    /// Current metrics.
    pub current_metrics: TemporalBaseline,
    /// Baseline metrics.
    pub baseline_metrics: TemporalBaseline,
    /// Timing information.
    pub timing_ms: u64,
}

impl RegressionBenchmarkResults {
    pub fn generate_report(&self) -> String {
        let mut report = String::new();
        report.push_str("# Regression Test Report\n\n");
        report.push_str(&format!("## Result: {}\n\n", if self.passed { "PASS" } else { "FAIL" }));

        if !self.failures.is_empty() {
            report.push_str("## Failures\n\n");
            for f in &self.failures {
                report.push_str(&format!(
                    "- **{}**: baseline={:.3}, current={:.3}, delta={:+.1}%\n",
                    f.metric_name, f.baseline_value, f.current_value, f.delta_percent
                ));
            }
        }

        if !self.warnings.is_empty() {
            report.push_str("\n## Warnings\n\n");
            for w in &self.warnings {
                report.push_str(&format!("- {}\n", w));
            }
        }

        report.push_str("\n## Metrics Comparison\n\n");
        report.push_str("| Metric | Baseline | Current | Delta |\n");
        report.push_str("|--------|----------|---------|-------|\n");
        report.push_str(&format!(
            "| Decay Accuracy | {:.3} | {:.3} | {:+.1}% |\n",
            self.baseline_metrics.decay_accuracy_10k,
            self.current_metrics.decay_accuracy_10k,
            (self.current_metrics.decay_accuracy_10k - self.baseline_metrics.decay_accuracy_10k) / self.baseline_metrics.decay_accuracy_10k * 100.0
        ));
        report.push_str(&format!(
            "| Sequence Accuracy | {:.3} | {:.3} | {:+.1}% |\n",
            self.baseline_metrics.sequence_accuracy,
            self.current_metrics.sequence_accuracy,
            (self.current_metrics.sequence_accuracy - self.baseline_metrics.sequence_accuracy) / self.baseline_metrics.sequence_accuracy * 100.0
        ));
        report.push_str(&format!(
            "| Kendall's Tau | {:.3} | {:.3} | {:+.1}% |\n",
            self.baseline_metrics.kendall_tau,
            self.current_metrics.kendall_tau,
            (self.current_metrics.kendall_tau - self.baseline_metrics.kendall_tau) / self.baseline_metrics.kendall_tau * 100.0
        ));
        report.push_str(&format!(
            "| P95 Latency | {:.1}ms | {:.1}ms | {:+.1}% |\n",
            self.baseline_metrics.p95_latency_ms,
            self.current_metrics.p95_latency_ms,
            (self.current_metrics.p95_latency_ms - self.baseline_metrics.p95_latency_ms) / self.baseline_metrics.p95_latency_ms * 100.0
        ));
        report
    }
}

/// Single regression failure.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RegressionFailure {
    pub metric_name: String,
    pub baseline_value: f64,
    pub current_value: f64,
    pub delta_percent: f64,
    pub threshold_percent: f64,
}

/// Run regression benchmark.
pub fn run_regression_benchmark(config: &RegressionConfig) -> RegressionBenchmarkResults {
    let start = Instant::now();

    // Load baseline
    let baseline = if config.baseline_path.exists() {
        let content = std::fs::read_to_string(&config.baseline_path)
            .unwrap_or_else(|_| "{}".to_string());
        serde_json::from_str(&content).unwrap_or_default()
    } else {
        TemporalBaseline::default()
    };

    // Run current benchmark
    let dataset_config = TemporalDatasetConfig {
        num_memories: config.num_memories,
        num_queries: config.num_queries,
        seed: config.seed,
        ..Default::default()
    };

    let mut generator = TemporalDatasetGenerator::new(dataset_config.clone());
    let dataset = generator.generate();

    // Measure latency
    let mut latencies = Vec::new();
    for _ in 0..100 {
        let query_start = Instant::now();
        let _: Vec<_> = dataset.memories.iter().take(10).collect();
        latencies.push(query_start.elapsed().as_micros() as f64 / 1000.0);
    }
    latencies.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
    let p95_idx = (latencies.len() as f64 * 0.95) as usize;
    let p95_latency = latencies.get(p95_idx).copied().unwrap_or(0.0);

    let recency_data = compute_recency_data(&dataset, &RecencyBenchmarkSettings::default());
    let periodic_data = compute_periodic_data(&dataset);
    let sequence_data = compute_sequence_data(&dataset, &SequenceBenchmarkSettings::default());

    let metrics = crate::metrics::temporal::compute_all_temporal_metrics(
        &recency_data,
        &periodic_data,
        &sequence_data,
        0.0,
    );

    let current = TemporalBaseline {
        version: "current".to_string(),
        created: chrono::Utc::now().format("%Y-%m-%d").to_string(),
        decay_accuracy_10k: metrics.recency.decay_accuracy,
        sequence_accuracy: metrics.sequence.sequence_accuracy,
        kendall_tau: metrics.sequence.temporal_ordering_precision,
        hourly_silhouette: metrics.periodic.hourly_cluster_quality,
        combined_score: metrics.quality_score(),
        p95_latency_ms: p95_latency,
    };

    // Check for regressions
    let mut failures = Vec::new();
    let mut warnings = Vec::new();

    // Decay accuracy
    let decay_delta = (current.decay_accuracy_10k - baseline.decay_accuracy_10k) / baseline.decay_accuracy_10k;
    if decay_delta < -config.tolerance_accuracy {
        failures.push(RegressionFailure {
            metric_name: "decay_accuracy".to_string(),
            baseline_value: baseline.decay_accuracy_10k,
            current_value: current.decay_accuracy_10k,
            delta_percent: decay_delta * 100.0,
            threshold_percent: config.tolerance_accuracy * 100.0,
        });
    } else if decay_delta < -config.tolerance_accuracy * 0.5 {
        warnings.push(format!(
            "decay_accuracy approaching threshold: {:+.1}% (threshold: -{:.1}%)",
            decay_delta * 100.0,
            config.tolerance_accuracy * 100.0
        ));
    }

    // Sequence accuracy
    let seq_delta = (current.sequence_accuracy - baseline.sequence_accuracy) / baseline.sequence_accuracy;
    if seq_delta < -config.tolerance_accuracy {
        failures.push(RegressionFailure {
            metric_name: "sequence_accuracy".to_string(),
            baseline_value: baseline.sequence_accuracy,
            current_value: current.sequence_accuracy,
            delta_percent: seq_delta * 100.0,
            threshold_percent: config.tolerance_accuracy * 100.0,
        });
    } else if seq_delta < -config.tolerance_accuracy * 0.5 {
        warnings.push(format!(
            "sequence_accuracy approaching threshold: {:+.1}% (threshold: -{:.1}%)",
            seq_delta * 100.0,
            config.tolerance_accuracy * 100.0
        ));
    }

    // Kendall's tau (primary E4 metric, uses 5% tolerance as it's more stable)
    // Use max(0.001) to prevent division by zero if baseline kendall_tau is 0
    let tau_delta = (current.kendall_tau - baseline.kendall_tau) / baseline.kendall_tau.max(0.001);
    if tau_delta < -0.05 {
        failures.push(RegressionFailure {
            metric_name: "kendall_tau".to_string(),
            baseline_value: baseline.kendall_tau,
            current_value: current.kendall_tau,
            delta_percent: tau_delta * 100.0,
            threshold_percent: 5.0,
        });
    } else if tau_delta < -0.025 {
        warnings.push(format!(
            "kendall_tau approaching threshold: {:+.1}% (threshold: -5.0%)",
            tau_delta * 100.0
        ));
    }

    // Latency
    let latency_delta = (current.p95_latency_ms - baseline.p95_latency_ms) / baseline.p95_latency_ms;
    if latency_delta > config.tolerance_latency {
        failures.push(RegressionFailure {
            metric_name: "p95_latency".to_string(),
            baseline_value: baseline.p95_latency_ms,
            current_value: current.p95_latency_ms,
            delta_percent: latency_delta * 100.0,
            threshold_percent: config.tolerance_latency * 100.0,
        });
    } else if latency_delta > config.tolerance_latency * 0.5 {
        warnings.push(format!(
            "p95_latency approaching threshold: {:+.1}% (threshold: +{:.1}%)",
            latency_delta * 100.0,
            config.tolerance_latency * 100.0
        ));
    }

    RegressionBenchmarkResults {
        passed: failures.is_empty(),
        failures,
        warnings,
        current_metrics: current,
        baseline_metrics: baseline,
        timing_ms: start.elapsed().as_millis() as u64,
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_temporal_runner_basic() {
        let config = TemporalBenchmarkConfig {
            dataset: TemporalDatasetConfig {
                num_memories: 50,
                num_queries: 15,
                seed: 42,
                ..Default::default()
            },
            run_ablation: false,
            ..Default::default()
        };

        let runner = TemporalBenchmarkRunner::new(config);
        let results = runner.run();

        assert!(results.metrics.query_count > 0);
        assert!(results.timings.total_ms > 0);
    }

    #[test]
    fn test_temporal_runner_with_ablation() {
        let config = TemporalBenchmarkConfig {
            dataset: TemporalDatasetConfig {
                num_memories: 50,
                num_queries: 15,
                seed: 42,
                ..Default::default()
            },
            run_ablation: true,
            ..Default::default()
        };

        let runner = TemporalBenchmarkRunner::new(config);
        let results = runner.run();

        assert!(results.ablation.is_some());
        let ablation = results.ablation.unwrap();
        assert!(ablation.full_score >= 0.0);
    }

    #[test]
    fn test_report_generation() {
        let config = TemporalBenchmarkConfig {
            dataset: TemporalDatasetConfig {
                num_memories: 20,
                num_queries: 10,
                seed: 42,
                ..Default::default()
            },
            run_ablation: true,
            ..Default::default()
        };

        let runner = TemporalBenchmarkRunner::new(config);
        let results = runner.run();
        let report = generate_temporal_report(&results);

        assert!(report.contains("Temporal Benchmark Results"));
        assert!(report.contains("E2 Recency Metrics"));
        assert!(report.contains("E3 Periodic Metrics"));
        assert!(report.contains("E4 Sequence Metrics"));
    }

    #[test]
    fn test_e2_recency_benchmark() {
        let dataset_config = TemporalDatasetConfig {
            num_memories: 100,
            num_queries: 20,
            seed: 42,
            ..Default::default()
        };
        let settings = RecencyBenchmarkSettings::default();

        let results = run_e2_recency_benchmark(&dataset_config, &settings, false, None);

        assert!(!results.decay_function_scores.is_empty());
        assert!(results.decay_accuracy >= 0.0);
        assert!(results.decay_accuracy <= 1.0);
    }

    #[test]
    fn test_e3_periodic_benchmark() {
        let dataset_config = TemporalDatasetConfig {
            num_memories: 100,
            num_queries: 20,
            seed: 42,
            ..Default::default()
        };
        let settings = PeriodicBenchmarkSettings::default();

        let results = run_e3_periodic_benchmark(&dataset_config, &settings);

        assert!(results.silhouette_validation.hourly_variance >= 0.0);
        assert!(results.overall_periodic_score >= 0.0);
    }

    #[test]
    fn test_e4_sequence_benchmark() {
        let dataset_config = TemporalDatasetConfig {
            num_memories: 100,
            num_queries: 20,
            seed: 42,
            ..Default::default()
        };
        let settings = SequenceBenchmarkSettings::default();

        let results = run_e4_sequence_benchmark(&dataset_config, &settings, false, None);

        assert!(results.before_after_accuracy >= 0.0);
        assert!(results.sequence_accuracy >= 0.0);
    }

    #[test]
    fn test_ablation_benchmark() {
        let dataset_config = TemporalDatasetConfig {
            num_memories: 50,
            num_queries: 15,
            seed: 42,
            ..Default::default()
        };
        let config = AblationConfig {
            weight_configs: vec![
                (0.5, 0.15, 0.35),
                (1.0, 0.0, 0.0),
            ],
            num_memories: 50,
            num_queries: 15,
            seed: 42,
        };

        let results = run_ablation_benchmark(&dataset_config, &config);

        assert_eq!(results.config_results.len(), 2);
        assert!(!results.interference.recommendation.is_empty());
    }

    #[test]
    fn test_scaling_benchmark() {
        let config = ScalingConfig {
            corpus_sizes: vec![50, 100],
            num_queries: 10,
            seed: 42,
            time_span_days: 7,
        };

        let results = run_scaling_benchmark(&config);

        assert_eq!(results.scaling_points.len(), 2);
    }
}
