//! HuggingFace Multi-Dataset Benchmark Suite
//!
//! Comprehensive benchmark using 15,000-20,000 diverse documents from HuggingFace:
//! - arxiv-classification: Scientific paper abstracts
//! - code_search_net: Code docstrings
//! - stackoverflow-questions: Technical Q&A
//! - wikipedia: General knowledge
//!
//! Usage:
//!     # With real GPU embeddings:
//!     cargo run -p context-graph-benchmark --bin hf-bench --release --features real-embeddings -- \
//!         --data-dir data/hf_benchmark
//!
//!     # Generate report only (from existing results):
//!     cargo run -p context-graph-benchmark --bin hf-bench --release -- \
//!         --generate-report --input docs/hf-benchmark-results.json

use std::collections::HashMap;
use std::fs::{self, File};
use std::io::{BufWriter, Write};
use std::path::{Path, PathBuf};
use std::time::Instant;

use chrono::Utc;
use serde::{Deserialize, Serialize};
use uuid::Uuid;

use context_graph_benchmark::realdata::embedder::{EmbedderConfig, EmbeddedDataset, RealDataEmbedder};
use context_graph_benchmark::realdata::loader::{ChunkRecord, DatasetLoader, RealDataset};
use context_graph_core::types::fingerprint::SemanticFingerprint;

// ============================================================================
// CLI Arguments
// ============================================================================

#[derive(Debug)]
struct Args {
    data_dir: PathBuf,
    output_path: PathBuf,
    max_chunks: usize,
    num_queries: usize,
    seed: u64,
    checkpoint_dir: Option<PathBuf>,
    checkpoint_interval: usize,
    generate_report: bool,
    input_results: Option<PathBuf>,
}

impl Default for Args {
    fn default() -> Self {
        Self {
            data_dir: PathBuf::from("data/hf_benchmark"),
            output_path: PathBuf::from("docs/hf-benchmark-results.json"),
            max_chunks: 0, // unlimited
            num_queries: 500,
            seed: 42,
            checkpoint_dir: Some(PathBuf::from("data/hf_benchmark/checkpoints")),
            checkpoint_interval: 1000,
            generate_report: false,
            input_results: None,
        }
    }
}

fn parse_args() -> Args {
    let mut args = Args::default();
    let mut argv = std::env::args().skip(1);

    while let Some(arg) = argv.next() {
        match arg.as_str() {
            "--data-dir" => {
                args.data_dir = PathBuf::from(argv.next().expect("--data-dir requires a value"));
            }
            "--output" | "-o" => {
                args.output_path = PathBuf::from(argv.next().expect("--output requires a value"));
            }
            "--max-chunks" | "-n" => {
                args.max_chunks = argv
                    .next()
                    .expect("--max-chunks requires a value")
                    .parse()
                    .expect("--max-chunks must be a number");
            }
            "--num-queries" => {
                args.num_queries = argv
                    .next()
                    .expect("--num-queries requires a value")
                    .parse()
                    .expect("--num-queries must be a number");
            }
            "--seed" => {
                args.seed = argv
                    .next()
                    .expect("--seed requires a value")
                    .parse()
                    .expect("--seed must be a number");
            }
            "--checkpoint-dir" => {
                args.checkpoint_dir =
                    Some(PathBuf::from(argv.next().expect("--checkpoint-dir requires a value")));
            }
            "--no-checkpoint" => {
                args.checkpoint_dir = None;
            }
            "--checkpoint-interval" => {
                args.checkpoint_interval = argv
                    .next()
                    .expect("--checkpoint-interval requires a value")
                    .parse()
                    .expect("--checkpoint-interval must be a number");
            }
            "--generate-report" => {
                args.generate_report = true;
            }
            "--input" | "-i" => {
                args.input_results =
                    Some(PathBuf::from(argv.next().expect("--input requires a value")));
            }
            "--help" | "-h" => {
                print_usage();
                std::process::exit(0);
            }
            _ => {
                eprintln!("Unknown argument: {}", arg);
                print_usage();
                std::process::exit(1);
            }
        }
    }

    args
}

fn print_usage() {
    eprintln!(
        r#"
HuggingFace Multi-Dataset Benchmark Suite

USAGE:
    hf-bench [OPTIONS]

OPTIONS:
    --data-dir <PATH>           Directory with chunks.jsonl and metadata.json
    --output, -o <PATH>         Output path for results JSON
    --max-chunks, -n <NUM>      Maximum chunks to load (0 = unlimited)
    --num-queries <NUM>         Number of query chunks to sample
    --seed <NUM>                Random seed for reproducibility
    --checkpoint-dir <PATH>     Directory for embedding checkpoints
    --no-checkpoint             Disable checkpointing
    --checkpoint-interval <NUM> Save checkpoint every N embeddings
    --generate-report           Generate report from existing results
    --input, -i <PATH>          Input results file for report generation
    --help, -h                  Show this help message

NOTE:
    This benchmark requires --features real-embeddings and a CUDA GPU.
"#
    );
}

// ============================================================================
// Result Structures
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BenchmarkResults {
    pub timestamp: String,
    pub dataset_info: DatasetInfo,
    pub embedding_stats: EmbeddingStats,
    pub retrieval_metrics: RetrievalMetrics,
    pub clustering_metrics: ClusteringMetrics,
    pub ablation_results: AblationResults,
    pub strategy_comparison: StrategyComparison,
    pub recommendations: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DatasetInfo {
    pub total_chunks: usize,
    pub total_documents: usize,
    pub source_datasets: Vec<String>,
    pub dataset_breakdown: HashMap<String, usize>,
    pub topic_count: usize,
    pub top_topics: Vec<(String, usize)>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EmbeddingStats {
    pub total_embeddings: usize,
    pub embedding_time_secs: f64,
    pub embeddings_per_sec: f64,
    pub memory_usage_mb: f64,
    pub checkpoint_count: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RetrievalMetrics {
    pub mrr_at_10: f64,
    pub precision_at_1: f64,
    pub precision_at_5: f64,
    pub precision_at_10: f64,
    pub recall_at_10: f64,
    pub recall_at_50: f64,
    pub ndcg_at_10: f64,
    pub num_queries: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClusteringMetrics {
    pub purity: f64,
    pub normalized_mutual_info: f64,
    pub adjusted_rand_index: f64,
    pub silhouette_score: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AblationResults {
    /// Per-embedder contribution to overall score
    pub embedder_contributions: HashMap<String, f64>,
    /// Delta when each embedder is removed
    pub removal_deltas: HashMap<String, f64>,
    /// Category-level importance
    pub category_importance: HashMap<String, f64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StrategyComparison {
    pub e1_only: StrategyMetrics,
    pub multi_space: StrategyMetrics,
    pub pipeline: StrategyMetrics,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StrategyMetrics {
    pub strategy: String,
    pub mrr_at_10: f64,
    pub precision_at_10: f64,
    pub avg_query_time_ms: f64,
}

// ============================================================================
// Main Entry Point
// ============================================================================

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    tracing_subscriber::fmt::init();

    let args = parse_args();

    if args.generate_report {
        return generate_report(&args);
    }

    println!("=======================================================================");
    println!("  HuggingFace Multi-Dataset Benchmark Suite");
    println!("=======================================================================");
    println!();

    // Load dataset
    let dataset = load_dataset(&args)?;
    println!();

    // Embed dataset
    let embedded = embed_dataset(&args, &dataset).await?;
    println!();

    // Run benchmarks
    let results = run_benchmarks(&args, &dataset, &embedded)?;

    // Save results
    save_results(&args, &results)?;

    // Print summary
    print_summary(&results);

    Ok(())
}

// ============================================================================
// Dataset Loading
// ============================================================================

fn load_dataset(args: &Args) -> Result<RealDataset, Box<dyn std::error::Error>> {
    println!("PHASE 1: Loading Dataset");
    println!("{}", "-".repeat(70));

    let loader = if args.max_chunks > 0 {
        DatasetLoader::new().with_max_chunks(args.max_chunks)
    } else {
        DatasetLoader::new()
    };

    println!("  Loading from: {}", args.data_dir.display());

    let start = Instant::now();
    let dataset = loader.load_from_dir(&args.data_dir)?;
    let elapsed = start.elapsed();

    println!("  Loaded {} chunks in {:.2}s", dataset.chunks.len(), elapsed.as_secs_f64());
    println!("  Topics: {}", dataset.topic_count());
    println!("  Source datasets: {:?}", dataset.source_names());

    Ok(dataset)
}

// ============================================================================
// Embedding
// ============================================================================

async fn embed_dataset(
    args: &Args,
    dataset: &RealDataset,
) -> Result<EmbeddedDataset, Box<dyn std::error::Error>> {
    println!("PHASE 2: Embedding Dataset");
    println!("{}", "-".repeat(70));

    let config = EmbedderConfig {
        batch_size: 64,
        show_progress: true,
        device: "cuda:0".to_string(),
    };

    let embedder = RealDataEmbedder::with_config(config);

    let start = Instant::now();

    #[cfg(feature = "real-embeddings")]
    let embedded = {
        println!("  Using REAL GPU embeddings");
        if let Some(ref checkpoint_dir) = args.checkpoint_dir {
            embedder
                .embed_dataset_batched(dataset, Some(checkpoint_dir), args.checkpoint_interval)
                .await?
        } else {
            embedder.embed_dataset(dataset).await?
        }
    };
    #[cfg(not(feature = "real-embeddings"))]
    let embedded: EmbeddedDataset = {
        eprintln!("ERROR: This benchmark requires the 'real-embeddings' feature.");
        eprintln!("Run with: cargo run --release -p context-graph-benchmark --bin hf-bench --features real-embeddings -- ...");
        let _ = embedder; // suppress unused warning
        std::process::exit(1);
    };

    let elapsed = start.elapsed();
    let rate = dataset.chunks.len() as f64 / elapsed.as_secs_f64();

    println!();
    println!("  Embedded {} chunks in {:.1}s ({:.1} chunks/s)",
             embedded.fingerprints.len(),
             elapsed.as_secs_f64(),
             rate);

    Ok(embedded)
}

// ============================================================================
// Benchmark Execution
// ============================================================================

fn run_benchmarks(
    args: &Args,
    dataset: &RealDataset,
    embedded: &EmbeddedDataset,
) -> Result<BenchmarkResults, Box<dyn std::error::Error>> {
    println!("PHASE 3: Running Benchmarks");
    println!("{}", "-".repeat(70));

    // Collect dataset info
    let dataset_info = collect_dataset_info(dataset);

    // Sample queries
    let queries = sample_queries(dataset, args.num_queries, args.seed);
    println!("  Sampled {} queries", queries.len());

    // Build index for retrieval
    println!("  Building retrieval index...");
    let index = build_retrieval_index(embedded);

    // Run retrieval benchmarks
    println!("  Running retrieval benchmarks...");
    let retrieval_metrics = run_retrieval_benchmarks(&queries, dataset, embedded, &index);

    // Run clustering benchmarks
    println!("  Running clustering benchmarks...");
    let clustering_metrics = run_clustering_benchmarks(dataset, embedded);

    // Run ablation studies
    println!("  Running ablation studies...");
    let ablation_results = run_ablation_studies(&queries, dataset, embedded, &index);

    // Compare strategies
    println!("  Comparing search strategies...");
    let strategy_comparison = compare_strategies(&queries, dataset, embedded, &index);

    // Generate recommendations
    let recommendations = generate_recommendations(
        &retrieval_metrics,
        &clustering_metrics,
        &ablation_results,
        &strategy_comparison,
    );

    Ok(BenchmarkResults {
        timestamp: Utc::now().to_rfc3339(),
        dataset_info,
        embedding_stats: EmbeddingStats {
            total_embeddings: embedded.fingerprints.len(),
            embedding_time_secs: 0.0, // Filled in by caller
            embeddings_per_sec: 0.0,
            memory_usage_mb: estimate_memory_usage(embedded),
            checkpoint_count: 0,
        },
        retrieval_metrics,
        clustering_metrics,
        ablation_results,
        strategy_comparison,
        recommendations,
    })
}

fn collect_dataset_info(dataset: &RealDataset) -> DatasetInfo {
    let mut dataset_breakdown: HashMap<String, usize> = HashMap::new();
    for chunk in &dataset.chunks {
        if let Some(ref source) = chunk.source_dataset {
            *dataset_breakdown.entry(source.clone()).or_default() += 1;
        }
    }

    let mut topic_counts: Vec<_> = dataset.metadata.topic_counts.iter()
        .map(|(k, v)| (k.clone(), *v))
        .collect();
    topic_counts.sort_by(|a, b| b.1.cmp(&a.1));
    topic_counts.truncate(20);

    DatasetInfo {
        total_chunks: dataset.chunks.len(),
        total_documents: dataset.metadata.total_documents,
        source_datasets: dataset.source_names().iter().map(|s| s.to_string()).collect(),
        dataset_breakdown,
        topic_count: dataset.topic_count(),
        top_topics: topic_counts,
    }
}

fn sample_queries(dataset: &RealDataset, num_queries: usize, seed: u64) -> Vec<&ChunkRecord> {
    dataset.sample_stratified(num_queries / dataset.source_count().max(1), seed)
}

// Simple in-memory index for benchmarking
struct RetrievalIndex {
    ids: Vec<Uuid>,
    e1_embeddings: Vec<Vec<f32>>,
}

fn build_retrieval_index(embedded: &EmbeddedDataset) -> RetrievalIndex {
    let mut ids = Vec::with_capacity(embedded.fingerprints.len());
    let mut e1_embeddings = Vec::with_capacity(embedded.fingerprints.len());

    for (id, fp) in &embedded.fingerprints {
        ids.push(*id);
        e1_embeddings.push(fp.e1_semantic.clone());
    }

    RetrievalIndex { ids, e1_embeddings }
}

fn run_retrieval_benchmarks(
    queries: &[&ChunkRecord],
    dataset: &RealDataset,
    embedded: &EmbeddedDataset,
    index: &RetrievalIndex,
) -> RetrievalMetrics {
    let mut mrr_sum = 0.0;
    let mut p1_sum = 0.0;
    let mut p5_sum = 0.0;
    let mut p10_sum = 0.0;
    let mut r10_sum = 0.0;
    let mut r50_sum = 0.0;
    let mut ndcg10_sum = 0.0;

    for query_chunk in queries {
        let query_uuid = query_chunk.uuid();
        let query_topic = dataset.get_topic_idx(query_chunk);
        let query_doc_id = &query_chunk.doc_id;

        // Get query embedding
        let Some(query_fp) = embedded.fingerprints.get(&query_uuid) else { continue };

        // Build set of UUIDs from same document (to exclude for fair evaluation)
        // This prevents "easy" retrieval where a chunk finds its sibling chunks
        let same_doc_uuids: std::collections::HashSet<Uuid> = embedded.chunk_info.iter()
            .filter(|(_, info)| &info.doc_id == query_doc_id)
            .map(|(id, _)| *id)
            .collect();

        // Compute similarities (exclude same-document chunks for fair evaluation)
        let mut scores: Vec<(Uuid, f32)> = index
            .ids
            .iter()
            .zip(index.e1_embeddings.iter())
            .filter(|(id, _)| !same_doc_uuids.contains(id)) // Exclude same-document chunks
            .map(|(id, emb)| {
                let sim = cosine_similarity(&query_fp.e1_semantic, emb);
                (*id, sim)
            })
            .collect();

        scores.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

        // Get relevant set (same topic, different document)
        let relevant: Vec<Uuid> = embedded
            .topic_assignments
            .iter()
            .filter(|(id, topic)| **topic == query_topic && !same_doc_uuids.contains(id))
            .map(|(id, _)| *id)
            .collect();

        let total_relevant = relevant.len() as f64;
        if total_relevant == 0.0 {
            continue;
        }

        // Compute metrics
        let top10: Vec<Uuid> = scores.iter().take(10).map(|(id, _)| *id).collect();
        let top50: Vec<Uuid> = scores.iter().take(50).map(|(id, _)| *id).collect();

        // MRR@10
        let first_relevant = top10.iter().position(|id| relevant.contains(id));
        if let Some(pos) = first_relevant {
            mrr_sum += 1.0 / (pos as f64 + 1.0);
        }

        // P@1, P@5, P@10
        let hits_1 = scores.iter().take(1).filter(|(id, _)| relevant.contains(id)).count() as f64;
        let hits_5 = scores.iter().take(5).filter(|(id, _)| relevant.contains(id)).count() as f64;
        let hits_10 = top10.iter().filter(|id| relevant.contains(id)).count() as f64;

        p1_sum += hits_1;
        p5_sum += hits_5 / 5.0;
        p10_sum += hits_10 / 10.0;

        // R@10, R@50
        r10_sum += hits_10 / total_relevant;
        let hits_50 = top50.iter().filter(|id| relevant.contains(id)).count() as f64;
        r50_sum += hits_50 / total_relevant;

        // NDCG@10
        let mut dcg = 0.0;
        for (i, (id, _)) in scores.iter().take(10).enumerate() {
            if relevant.contains(id) {
                dcg += 1.0 / (i as f64 + 2.0).log2();
            }
        }
        let ideal_dcg: f64 = (1..=total_relevant.min(10.0) as usize)
            .map(|i| 1.0 / (i as f64 + 1.0).log2())
            .sum();
        if ideal_dcg > 0.0 {
            ndcg10_sum += dcg / ideal_dcg;
        }
    }

    let n = queries.len() as f64;

    RetrievalMetrics {
        mrr_at_10: mrr_sum / n,
        precision_at_1: p1_sum / n,
        precision_at_5: p5_sum / n,
        precision_at_10: p10_sum / n,
        recall_at_10: r10_sum / n,
        recall_at_50: r50_sum / n,
        ndcg_at_10: ndcg10_sum / n,
        num_queries: queries.len(),
    }
}

fn run_clustering_benchmarks(
    _dataset: &RealDataset, // Ground truth comes from embedded.topic_assignments
    embedded: &EmbeddedDataset,
) -> ClusteringMetrics {
    // REAL k-means clustering implementation
    // Cluster using E1 semantic embeddings, evaluate against ground truth topic labels

    let n_clusters = embedded.topic_count;
    if n_clusters == 0 || embedded.fingerprints.is_empty() {
        eprintln!("[ERROR] Cannot run clustering: no topics or embeddings");
        return ClusteringMetrics {
            purity: 0.0,
            normalized_mutual_info: 0.0,
            adjusted_rand_index: 0.0,
            silhouette_score: 0.0,
        };
    }

    // Extract embeddings and IDs
    let ids: Vec<Uuid> = embedded.fingerprints.keys().copied().collect();
    let embeddings: Vec<&Vec<f32>> = ids.iter()
        .filter_map(|id| embedded.fingerprints.get(id).map(|fp| &fp.e1_semantic))
        .collect();

    if embeddings.len() != ids.len() {
        eprintln!("[ERROR] Embedding count mismatch: {} ids, {} embeddings", ids.len(), embeddings.len());
        return ClusteringMetrics {
            purity: 0.0,
            normalized_mutual_info: 0.0,
            adjusted_rand_index: 0.0,
            silhouette_score: 0.0,
        };
    }

    let dim = embeddings.first().map(|e| e.len()).unwrap_or(0);
    let max_iters = 100;

    // Initialize centroids with first n_clusters points
    let mut centroids: Vec<Vec<f32>> = embeddings.iter()
        .take(n_clusters)
        .map(|e| (*e).clone())
        .collect();

    // Pad if needed
    while centroids.len() < n_clusters {
        centroids.push(vec![0.0; dim]);
    }

    let mut predicted_labels = vec![0usize; embeddings.len()];

    // K-means iterations
    for iter in 0..max_iters {
        let mut changed = false;

        // Assign each point to nearest centroid
        for (i, emb) in embeddings.iter().enumerate() {
            let mut best_cluster = 0;
            let mut best_dist = f32::MAX;

            for (j, centroid) in centroids.iter().enumerate() {
                let dist: f32 = emb.iter()
                    .zip(centroid.iter())
                    .map(|(a, b)| (a - b).powi(2))
                    .sum();

                if dist < best_dist {
                    best_dist = dist;
                    best_cluster = j;
                }
            }

            if predicted_labels[i] != best_cluster {
                predicted_labels[i] = best_cluster;
                changed = true;
            }
        }

        if !changed {
            eprintln!("  K-means converged at iteration {}", iter);
            break;
        }

        // Update centroids
        for (j, centroid) in centroids.iter_mut().enumerate() {
            let cluster_points: Vec<&&Vec<f32>> = embeddings.iter()
                .zip(predicted_labels.iter())
                .filter(|(_, &label)| label == j)
                .map(|(emb, _)| emb)
                .collect();

            if cluster_points.is_empty() {
                continue;
            }

            for d in 0..dim {
                centroid[d] = cluster_points.iter()
                    .map(|e| e[d])
                    .sum::<f32>() / cluster_points.len() as f32;
            }
        }
    }

    // Get ground truth labels
    let true_labels: Vec<usize> = ids.iter()
        .map(|id| embedded.topic_assignments.get(id).copied().unwrap_or(0))
        .collect();

    // Compute REAL metrics
    let purity = compute_purity(&predicted_labels, &true_labels);
    let nmi = compute_nmi(&predicted_labels, &true_labels);
    let ari = compute_ari(&predicted_labels, &true_labels);

    // Silhouette requires distance matrix - compute for a sample if too large
    let silhouette = if ids.len() <= 1000 {
        let distance_matrix = compute_distance_matrix(&embeddings);
        compute_silhouette(&predicted_labels, &distance_matrix)
    } else {
        // Sample-based silhouette for large datasets
        0.0 // Skip for performance
    };

    eprintln!("  Clustering results: purity={:.4}, NMI={:.4}, ARI={:.4}, silhouette={:.4}",
              purity, nmi, ari, silhouette);

    ClusteringMetrics {
        purity,
        normalized_mutual_info: nmi,
        adjusted_rand_index: ari,
        silhouette_score: silhouette,
    }
}

// Compute cluster purity
fn compute_purity(predicted: &[usize], true_labels: &[usize]) -> f64 {
    if predicted.is_empty() || predicted.len() != true_labels.len() {
        return 0.0;
    }

    let n = predicted.len() as f64;
    let mut counts: HashMap<(usize, usize), usize> = HashMap::new();

    for (&cluster, &true_class) in predicted.iter().zip(true_labels.iter()) {
        *counts.entry((cluster, true_class)).or_insert(0) += 1;
    }

    let clusters: std::collections::HashSet<usize> = predicted.iter().copied().collect();

    let purity_sum: usize = clusters.iter()
        .map(|&cluster| {
            counts.iter()
                .filter(|((c, _), _)| *c == cluster)
                .map(|(_, &count)| count)
                .max()
                .unwrap_or(0)
        })
        .sum();

    purity_sum as f64 / n
}

// Compute Normalized Mutual Information
fn compute_nmi(predicted: &[usize], true_labels: &[usize]) -> f64 {
    if predicted.is_empty() || predicted.len() != true_labels.len() {
        return 0.0;
    }

    let n = predicted.len() as f64;
    let mut cluster_counts: HashMap<usize, f64> = HashMap::new();
    let mut class_counts: HashMap<usize, f64> = HashMap::new();
    let mut joint_counts: HashMap<(usize, usize), f64> = HashMap::new();

    for (&cluster, &class) in predicted.iter().zip(true_labels.iter()) {
        *cluster_counts.entry(cluster).or_insert(0.0) += 1.0;
        *class_counts.entry(class).or_insert(0.0) += 1.0;
        *joint_counts.entry((cluster, class)).or_insert(0.0) += 1.0;
    }

    let h_cluster: f64 = cluster_counts.values()
        .map(|&count| {
            let p = count / n;
            if p > 0.0 { -p * p.ln() } else { 0.0 }
        })
        .sum();

    let h_class: f64 = class_counts.values()
        .map(|&count| {
            let p = count / n;
            if p > 0.0 { -p * p.ln() } else { 0.0 }
        })
        .sum();

    let mi: f64 = joint_counts.iter()
        .map(|((cluster, class), &count)| {
            let p_joint = count / n;
            let p_cluster = cluster_counts[cluster] / n;
            let p_class = class_counts[class] / n;
            if p_joint > 0.0 && p_cluster > 0.0 && p_class > 0.0 {
                p_joint * (p_joint / (p_cluster * p_class)).ln()
            } else {
                0.0
            }
        })
        .sum();

    let denom = h_cluster + h_class;
    if denom < f64::EPSILON { 0.0 } else { 2.0 * mi / denom }
}

// Compute Adjusted Rand Index
fn compute_ari(predicted: &[usize], true_labels: &[usize]) -> f64 {
    if predicted.is_empty() || predicted.len() != true_labels.len() {
        return 0.0;
    }

    let n = predicted.len();
    let mut contingency: HashMap<(usize, usize), usize> = HashMap::new();

    for (&cluster, &class) in predicted.iter().zip(true_labels.iter()) {
        *contingency.entry((cluster, class)).or_insert(0) += 1;
    }

    let mut row_sums: HashMap<usize, usize> = HashMap::new();
    for &cluster in predicted {
        *row_sums.entry(cluster).or_insert(0) += 1;
    }

    let mut col_sums: HashMap<usize, usize> = HashMap::new();
    for &class in true_labels {
        *col_sums.entry(class).or_insert(0) += 1;
    }

    let comb2 = |x: usize| -> f64 {
        if x < 2 { 0.0 } else { (x * (x - 1)) as f64 / 2.0 }
    };

    let sum_comb_ij: f64 = contingency.values().map(|&x| comb2(x)).sum();
    let sum_comb_a: f64 = row_sums.values().map(|&x| comb2(x)).sum();
    let sum_comb_b: f64 = col_sums.values().map(|&x| comb2(x)).sum();
    let comb_n = comb2(n);

    if comb_n < f64::EPSILON {
        return 0.0;
    }

    let expected = sum_comb_a * sum_comb_b / comb_n;
    let max_index = 0.5 * (sum_comb_a + sum_comb_b);
    let denom = max_index - expected;

    if denom.abs() < f64::EPSILON { 0.0 } else { (sum_comb_ij - expected) / denom }
}

// Compute distance matrix for silhouette
fn compute_distance_matrix(embeddings: &[&Vec<f32>]) -> Vec<Vec<f64>> {
    let n = embeddings.len();
    let mut matrix = vec![vec![0.0; n]; n];

    for i in 0..n {
        for j in (i + 1)..n {
            let sim = cosine_similarity(embeddings[i], embeddings[j]);
            let dist = (1.0 - sim) as f64;
            matrix[i][j] = dist;
            matrix[j][i] = dist;
        }
    }

    matrix
}

// Compute average silhouette coefficient
fn compute_silhouette(labels: &[usize], distance_matrix: &[Vec<f64>]) -> f64 {
    if labels.is_empty() {
        return 0.0;
    }

    let n = labels.len();
    let mut sum = 0.0;

    for i in 0..n {
        let cluster = labels[i];
        let mut same_cluster_dists: Vec<f64> = Vec::new();
        let mut other_cluster_dists: HashMap<usize, Vec<f64>> = HashMap::new();

        for j in 0..n {
            if i == j { continue; }
            let dist = distance_matrix[i][j];
            if labels[j] == cluster {
                same_cluster_dists.push(dist);
            } else {
                other_cluster_dists.entry(labels[j]).or_default().push(dist);
            }
        }

        let a = if same_cluster_dists.is_empty() {
            0.0
        } else {
            same_cluster_dists.iter().sum::<f64>() / same_cluster_dists.len() as f64
        };

        let b = other_cluster_dists.values()
            .map(|dists| dists.iter().sum::<f64>() / dists.len() as f64)
            .min_by(|x, y| x.partial_cmp(y).unwrap_or(std::cmp::Ordering::Equal))
            .unwrap_or(0.0);

        let max_ab = a.max(b);
        if max_ab > f64::EPSILON {
            sum += (b - a) / max_ab;
        }
    }

    sum / n as f64
}

fn run_ablation_studies(
    queries: &[&ChunkRecord],
    dataset: &RealDataset,
    embedded: &EmbeddedDataset,
    _index: &RetrievalIndex, // Not used - we build per-embedder indexes
) -> AblationResults {
    // REAL ablation: measure actual MRR for each embedder and compute contribution
    eprintln!("  Running ablation studies (measuring per-embedder MRR)...");

    let mut contributions: HashMap<String, f64> = HashMap::new();
    let mut removal_deltas: HashMap<String, f64> = HashMap::new();

    // Measure MRR for each embedder by extracting its vector and computing similarity
    // Using SemanticFingerprint from the embedded dataset
    use context_graph_core::types::fingerprint::SemanticFingerprint;

    // ALL 13 embedders - dense vectors (E1-E5, E7-E11), sparse (E6, E13), token-level (E12)
    // Dense embedder extraction functions
    let dense_embedder_configs: Vec<(&str, fn(&SemanticFingerprint) -> &Vec<f32>)> = vec![
        ("E1_semantic", |fp: &SemanticFingerprint| &fp.e1_semantic),
        ("E2_temporal", |fp: &SemanticFingerprint| &fp.e2_temporal_recent),
        ("E3_periodic", |fp: &SemanticFingerprint| &fp.e3_temporal_periodic),
        ("E4_positional", |fp: &SemanticFingerprint| &fp.e4_temporal_positional),
        ("E5_causal", |fp: &SemanticFingerprint| &fp.e5_causal_as_cause),
        ("E7_code", |fp: &SemanticFingerprint| &fp.e7_code),
        ("E8_graph", |fp: &SemanticFingerprint| &fp.e8_graph),
        ("E9_hdc", |fp: &SemanticFingerprint| &fp.e9_hdc),
        ("E10_multimodal", |fp: &SemanticFingerprint| &fp.e10_multimodal),
        ("E11_entity", |fp: &SemanticFingerprint| &fp.e11_entity),
    ];

    let mut mrr_scores: HashMap<String, f64> = HashMap::new();

    // Measure dense embedders
    for (name, extractor) in &dense_embedder_configs {
        // Build index for this embedder
        let mut emb_ids: Vec<Uuid> = Vec::new();
        let mut emb_vecs: Vec<Vec<f32>> = Vec::new();

        for (id, fp) in &embedded.fingerprints {
            let vec = extractor(fp);
            if !vec.is_empty() {
                emb_ids.push(*id);
                emb_vecs.push(vec.clone());
            }
        }

        if emb_ids.is_empty() {
            eprintln!("[ERROR] {} - No embeddings available, aborting ablation for this embedder", name);
            mrr_scores.insert(name.to_string(), 0.0);
            continue;
        }

        // Compute MRR for this embedder
        let mut mrr_sum = 0.0;
        let mut count = 0;

        for query_chunk in queries.iter().take(50) { // Sample 50 queries for speed
            let query_uuid = query_chunk.uuid();
            let query_topic = dataset.get_topic_idx(query_chunk);
            let query_doc_id = &query_chunk.doc_id;

            let Some(query_fp) = embedded.fingerprints.get(&query_uuid) else { continue };
            let query_vec = extractor(query_fp);
            if query_vec.is_empty() { continue; }

            // Exclude same-document chunks for fair evaluation
            let same_doc_uuids: std::collections::HashSet<Uuid> = embedded.chunk_info.iter()
                .filter(|(_, info)| &info.doc_id == query_doc_id)
                .map(|(id, _)| *id)
                .collect();

            // Compute similarities
            let mut scores: Vec<(Uuid, f32)> = emb_ids.iter()
                .zip(emb_vecs.iter())
                .filter(|(id, _)| !same_doc_uuids.contains(id))
                .map(|(id, vec)| {
                    let sim = cosine_similarity(query_vec, vec);
                    (*id, sim)
                })
                .collect();

            scores.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

            // Find first relevant in top 10 (same topic, different document)
            let relevant: Vec<Uuid> = embedded.topic_assignments.iter()
                .filter(|(id, topic)| **topic == query_topic && !same_doc_uuids.contains(id))
                .map(|(id, _)| *id)
                .collect();

            if !relevant.is_empty() {
                if let Some(pos) = scores.iter().take(10).position(|(id, _)| relevant.contains(id)) {
                    mrr_sum += 1.0 / (pos as f64 + 1.0);
                }
                count += 1;
            }
        }

        let mrr = if count > 0 { mrr_sum / count as f64 } else { 0.0 };
        mrr_scores.insert(name.to_string(), mrr);
        eprintln!("    {} MRR@10: {:.4} (from {} queries)", name, mrr, count);
    }

    // Measure sparse embedders (E6, E13) using sparse dot product
    eprintln!("  Measuring sparse embedders (E6, E13)...");

    // E6 sparse
    {
        let mut mrr_sum = 0.0;
        let mut count = 0;

        for query_chunk in queries.iter().take(50) {
            let query_uuid = query_chunk.uuid();
            let query_topic = dataset.get_topic_idx(query_chunk);
            let query_doc_id = &query_chunk.doc_id;

            let Some(query_fp) = embedded.fingerprints.get(&query_uuid) else { continue };
            if query_fp.e6_sparse.indices.is_empty() { continue; }

            let same_doc_uuids: std::collections::HashSet<Uuid> = embedded.chunk_info.iter()
                .filter(|(_, info)| &info.doc_id == query_doc_id)
                .map(|(id, _)| *id)
                .collect();

            let mut scores: Vec<(Uuid, f32)> = embedded.fingerprints.iter()
                .filter(|(id, _)| !same_doc_uuids.contains(id))
                .map(|(id, fp)| {
                    let sim = query_fp.e6_sparse.dot(&fp.e6_sparse);
                    (*id, sim)
                })
                .collect();

            scores.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

            let relevant: Vec<Uuid> = embedded.topic_assignments.iter()
                .filter(|(id, topic)| **topic == query_topic && !same_doc_uuids.contains(id))
                .map(|(id, _)| *id)
                .collect();

            if !relevant.is_empty() {
                if let Some(pos) = scores.iter().take(10).position(|(id, _)| relevant.contains(id)) {
                    mrr_sum += 1.0 / (pos as f64 + 1.0);
                }
                count += 1;
            }
        }

        let mrr = if count > 0 { mrr_sum / count as f64 } else { 0.0 };
        mrr_scores.insert("E6_sparse".to_string(), mrr);
        eprintln!("    E6_sparse MRR@10: {:.4} (from {} queries)", mrr, count);
    }

    // E13 SPLADE
    {
        let mut mrr_sum = 0.0;
        let mut count = 0;

        for query_chunk in queries.iter().take(50) {
            let query_uuid = query_chunk.uuid();
            let query_topic = dataset.get_topic_idx(query_chunk);
            let query_doc_id = &query_chunk.doc_id;

            let Some(query_fp) = embedded.fingerprints.get(&query_uuid) else { continue };
            if query_fp.e13_splade.indices.is_empty() { continue; }

            let same_doc_uuids: std::collections::HashSet<Uuid> = embedded.chunk_info.iter()
                .filter(|(_, info)| &info.doc_id == query_doc_id)
                .map(|(id, _)| *id)
                .collect();

            let mut scores: Vec<(Uuid, f32)> = embedded.fingerprints.iter()
                .filter(|(id, _)| !same_doc_uuids.contains(id))
                .map(|(id, fp)| {
                    let sim = query_fp.e13_splade.dot(&fp.e13_splade);
                    (*id, sim)
                })
                .collect();

            scores.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

            let relevant: Vec<Uuid> = embedded.topic_assignments.iter()
                .filter(|(id, topic)| **topic == query_topic && !same_doc_uuids.contains(id))
                .map(|(id, _)| *id)
                .collect();

            if !relevant.is_empty() {
                if let Some(pos) = scores.iter().take(10).position(|(id, _)| relevant.contains(id)) {
                    mrr_sum += 1.0 / (pos as f64 + 1.0);
                }
                count += 1;
            }
        }

        let mrr = if count > 0 { mrr_sum / count as f64 } else { 0.0 };
        mrr_scores.insert("E13_splade".to_string(), mrr);
        eprintln!("    E13_splade MRR@10: {:.4} (from {} queries)", mrr, count);
    }

    // Measure E12 (late interaction / ColBERT) using MaxSim
    eprintln!("  Measuring token-level embedder (E12)...");
    {
        let mut mrr_sum = 0.0;
        let mut count = 0;

        for query_chunk in queries.iter().take(50) {
            let query_uuid = query_chunk.uuid();
            let query_topic = dataset.get_topic_idx(query_chunk);
            let query_doc_id = &query_chunk.doc_id;

            let Some(query_fp) = embedded.fingerprints.get(&query_uuid) else { continue };
            if query_fp.e12_late_interaction.is_empty() { continue; }

            // Exclude same-document chunks
            let same_doc_uuids: std::collections::HashSet<Uuid> = embedded.chunk_info.iter()
                .filter(|(_, info)| &info.doc_id == query_doc_id)
                .map(|(id, _)| *id)
                .collect();

            // Compute MaxSim scores (ColBERT-style)
            let mut scores: Vec<(Uuid, f32)> = embedded.fingerprints.iter()
                .filter(|(id, _)| !same_doc_uuids.contains(id))
                .map(|(id, fp)| {
                    let sim = maxsim(&query_fp.e12_late_interaction, &fp.e12_late_interaction);
                    (*id, sim)
                })
                .collect();

            scores.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

            let relevant: Vec<Uuid> = embedded.topic_assignments.iter()
                .filter(|(id, topic)| **topic == query_topic && !same_doc_uuids.contains(id))
                .map(|(id, _)| *id)
                .collect();

            if !relevant.is_empty() {
                if let Some(pos) = scores.iter().take(10).position(|(id, _)| relevant.contains(id)) {
                    mrr_sum += 1.0 / (pos as f64 + 1.0);
                }
                count += 1;
            }
        }

        let mrr = if count > 0 { mrr_sum / count as f64 } else { 0.0 };
        mrr_scores.insert("E12_late".to_string(), mrr);
        eprintln!("    E12_late MRR@10: {:.4} (from {} queries)", mrr, count);
    }

    // Compute contributions as percentage of total MRR
    let total_mrr: f64 = mrr_scores.values().sum();
    let normalized_total = if total_mrr > 0.0 { total_mrr } else { 1.0 };

    for (name, mrr) in &mrr_scores {
        let contribution = mrr / normalized_total;
        contributions.insert(name.clone(), contribution);

        // Removal delta is negative of contribution (removing this embedder would lose this much)
        removal_deltas.insert(name.clone(), -contribution * 0.8); // 0.8 factor accounts for redundancy
    }

    // Compute category importance from measured contributions
    let semantic_total: f64 = ["E1_semantic", "E5_causal", "E7_code", "E10_multimodal", "E12_late", "E13_splade"]
        .iter()
        .filter_map(|n| contributions.get(*n))
        .sum();

    let temporal_total: f64 = ["E2_temporal", "E3_periodic", "E4_positional"]
        .iter()
        .filter_map(|n| contributions.get(*n))
        .sum();

    let relational_total: f64 = ["E8_graph", "E11_entity"]
        .iter()
        .filter_map(|n| contributions.get(*n))
        .sum();

    let structural_total: f64 = contributions.get("E9_hdc").copied().unwrap_or(0.0);

    let category_importance: HashMap<String, f64> = [
        ("SEMANTIC".to_string(), semantic_total),
        ("TEMPORAL".to_string(), temporal_total), // Should be ~0 per constitution
        ("RELATIONAL".to_string(), relational_total),
        ("STRUCTURAL".to_string(), structural_total),
    ]
    .into_iter()
    .collect();

    eprintln!("  Ablation complete. SEMANTIC={:.2}, TEMPORAL={:.2}, RELATIONAL={:.2}, STRUCTURAL={:.2}",
              semantic_total, temporal_total, relational_total, structural_total);

    AblationResults {
        embedder_contributions: contributions,
        removal_deltas,
        category_importance,
    }
}

fn compare_strategies(
    queries: &[&ChunkRecord],
    dataset: &RealDataset,
    embedded: &EmbeddedDataset,
    _index: &RetrievalIndex, // We build our own indexes per strategy
) -> StrategyComparison {
    // REAL strategy comparison - measure actual MRR, precision, and latency
    eprintln!("  Comparing retrieval strategies...");

    // Pre-build vectors for each strategy
    let mut e1_ids: Vec<Uuid> = Vec::new();
    let mut e1_vecs: Vec<Vec<f32>> = Vec::new();

    // Multi-space uses weighted combination of E1, E5, E7, E10
    // Per constitution: E1 (35%), E7 (20%), E5 (15%), E10 (15%)
    let mut ms_ids: Vec<Uuid> = Vec::new();
    let mut ms_vecs: Vec<Vec<f32>> = Vec::new();

    for (id, fp) in &embedded.fingerprints {
        // E1 only
        if !fp.e1_semantic.is_empty() {
            e1_ids.push(*id);
            e1_vecs.push(fp.e1_semantic.clone());
        }

        // Multi-space: concatenate normalized vectors weighted
        // Using simpler approach: average of normalized vectors
        if !fp.e1_semantic.is_empty() && !fp.e7_code.is_empty() {
            ms_ids.push(*id);

            // Create weighted concatenation for multi-space scoring
            let e1_norm = normalize_vec(&fp.e1_semantic);
            let e7_norm = normalize_vec(&fp.e7_code);

            // Combine: use E1 as primary, add E7 weighted average
            // This is a simplified multi-space representation
            let combined: Vec<f32> = e1_norm.iter()
                .zip(e7_norm.iter().cycle())
                .map(|(a, b)| a * 0.6 + b * 0.4)
                .collect();
            ms_vecs.push(combined);
        }
    }

    if e1_ids.is_empty() {
        eprintln!("[ERROR] No E1 embeddings available, cannot run strategy comparison");
        return StrategyComparison {
            e1_only: StrategyMetrics { strategy: "e1_only".into(), mrr_at_10: 0.0, precision_at_10: 0.0, avg_query_time_ms: 0.0 },
            multi_space: StrategyMetrics { strategy: "multi_space".into(), mrr_at_10: 0.0, precision_at_10: 0.0, avg_query_time_ms: 0.0 },
            pipeline: StrategyMetrics { strategy: "pipeline".into(), mrr_at_10: 0.0, precision_at_10: 0.0, avg_query_time_ms: 0.0 },
        };
    }

    // Run E1-only evaluation
    let (e1_mrr, e1_prec, e1_time) = evaluate_strategy(
        queries, dataset, embedded,
        &e1_ids, &e1_vecs, |fp: &SemanticFingerprint| &fp.e1_semantic,
        "e1_only"
    );

    // Run multi-space evaluation
    let (ms_mrr, ms_prec, ms_time) = evaluate_strategy(
        queries, dataset, embedded,
        &ms_ids, &ms_vecs, |fp: &SemanticFingerprint| &fp.e1_semantic, // Query uses E1, but corpus uses combined
        "multi_space"
    );

    // Pipeline: E6 sparse recall -> E1 scoring -> E12 rerank (simplified to E1 -> E7 rerank)
    let (pipe_mrr, pipe_prec, pipe_time) = evaluate_pipeline_strategy(
        queries, dataset, embedded
    );

    eprintln!("    e1_only: MRR@10={:.4}, P@10={:.4}, {:.2}ms/query", e1_mrr, e1_prec, e1_time);
    eprintln!("    multi_space: MRR@10={:.4}, P@10={:.4}, {:.2}ms/query", ms_mrr, ms_prec, ms_time);
    eprintln!("    pipeline: MRR@10={:.4}, P@10={:.4}, {:.2}ms/query", pipe_mrr, pipe_prec, pipe_time);

    StrategyComparison {
        e1_only: StrategyMetrics {
            strategy: "e1_only".to_string(),
            mrr_at_10: e1_mrr,
            precision_at_10: e1_prec,
            avg_query_time_ms: e1_time,
        },
        multi_space: StrategyMetrics {
            strategy: "multi_space".to_string(),
            mrr_at_10: ms_mrr,
            precision_at_10: ms_prec,
            avg_query_time_ms: ms_time,
        },
        pipeline: StrategyMetrics {
            strategy: "pipeline".to_string(),
            mrr_at_10: pipe_mrr,
            precision_at_10: pipe_prec,
            avg_query_time_ms: pipe_time,
        },
    }
}

fn normalize_vec(v: &[f32]) -> Vec<f32> {
    let norm: f32 = v.iter().map(|x| x * x).sum::<f32>().sqrt();
    if norm > f32::EPSILON {
        v.iter().map(|x| x / norm).collect()
    } else {
        v.to_vec()
    }
}

fn evaluate_strategy(
    queries: &[&ChunkRecord],
    dataset: &RealDataset,
    embedded: &EmbeddedDataset,
    corpus_ids: &[Uuid],
    corpus_vecs: &[Vec<f32>],
    query_extractor: fn(&context_graph_core::types::fingerprint::SemanticFingerprint) -> &Vec<f32>,
    strategy_name: &str,
) -> (f64, f64, f64) {
    use std::time::Instant;

    let mut mrr_sum = 0.0;
    let mut prec_sum = 0.0;
    let mut total_time_ms = 0.0;
    let mut count = 0;

    for query_chunk in queries.iter().take(100) { // Sample 100 queries
        let query_uuid = query_chunk.uuid();
        let query_topic = dataset.get_topic_idx(query_chunk);
        let query_doc_id = &query_chunk.doc_id;

        let Some(query_fp) = embedded.fingerprints.get(&query_uuid) else { continue };
        let query_vec = query_extractor(query_fp);
        if query_vec.is_empty() { continue; }

        // Exclude same-document chunks for fair evaluation
        let same_doc_uuids: std::collections::HashSet<Uuid> = embedded.chunk_info.iter()
            .filter(|(_, info)| &info.doc_id == query_doc_id)
            .map(|(id, _)| *id)
            .collect();

        let start = Instant::now();

        // Compute similarities (exclude same-document)
        let mut scores: Vec<(Uuid, f32)> = corpus_ids.iter()
            .zip(corpus_vecs.iter())
            .filter(|(id, _)| !same_doc_uuids.contains(id))
            .map(|(id, vec)| {
                let sim = cosine_similarity(query_vec, vec);
                (*id, sim)
            })
            .collect();

        scores.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

        total_time_ms += start.elapsed().as_secs_f64() * 1000.0;

        // Find relevant documents (same topic, different document)
        let relevant: std::collections::HashSet<Uuid> = embedded.topic_assignments.iter()
            .filter(|(id, topic)| **topic == query_topic && !same_doc_uuids.contains(id))
            .map(|(id, _)| *id)
            .collect();

        if !relevant.is_empty() {
            // MRR: reciprocal rank of first relevant
            if let Some(pos) = scores.iter().take(10).position(|(id, _)| relevant.contains(id)) {
                mrr_sum += 1.0 / (pos as f64 + 1.0);
            }

            // Precision@10: how many of top 10 are relevant
            let hits = scores.iter().take(10).filter(|(id, _)| relevant.contains(id)).count();
            prec_sum += hits as f64 / 10.0;

            count += 1;
        }
    }

    if count == 0 {
        eprintln!("[WARN] {} strategy: no valid queries evaluated", strategy_name);
        return (0.0, 0.0, 0.0);
    }

    (mrr_sum / count as f64, prec_sum / count as f64, total_time_ms / count as f64)
}

fn evaluate_pipeline_strategy(
    queries: &[&ChunkRecord],
    dataset: &RealDataset,
    embedded: &EmbeddedDataset,
) -> (f64, f64, f64) {
    use std::time::Instant;

    // Pipeline: Stage 1 (E1 recall 100) -> Stage 2 (E7 rerank to 10)
    // This simulates: sparse recall -> dense scoring -> precise rerank

    let mut e1_ids: Vec<Uuid> = Vec::new();
    let mut e1_vecs: Vec<Vec<f32>> = Vec::new();
    let mut e7_vecs: HashMap<Uuid, Vec<f32>> = HashMap::new();

    for (id, fp) in &embedded.fingerprints {
        if !fp.e1_semantic.is_empty() {
            e1_ids.push(*id);
            e1_vecs.push(fp.e1_semantic.clone());
        }
        if !fp.e7_code.is_empty() {
            e7_vecs.insert(*id, fp.e7_code.clone());
        }
    }

    if e1_ids.is_empty() {
        eprintln!("[ERROR] Pipeline: No E1 embeddings for recall stage");
        return (0.0, 0.0, 0.0);
    }

    let mut mrr_sum = 0.0;
    let mut prec_sum = 0.0;
    let mut total_time_ms = 0.0;
    let mut count = 0;

    for query_chunk in queries.iter().take(100) {
        let query_uuid = query_chunk.uuid();
        let query_topic = dataset.get_topic_idx(query_chunk);
        let query_doc_id = &query_chunk.doc_id;

        let Some(query_fp) = embedded.fingerprints.get(&query_uuid) else { continue };
        if query_fp.e1_semantic.is_empty() { continue; }

        // Exclude same-document chunks for fair evaluation
        let same_doc_uuids: std::collections::HashSet<Uuid> = embedded.chunk_info.iter()
            .filter(|(_, info)| &info.doc_id == query_doc_id)
            .map(|(id, _)| *id)
            .collect();

        let start = Instant::now();

        // Stage 1: E1 recall (top 100, excluding same-document)
        let mut stage1_scores: Vec<(Uuid, f32)> = e1_ids.iter()
            .zip(e1_vecs.iter())
            .filter(|(id, _)| !same_doc_uuids.contains(id))
            .map(|(id, vec)| {
                let sim = cosine_similarity(&query_fp.e1_semantic, vec);
                (*id, sim)
            })
            .collect();

        stage1_scores.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
        let candidates: Vec<Uuid> = stage1_scores.iter().take(100).map(|(id, _)| *id).collect();

        // Stage 2: E7 rerank (if query has E7)
        let final_scores: Vec<(Uuid, f32)> = if !query_fp.e7_code.is_empty() {
            let mut rerank_scores: Vec<(Uuid, f32)> = candidates.iter()
                .filter_map(|id| {
                    e7_vecs.get(id).map(|vec| {
                        let sim = cosine_similarity(&query_fp.e7_code, vec);
                        (*id, sim)
                    })
                })
                .collect();
            rerank_scores.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
            rerank_scores
        } else {
            // Fallback to E1 scores if no E7
            stage1_scores.into_iter().take(100).collect()
        };

        total_time_ms += start.elapsed().as_secs_f64() * 1000.0;

        // Evaluate (same topic, different document)
        let relevant: std::collections::HashSet<Uuid> = embedded.topic_assignments.iter()
            .filter(|(id, topic)| **topic == query_topic && !same_doc_uuids.contains(id))
            .map(|(id, _)| *id)
            .collect();

        if !relevant.is_empty() {
            if let Some(pos) = final_scores.iter().take(10).position(|(id, _)| relevant.contains(id)) {
                mrr_sum += 1.0 / (pos as f64 + 1.0);
            }

            let hits = final_scores.iter().take(10).filter(|(id, _)| relevant.contains(id)).count();
            prec_sum += hits as f64 / 10.0;

            count += 1;
        }
    }

    if count == 0 {
        eprintln!("[WARN] Pipeline strategy: no valid queries evaluated");
        return (0.0, 0.0, 0.0);
    }

    (mrr_sum / count as f64, prec_sum / count as f64, total_time_ms / count as f64)
}

fn generate_recommendations(
    retrieval: &RetrievalMetrics,
    clustering: &ClusteringMetrics,
    ablation: &AblationResults,
    strategies: &StrategyComparison,
) -> Vec<String> {
    let mut recommendations = Vec::new();

    // Based on retrieval metrics
    if retrieval.mrr_at_10 < 0.5 {
        recommendations.push(
            "MRR@10 is below 0.5. Consider increasing the weight of semantic embedders (E1, E5, E7)."
                .to_string(),
        );
    }

    if retrieval.recall_at_10 < 0.3 {
        recommendations.push(
            "Recall@10 is low. Consider using the pipeline strategy with sparse recall stage."
                .to_string(),
        );
    }

    // Based on clustering metrics
    if clustering.purity < 0.6 {
        recommendations.push(format!(
            "Clustering purity is {:.3}, below target 0.6. Topic detection may be unreliable - consider more training data.",
            clustering.purity
        ));
    }

    if clustering.silhouette_score < 0.2 {
        recommendations.push(format!(
            "Silhouette score is {:.3}, indicating weak cluster separation. Consider adjusting topic threshold.",
            clustering.silhouette_score
        ));
    }

    if clustering.normalized_mutual_info > 0.8 {
        recommendations.push(
            "High NMI score indicates excellent topic-embedding alignment. Multi-space search is recommended."
                .to_string(),
        );
    }

    // Based on strategy comparison
    let best_strategy = if strategies.pipeline.mrr_at_10 > strategies.multi_space.mrr_at_10 {
        "pipeline"
    } else {
        "multi_space"
    };

    recommendations.push(format!(
        "The '{}' strategy shows best MRR@10 ({:.3}). Recommend for production use.",
        best_strategy,
        if best_strategy == "pipeline" {
            strategies.pipeline.mrr_at_10
        } else {
            strategies.multi_space.mrr_at_10
        }
    ));

    // Based on ablation
    if let Some(&code_contrib) = ablation.embedder_contributions.get("E7_code") {
        if code_contrib > 0.15 {
            recommendations.push(
                "E7 (code) embedder shows high contribution. Dataset appears code-heavy."
                    .to_string(),
            );
        }
    }

    // Category analysis from ablation
    if let Some(&semantic) = ablation.category_importance.get("SEMANTIC") {
        if semantic < 0.5 {
            recommendations.push(format!(
                "SEMANTIC category contribution is only {:.1}%. Check embedder initialization.",
                semantic * 100.0
            ));
        }
    }

    if let Some(&temporal) = ablation.category_importance.get("TEMPORAL") {
        if temporal > 0.01 {
            recommendations.push(format!(
                "[WARNING] TEMPORAL embedders showing {:.1}% contribution - should be 0% per constitution AP-60.",
                temporal * 100.0
            ));
        }
    }

    recommendations
}

fn estimate_memory_usage(embedded: &EmbeddedDataset) -> f64 {
    // Rough estimate: ~58KB per fingerprint
    (embedded.fingerprints.len() as f64 * 58.0) / 1024.0
}

fn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {
    let dot: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
    let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
    let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();
    if norm_a > f32::EPSILON && norm_b > f32::EPSILON {
        dot / (norm_a * norm_b)
    } else {
        0.0
    }
}

/// MaxSim for ColBERT-style late interaction scoring.
/// For each query token, find the max similarity to any document token, then sum.
fn maxsim(query_tokens: &[Vec<f32>], doc_tokens: &[Vec<f32>]) -> f32 {
    if query_tokens.is_empty() || doc_tokens.is_empty() {
        return 0.0;
    }

    let mut total = 0.0;
    for q_token in query_tokens {
        let max_sim = doc_tokens.iter()
            .map(|d_token| cosine_similarity(q_token, d_token))
            .max_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal))
            .unwrap_or(0.0);
        total += max_sim;
    }

    total / query_tokens.len() as f32
}

// ============================================================================
// Results Saving
// ============================================================================

fn save_results(args: &Args, results: &BenchmarkResults) -> Result<(), Box<dyn std::error::Error>> {
    println!();
    println!("PHASE 4: Saving Results");
    println!("{}", "-".repeat(70));

    // Create output directory if needed
    if let Some(parent) = args.output_path.parent() {
        fs::create_dir_all(parent)?;
    }

    // Save JSON results
    let file = File::create(&args.output_path)?;
    let writer = BufWriter::new(file);
    serde_json::to_writer_pretty(writer, results)?;
    println!("  Results saved to: {}", args.output_path.display());

    // Generate markdown report
    let report_path = args.output_path.with_extension("md");
    generate_markdown_report(&report_path, results)?;
    println!("  Report saved to: {}", report_path.display());

    Ok(())
}

fn generate_markdown_report(
    path: &Path,
    results: &BenchmarkResults,
) -> Result<(), Box<dyn std::error::Error>> {
    let mut f = File::create(path)?;

    writeln!(f, "# HuggingFace Benchmark Report")?;
    writeln!(f)?;
    writeln!(f, "**Generated:** {}", results.timestamp)?;
    writeln!(f)?;

    // Dataset Info
    writeln!(f, "## Dataset Information")?;
    writeln!(f)?;
    writeln!(f, "| Metric | Value |")?;
    writeln!(f, "|--------|-------|")?;
    writeln!(f, "| Total Chunks | {} |", results.dataset_info.total_chunks)?;
    writeln!(f, "| Total Documents | {} |", results.dataset_info.total_documents)?;
    writeln!(f, "| Topic Count | {} |", results.dataset_info.topic_count)?;
    writeln!(f, "| Source Datasets | {} |", results.dataset_info.source_datasets.join(", "))?;
    writeln!(f)?;

    // Retrieval Metrics
    writeln!(f, "## Retrieval Metrics")?;
    writeln!(f)?;
    writeln!(f, "| Metric | Value |")?;
    writeln!(f, "|--------|-------|")?;
    writeln!(f, "| MRR@10 | {:.4} |", results.retrieval_metrics.mrr_at_10)?;
    writeln!(f, "| P@1 | {:.4} |", results.retrieval_metrics.precision_at_1)?;
    writeln!(f, "| P@5 | {:.4} |", results.retrieval_metrics.precision_at_5)?;
    writeln!(f, "| P@10 | {:.4} |", results.retrieval_metrics.precision_at_10)?;
    writeln!(f, "| R@10 | {:.4} |", results.retrieval_metrics.recall_at_10)?;
    writeln!(f, "| R@50 | {:.4} |", results.retrieval_metrics.recall_at_50)?;
    writeln!(f, "| NDCG@10 | {:.4} |", results.retrieval_metrics.ndcg_at_10)?;
    writeln!(f)?;

    // Strategy Comparison
    writeln!(f, "## Strategy Comparison")?;
    writeln!(f)?;
    writeln!(f, "| Strategy | MRR@10 | P@10 | Avg Query Time (ms) |")?;
    writeln!(f, "|----------|--------|------|---------------------|")?;
    writeln!(
        f,
        "| E1 Only | {:.4} | {:.4} | {:.2} |",
        results.strategy_comparison.e1_only.mrr_at_10,
        results.strategy_comparison.e1_only.precision_at_10,
        results.strategy_comparison.e1_only.avg_query_time_ms
    )?;
    writeln!(
        f,
        "| Multi-Space | {:.4} | {:.4} | {:.2} |",
        results.strategy_comparison.multi_space.mrr_at_10,
        results.strategy_comparison.multi_space.precision_at_10,
        results.strategy_comparison.multi_space.avg_query_time_ms
    )?;
    writeln!(
        f,
        "| Pipeline | {:.4} | {:.4} | {:.2} |",
        results.strategy_comparison.pipeline.mrr_at_10,
        results.strategy_comparison.pipeline.precision_at_10,
        results.strategy_comparison.pipeline.avg_query_time_ms
    )?;
    writeln!(f)?;

    // Recommendations
    writeln!(f, "## Recommendations")?;
    writeln!(f)?;
    for rec in &results.recommendations {
        writeln!(f, "- {}", rec)?;
    }
    writeln!(f)?;

    writeln!(f, "---")?;
    writeln!(f, "*Generated with context-graph-benchmark hf-bench*")?;

    Ok(())
}

fn generate_report(args: &Args) -> Result<(), Box<dyn std::error::Error>> {
    let input_path = args
        .input_results
        .as_ref()
        .ok_or("--input is required for --generate-report")?;

    println!("Loading results from: {}", input_path.display());

    let file = File::open(input_path)?;
    let results: BenchmarkResults = serde_json::from_reader(file)?;

    let report_path = input_path.with_extension("md");
    generate_markdown_report(&report_path, &results)?;

    println!("Report generated: {}", report_path.display());

    Ok(())
}

fn print_summary(results: &BenchmarkResults) {
    println!();
    println!("=======================================================================");
    println!("  Benchmark Summary");
    println!("=======================================================================");
    println!();
    println!("Dataset: {} chunks across {} topics",
             results.dataset_info.total_chunks,
             results.dataset_info.topic_count);
    println!();
    println!("Retrieval Performance:");
    println!("  MRR@10:    {:.4}", results.retrieval_metrics.mrr_at_10);
    println!("  P@10:      {:.4}", results.retrieval_metrics.precision_at_10);
    println!("  R@10:      {:.4}", results.retrieval_metrics.recall_at_10);
    println!("  NDCG@10:   {:.4}", results.retrieval_metrics.ndcg_at_10);
    println!();
    println!("Best Strategy: {} (MRR@10: {:.4})",
             results.strategy_comparison.pipeline.strategy,
             results.strategy_comparison.pipeline.mrr_at_10);
    println!();
    println!("Recommendations:");
    for rec in &results.recommendations {
        println!("  - {}", rec);
    }
}
