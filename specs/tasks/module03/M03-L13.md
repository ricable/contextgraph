# M03-L13: EntityModel (E11 - all-MiniLM-L6-v2)

## Task Summary

Implement `EntityModel` for named entity embeddings using `sentence-transformers/all-MiniLM-L6-v2`. This model produces 384D vectors optimized for entity mentions and TransE-style knowledge graph operations where `head + relation ≈ tail`.

**File to create**: `crates/context-graph-embeddings/src/models/pretrained/entity.rs`

---

## Critical Context

### Codebase State (as of 2026-01-01)

The following models are **already implemented** and working:
- `SemanticModel` (E1) - 1024D - `pretrained/semantic.rs`
- `TemporalRecentModel` (E2) - 512D - `custom/temporal_recent.rs`
- `TemporalPeriodicModel` (E3) - 512D - `custom/temporal_periodic.rs`
- `TemporalPositionalModel` (E4) - 512D - `custom/temporal_positional.rs`
- `CausalModel` (E5) - 768D - `pretrained/causal.rs`
- `SparseModel` (E6) - 30522D sparse → 1536D projected - `pretrained/sparse.rs`
- `CodeModel` (E7) - 256D → 768D projected - `pretrained/code.rs`
- `GraphModel` (E8) - 384D - `pretrained/graph.rs`
- `HdcModel` (E9) - 10000-bit → 1024D projected - `custom/hdc.rs`

**NOT YET IMPLEMENTED**:
- `MultimodalModel` (E10) - M03-L12 - openai/clip-vit-large-patch14 - 768D
- `EntityModel` (E11) - **THIS TASK** - sentence-transformers/all-MiniLM-L6-v2 - 384D
- `LateInteractionModel` (E12) - M03-L14 - colbert-ir/colbertv2.0 - 128D/token

**Pattern to follow**: `GraphModel` in `crates/context-graph-embeddings/src/models/pretrained/graph.rs` uses the same MiniLM architecture and is the closest reference implementation. Copy its structure exactly.

### Key Differences: EntityModel vs GraphModel

| Aspect | GraphModel (E8) | EntityModel (E11) |
|--------|-----------------|-------------------|
| HuggingFace Repo | `paraphrase-MiniLM-L6-v2` | `all-MiniLM-L6-v2` |
| Dimension | 384D | 384D |
| Latency Target | 5ms | 2ms |
| Max Tokens | 512 | 512 |
| Tokenizer Family | BertWordpiece | BertWordpiece |
| Primary Use | Relation encoding | Entity + TransE ops |
| Special Methods | `encode_relation`, `encode_context` | `encode_entity`, `transe_score`, `predict_tail`, `predict_relation` |

### ModelId Specification (Source of Truth: types/model_id.rs)

```rust
// From crates/context-graph-embeddings/src/types/model_id.rs
Entity = 10,                                                    // Enum value
Self::Entity => 384,                                            // dimension()
Self::Entity => 384,                                            // projected_dimension()
Self::Entity => Some("sentence-transformers/all-MiniLM-L6-v2"), // model_repo()
Self::Entity => "entity",                                       // directory_name()
Self::Entity => TokenizerFamily::BertWordpiece,                 // tokenizer_family()
Self::Entity => 2,                                              // latency_budget_ms()
_ => 512,                                                       // max_tokens() (BERT default)
```

---

## Exact File Locations

```
crates/context-graph-embeddings/
├── src/
│   ├── models/
│   │   ├── pretrained/
│   │   │   ├── mod.rs           # UPDATE: add entity module export
│   │   │   ├── graph.rs         # REFERENCE: copy structure from here (45+ tests, 1100+ lines)
│   │   │   └── entity.rs        # CREATE: this file
│   │   ├── custom/
│   │   │   ├── hdc.rs           # REFERENCE: shows custom model pattern
│   │   │   └── ...
│   │   └── mod.rs
│   ├── traits/
│   │   └── embedding_model.rs   # REFERENCE: EmbeddingModel trait to implement
│   ├── types/
│   │   └── model_id.rs          # ALREADY DEFINED: ModelId::Entity = 10, dim=384
│   ├── error.rs                 # REFERENCE: EmbeddingError types
│   └── lib.rs
└── Cargo.toml
```

### Currently Exported in pretrained/mod.rs

```rust
mod causal;
mod code;
mod graph;
mod semantic;
mod sparse;

pub use causal::{...};
pub use code::{...};
pub use graph::{...};
pub use semantic::{...};
pub use sparse::{...};
```

**You must add**:
```rust
mod entity;

pub use entity::{
    EntityModel,
    ENTITY_DIMENSION,
    ENTITY_LATENCY_BUDGET_MS,
    ENTITY_MAX_TOKENS,
    ENTITY_MODEL_NAME,
};
```

---

## Implementation Specification

### Constants (Required - at top of file)

```rust
/// Native dimension for all-MiniLM entity embeddings.
pub const ENTITY_DIMENSION: usize = 384;

/// Maximum tokens for MiniLM (standard BERT-family limit).
pub const ENTITY_MAX_TOKENS: usize = 512;

/// Latency budget in milliseconds (P95 target).
pub const ENTITY_LATENCY_BUDGET_MS: u64 = 2;

/// HuggingFace model repository name.
pub const ENTITY_MODEL_NAME: &str = "sentence-transformers/all-MiniLM-L6-v2";
```

### Required Imports

```rust
use std::path::{Path, PathBuf};
use std::sync::atomic::{AtomicBool, Ordering};

use async_trait::async_trait;
use rand::rngs::StdRng;
use rand::{Rng, SeedableRng};

use crate::error::{EmbeddingError, EmbeddingResult};
use crate::traits::{EmbeddingModel, SingleModelConfig};
use crate::types::{InputType, ModelEmbedding, ModelId, ModelInput};
```

### Struct Definition (Copy from GraphModel pattern)

```rust
/// Internal state that varies based on feature flags.
#[allow(dead_code)]
enum ModelState {
    /// Unloaded - no weights in memory.
    Unloaded,

    /// Loaded with candle model and tokenizer (candle feature).
    #[cfg(feature = "candle")]
    Loaded {
        // TODO: candle model and tokenizer fields
    },

    /// Stub for testing without real weights.
    #[cfg(not(feature = "candle"))]
    Stub,
}

/// Entity embedding model using sentence-transformers/all-MiniLM-L6-v2.
pub struct EntityModel {
    /// Model weights and inference engine.
    #[allow(dead_code)]
    model_state: std::sync::RwLock<ModelState>,

    /// Path to model weights directory.
    #[allow(dead_code)]
    model_path: PathBuf,

    /// Configuration for this model instance.
    #[allow(dead_code)]
    config: SingleModelConfig,

    /// Whether model weights are loaded and ready.
    loaded: AtomicBool,

    /// Memory used by model weights (bytes).
    #[allow(dead_code)]
    memory_size: usize,
}
```

### Required Methods

#### Constructor
```rust
pub fn new(model_path: &Path, config: SingleModelConfig) -> EmbeddingResult<Self>
```
- Returns `EmbeddingError::ConfigError` if `config.max_batch_size == 0`

#### Entity Encoding (Static method)
```rust
/// Encode an entity with optional type context.
/// Examples:
///   encode_entity("Alice", Some("PERSON")) => "[PERSON] Alice"
///   encode_entity("Anthropic", Some("ORG")) => "[ORG] Anthropic"
///   encode_entity("Paris", None) => "Paris"
pub fn encode_entity(name: &str, entity_type: Option<&str>) -> String {
    match entity_type {
        Some(etype) => format!("[{}] {}", etype.to_uppercase(), name),
        None => name.to_string(),
    }
}
```

#### Relation Encoding (Static method)
```rust
/// Encode a relation for TransE-style operations.
/// Example: encode_relation("works_at") => "works at"
pub fn encode_relation(relation: &str) -> String {
    relation.replace('_', " ")
}
```

#### TransE Operations (Static Methods)
```rust
/// TransE scoring: score = -||h + r - t||₂
/// Higher score = more likely valid triple.
/// Returns negative L2 distance (0 = perfect, negative = worse).
pub fn transe_score(head: &[f32], relation: &[f32], tail: &[f32]) -> f32 {
    assert_eq!(head.len(), ENTITY_DIMENSION);
    assert_eq!(relation.len(), ENTITY_DIMENSION);
    assert_eq!(tail.len(), ENTITY_DIMENSION);

    let sum_sq: f32 = head.iter()
        .zip(relation.iter())
        .zip(tail.iter())
        .map(|((h, r), t)| {
            let diff = h + r - t;
            diff * diff
        })
        .sum();

    -sum_sq.sqrt()
}

/// Predict tail entity embedding: t̂ = h + r
pub fn predict_tail(head: &[f32], relation: &[f32]) -> Vec<f32> {
    assert_eq!(head.len(), ENTITY_DIMENSION);
    assert_eq!(relation.len(), ENTITY_DIMENSION);

    head.iter().zip(relation.iter()).map(|(h, r)| h + r).collect()
}

/// Predict relation embedding: r̂ = t - h
pub fn predict_relation(head: &[f32], tail: &[f32]) -> Vec<f32> {
    assert_eq!(head.len(), ENTITY_DIMENSION);
    assert_eq!(tail.len(), ENTITY_DIMENSION);

    tail.iter().zip(head.iter()).map(|(t, h)| t - h).collect()
}
```

#### Lifecycle Methods
```rust
pub async fn load(&self) -> EmbeddingResult<()>;
pub async fn unload(&self) -> EmbeddingResult<()>;
pub async fn embed_batch(&self, inputs: &[ModelInput]) -> EmbeddingResult<Vec<ModelEmbedding>>;
```

### EmbeddingModel Trait Implementation

```rust
#[async_trait]
impl EmbeddingModel for EntityModel {
    fn model_id(&self) -> ModelId { ModelId::Entity }
    fn supported_input_types(&self) -> &[InputType] { &[InputType::Text] }
    fn is_initialized(&self) -> bool { self.loaded.load(Ordering::SeqCst) }

    async fn embed(&self, input: &ModelInput) -> EmbeddingResult<ModelEmbedding> {
        // 1. Check initialized (return NotInitialized error if not)
        // 2. Validate input type via validate_input()
        // 3. Extract text content
        // 4. Generate 384D embedding using generate_deterministic_embedding()
        // 5. Return ModelEmbedding with ModelId::Entity
    }
}

// Thread safety - required
unsafe impl Send for EntityModel {}
unsafe impl Sync for EntityModel {}
```

### Deterministic Embedding Generation (Stub mode)

```rust
#[cfg(not(feature = "candle"))]
fn generate_deterministic_embedding(text: &str) -> Vec<f32> {
    use rand::{Rng, SeedableRng};
    use rand::rngs::StdRng;

    let hash = xxhash_rust::xxh64::xxh64(text.as_bytes(), 0);
    let mut rng = StdRng::seed_from_u64(hash);

    let mut vector: Vec<f32> = (0..ENTITY_DIMENSION)
        .map(|_| rng.gen_range(-1.0..1.0))
        .collect();

    // L2 normalize to unit vector
    let norm: f32 = vector.iter().map(|x| x * x).sum::<f32>().sqrt();
    if norm > f32::EPSILON {
        for v in &mut vector {
            *v /= norm;
        }
    }

    vector
}
```

### Helper for ModelInput Text Extraction

```rust
/// Extract text content from ModelInput.
fn extract_content(input: &ModelInput) -> EmbeddingResult<&str> {
    match input {
        ModelInput::Text { content } => Ok(content.as_str()),
        _ => Err(EmbeddingError::UnsupportedModality {
            expected: "text".to_string(),
            got: format!("{:?}", input.input_type()),
        }),
    }
}
```

---

## Verification Requirements

### Full State Verification (MANDATORY)

Every test MUST include before/after state logging:

1. **Source of Truth**: Print actual values from `ModelEmbedding.vector` - never rely on assumptions
2. **Execute & Inspect**: Run actual code paths and print intermediate results
3. **Edge Cases**: Test boundary conditions with explicit state logging
4. **Evidence of Success**: Print comprehensive output proving implementation works

### Source of Truth (types/model_id.rs)

The **Source of Truth** for this implementation is:
1. `ModelId::Entity` in `types/model_id.rs` - dimension=384, latency_budget_ms=2
2. Embedding vectors stored in `ModelEmbedding.vector`
3. Test assertions verifying vector properties

### Mandatory Test Categories (minimum 40 tests)

#### 1. Construction Tests (2 tests)
- `test_new_creates_unloaded_model`
- `test_new_with_zero_batch_size_fails`

#### 2. Trait Implementation Tests (8 tests)
- `test_model_id` - returns `ModelId::Entity`
- `test_native_dimension` - returns 384
- `test_projected_dimension_equals_native` - returns 384 (no projection)
- `test_max_tokens` - returns 512
- `test_latency_budget_ms` - returns 2
- `test_is_pretrained` - returns true
- `test_supported_input_types` - contains only `InputType::Text`
- `test_model_id_matches_constants`

#### 3. State Transition Tests (4 tests)
- `test_load_sets_initialized`
- `test_unload_clears_initialized`
- `test_unload_when_not_loaded_fails`
- `test_state_transitions_full_cycle`

#### 4. Embedding Tests (10 tests)
- `test_embed_before_load_fails`
- `test_embed_text_returns_384d`
- `test_embed_returns_l2_normalized_vector`
- `test_embed_no_nan_values`
- `test_embed_no_inf_values`
- `test_embed_deterministic`
- `test_embed_different_inputs_differ`
- `test_embed_model_id_is_entity`
- `test_embed_latency_under_budget`
- `test_embed_encoded_entity`

#### 5. Entity Encoding Tests (5 tests)
- `test_encode_entity_with_type`
- `test_encode_entity_without_type`
- `test_encode_entity_uppercase_type`
- `test_encode_entity_lowercase_type_converted`
- `test_encode_relation_replaces_underscores`

#### 6. TransE Operation Tests (4 tests)
- `test_transe_score_perfect_triple`
- `test_transe_score_imperfect_triple`
- `test_predict_tail_correctness`
- `test_predict_relation_correctness`

#### 7. Batch Tests (2 tests)
- `test_embed_batch_multiple_inputs`
- `test_embed_batch_before_load_fails`

#### 8. Thread Safety Tests (1 test)
- `test_concurrent_embed_calls`

#### 9. Constants Tests (3 tests)
- `test_constants_are_correct`
- `test_model_id_dimension_matches_constant`
- `test_model_id_latency_matches_constant`

#### 10. Edge Case Tests (5 tests)
- `test_edge_case_1_empty_text_content`
- `test_edge_case_2_long_entity_name`
- `test_edge_case_3_unsupported_modality_code`
- `test_edge_case_4_unsupported_modality_image`
- `test_edge_case_5_special_characters`

---

## Edge Cases (MANDATORY - Print Before/After State)

### Edge Case 1: Empty Text Content
```rust
#[tokio::test]
async fn test_edge_case_1_empty_text_content() {
    let model = create_and_load_model().await;

    println!("=== EDGE CASE 1: Empty Text Content ===");
    println!("BEFORE: model initialized = {}", model.is_initialized());

    let result = ModelInput::text("");
    assert!(result.is_err(), "Empty text string should error on ModelInput::text");

    // Whitespace should work
    let input = ModelInput::text(" ").expect("Whitespace input should work");
    let result = model.embed(&input).await;

    println!("AFTER: result = {:?}", result.is_ok());
    assert!(result.is_ok());
    println!("AFTER: vector.len() = {}", result.unwrap().vector.len());
}
```

### Edge Case 2: Long Entity Name
```rust
#[tokio::test]
async fn test_edge_case_2_long_entity_name() {
    let model = create_and_load_model().await;

    let long_name = "Entity ".repeat(200);

    println!("=== EDGE CASE 2: Long Entity Name ===");
    println!("BEFORE: name length = {} chars", long_name.len());

    let encoded = EntityModel::encode_entity(&long_name, Some("THING"));
    let input = ModelInput::text(&encoded).expect("Input");
    let result = model.embed(&input).await;

    println!("AFTER: result.is_ok() = {}", result.is_ok());
    assert!(result.is_ok());
    assert_eq!(result.unwrap().vector.len(), 384);
}
```

### Edge Case 3: Unsupported Modality (Code)
```rust
#[tokio::test]
async fn test_edge_case_3_unsupported_modality_code() {
    let model = create_and_load_model().await;

    println!("=== EDGE CASE 3: Unsupported Modality (Code) ===");
    println!("BEFORE: model supports Text only");

    let input = ModelInput::code("fn main() {}", "rust").expect("Code input");
    let result = model.embed(&input).await;

    println!("AFTER: result = {:?}", result);
    assert!(matches!(result, Err(EmbeddingError::UnsupportedModality { .. })));
}
```

### Edge Case 4: Unsupported Modality (Image)
```rust
#[tokio::test]
async fn test_edge_case_4_unsupported_modality_image() {
    let model = create_and_load_model().await;

    println!("=== EDGE CASE 4: Unsupported Modality (Image) ===");
    println!("BEFORE: model supports Text only");

    let input = ModelInput::image(vec![0u8; 100], "image/png").expect("Image input");
    let result = model.embed(&input).await;

    println!("AFTER: result = {:?}", result);
    assert!(matches!(result, Err(EmbeddingError::UnsupportedModality { .. })));
}
```

### Edge Case 5: Special Characters
```rust
#[tokio::test]
async fn test_edge_case_5_special_characters() {
    let model = create_and_load_model().await;

    let special_text = "[PERSON] Alice & Bob <Anthropic> \"Test\" 'Single' \n\t Unicode: ";

    println!("=== EDGE CASE 5: Special Characters ===");
    println!("BEFORE: text = {:?}", special_text);

    let input = ModelInput::text(special_text).expect("Special input");
    let result = model.embed(&input).await;

    println!("AFTER: result.is_ok() = {}", result.is_ok());
    assert!(result.is_ok());

    let emb = result.unwrap();
    let has_nan = emb.vector.iter().any(|x| x.is_nan());
    let has_inf = emb.vector.iter().any(|x| x.is_infinite());
    println!("AFTER: has_nan = {}, has_inf = {}", has_nan, has_inf);
    assert!(!has_nan && !has_inf);
}
```

---

## Source of Truth Verification Test

```rust
#[tokio::test]
async fn test_source_of_truth_verification() {
    let model = create_and_load_model().await;
    let input = ModelInput::text("[PERSON] Alice").expect("Input");

    let embedding = model.embed(&input).await.expect("Embed should succeed");

    // INSPECT SOURCE OF TRUTH
    println!("=== SOURCE OF TRUTH VERIFICATION ===");
    println!("model_id: {:?}", embedding.model_id);
    println!("vector.len(): {}", embedding.vector.len());
    println!("vector[0..10]: {:?}", &embedding.vector[0..10]);
    println!("latency_us: {}", embedding.latency_us);

    let norm: f32 = embedding.vector.iter().map(|x| x * x).sum::<f32>().sqrt();
    println!("L2 norm: {}", norm);

    let has_nan = embedding.vector.iter().any(|x| x.is_nan());
    let has_inf = embedding.vector.iter().any(|x| x.is_infinite());
    println!("has_nan: {}, has_inf: {}", has_nan, has_inf);

    // VERIFY AGAINST SOURCE OF TRUTH (types/model_id.rs)
    assert_eq!(embedding.model_id, ModelId::Entity);
    assert_eq!(embedding.vector.len(), 384);  // ModelId::Entity.dimension()
    assert!((norm - 1.0).abs() < 0.001, "Must be L2 normalized");
    assert!(!has_nan && !has_inf, "No NaN or Inf values");
}
```

---

## Evidence of Success Test

```rust
#[tokio::test]
async fn test_evidence_of_success() {
    println!("\n========================================");
    println!("M03-L13 EVIDENCE OF SUCCESS");
    println!("========================================\n");

    let model = create_and_load_model().await;

    // 1. Model metadata
    println!("1. MODEL METADATA:");
    println!("   model_id = {:?}", model.model_id());
    println!("   dimension = {}", ModelId::Entity.dimension());
    println!("   projected_dimension = {}", ModelId::Entity.projected_dimension());
    println!("   max_tokens = {}", ModelId::Entity.max_tokens());
    println!("   is_initialized = {}", model.is_initialized());
    println!("   is_pretrained = {}", ModelId::Entity.is_pretrained());
    println!("   latency_budget_ms = {}", ModelId::Entity.latency_budget_ms());
    println!("   supported_types = {:?}", model.supported_input_types());

    // 2. Entity encoding
    println!("\n2. ENTITY ENCODING:");
    let encoded = EntityModel::encode_entity("Alice", Some("person"));
    println!("   encode_entity(\"Alice\", Some(\"person\")) = \"{}\"", encoded);
    assert_eq!(encoded, "[PERSON] Alice");

    let rel = EntityModel::encode_relation("works_at");
    println!("   encode_relation(\"works_at\") = \"{}\"", rel);
    assert_eq!(rel, "works at");

    // 3. Embed and verify
    let input = ModelInput::text(&encoded).expect("Input");
    let start = std::time::Instant::now();
    let embedding = model.embed(&input).await.expect("Embed");
    let elapsed = start.elapsed();

    println!("\n3. EMBEDDING OUTPUT:");
    println!("   vector length = {}", embedding.vector.len());
    println!("   latency = {:?}", elapsed);
    println!("   first 10 values = {:?}", &embedding.vector[0..10]);

    let norm: f32 = embedding.vector.iter().map(|x| x * x).sum::<f32>().sqrt();
    println!("   L2 norm = {}", norm);

    // 4. TransE operations
    println!("\n4. TRANSE OPERATIONS:");
    let h: Vec<f32> = (0..384).map(|i| (i as f32 / 384.0)).collect();
    let r: Vec<f32> = (0..384).map(|i| 0.1 * (i as f32 / 384.0)).collect();
    let t: Vec<f32> = h.iter().zip(&r).map(|(a, b)| a + b).collect();

    let score = EntityModel::transe_score(&h, &r, &t);
    println!("   transe_score(h, r, h+r) = {} (should be ~0)", score);
    assert!(score.abs() < 1e-5);

    let predicted_t = EntityModel::predict_tail(&h, &r);
    let predicted_r = EntityModel::predict_relation(&h, &t);
    println!("   predict_tail matches = {}", predicted_t == t);
    println!("   predict_relation matches = {}", predicted_r == r);

    // 5. Determinism
    println!("\n5. DETERMINISM CHECK:");
    let emb2 = model.embed(&input).await.unwrap();
    println!("   same input same output = {}", embedding.vector == emb2.vector);

    println!("\n========================================");
    println!("ALL CHECKS PASSED");
    println!("========================================\n");

    // Final assertions
    assert_eq!(embedding.vector.len(), 384);
    assert!((norm - 1.0).abs() < 0.001);
}
```

---

## Validation Commands

```bash
# 1. Check compilation
cargo check -p context-graph-embeddings

# 2. Run all entity tests
cargo test -p context-graph-embeddings entity -- --nocapture

# 3. Run verification tests
cargo test -p context-graph-embeddings test_source_of_truth_verification -- --nocapture
cargo test -p context-graph-embeddings test_evidence_of_success -- --nocapture

# 4. Run all embedding tests
cargo test -p context-graph-embeddings --lib

# 5. Check for clippy warnings
cargo clippy -p context-graph-embeddings -- -D warnings
```

---

## DO NOT DO

1. **NO mock data** - Use real deterministic embeddings from xxhash seeding
2. **NO fallbacks** - If something fails, return proper `EmbeddingError`, don't work around it
3. **NO backwards compatibility hacks** - Clean implementation only
4. **NO dimension projection** - Entity outputs 384D directly (unlike Code/Sparse)
5. **NO memory_usage_bytes() or warmup_complete()** - These are NOT in the trait
6. **NO is_loaded()** - The method is called `is_initialized()` in the trait
7. **NO guessing file paths** - Verify against actual codebase structure shown above
8. **NO assumptions about trait methods** - Check `traits/embedding_model.rs` for exact signatures

---

## Final Verification Step

**MANDATORY**: After completing implementation, use `sherlock-holmes` subagent to verify:

1. `cargo check -p context-graph-embeddings` passes with no errors
2. `cargo test -p context-graph-embeddings entity` - all 40+ tests pass
3. Module exports added to `pretrained/mod.rs`
4. `ModelId::Entity` dimension (384) matches implementation
5. TransE operations are mathematically correct
6. Edge cases return appropriate errors (not panics)
7. No clippy warnings on new code

```bash
# Sherlock verification command
cargo test -p context-graph-embeddings entity -- --nocapture 2>&1 | head -100
cargo clippy -p context-graph-embeddings -- -D warnings 2>&1 | head -50
```

---

## Completion Checklist

- [x] `entity.rs` created at `crates/context-graph-embeddings/src/models/pretrained/entity.rs`
- [x] Constants defined: `ENTITY_DIMENSION`, `ENTITY_MAX_TOKENS`, `ENTITY_LATENCY_BUDGET_MS`, `ENTITY_MODEL_NAME`
- [x] `EntityModel` struct with `model_state`, `model_path`, `config`, `loaded`, `memory_size`
- [x] `ModelState` enum with `Unloaded`, `Stub` variants
- [x] `new()` constructor with zero batch size validation
- [x] `encode_entity()` static method - uppercases type
- [x] `encode_relation()` static method - replaces underscores
- [x] `transe_score()` static method - returns negative L2 distance
- [x] `predict_tail()` static method - returns h + r
- [x] `predict_relation()` static method - returns t - h
- [x] `load()` async method - sets `loaded` to true
- [x] `unload()` async method - checks initialized first, sets `loaded` to false
- [x] `embed_batch()` async method
- [x] `EmbeddingModel` trait: `model_id()`, `supported_input_types()`, `is_initialized()`, `embed()`
- [x] `Send + Sync` implemented
- [x] `generate_deterministic_embedding()` helper using xxhash + L2 normalization
- [x] `extract_content()` helper for ModelInput text extraction
- [x] Module exported in `pretrained/mod.rs`
- [x] 40+ tests written and passing (46 tests)
- [x] 5 edge case tests with before/after logging
- [x] Source of truth verification test
- [x] Evidence of success test
- [x] `cargo check` passes
- [x] `cargo test` passes
- [x] `cargo clippy` passes
- [x] Sherlock-holmes verification complete

---

## Implementation Complete - 2026-01-01

**Sherlock-Holmes Verification Result**: INNOCENT - All requirements verified

**Summary**:
- EntityModel (E11) implemented with sentence-transformers/all-MiniLM-L6-v2
- 384D native dimension (no projection)
- Text-only input support with <2ms latency budget
- TransE operations: transe_score(), predict_tail(), predict_relation()
- encode_entity() correctly uppercases type: "[TYPE] name"
- encode_relation() replaces underscores with spaces
- 46 tests passing (exceeds 40 minimum)
- No clippy warnings
- Thread-safe (Send + Sync)
