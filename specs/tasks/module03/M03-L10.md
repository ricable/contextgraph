# M03-L10: Graph Model (E8 - MiniLM)

```xml
<task_spec id="M03-L10" version="2.0">
<metadata>
  <title>Implement Graph Model for Structural Relations</title>
  <status>complete</status>
  <layer>logic</layer>
  <sequence>10</sequence>
  <implements>PRD E8 - Graph-GNN embedding with message passing</implements>
  <depends_on>M03-F09, M03-L01</depends_on>
  <estimated_hours>3</estimated_hours>
</metadata>

<source_of_truth>
  <!-- VERIFIED from model_id.rs - the canonical source -->
  <file>crates/context-graph-embeddings/src/types/model_id.rs</file>
  <verified_values>
    <value name="ModelId">Graph = 7</value>
    <value name="dimension">384</value>
    <value name="projected_dimension">384 (no projection needed)</value>
    <value name="max_tokens">512 (default BERT-family)</value>
    <value name="latency_budget_ms">5</value>
    <value name="model_repo">sentence-transformers/paraphrase-MiniLM-L6-v2</value>
    <value name="tokenizer_family">BertWordpiece</value>
    <value name="model_dir">graph</value>
    <value name="display_name">Graph (E8)</value>
  </verified_values>
</source_of_truth>

<context>
Implement graph embedding using sentence-transformers/paraphrase-MiniLM-L6-v2.
This model is used for encoding structural and relational information in the
knowledge graph. Optimized for short relation descriptions and entity contexts.

Output: 384D dense vector (no projection layer needed - native dimension matches target).
Latency target: less than 5ms.

The model is efficient due to knowledge distillation from larger models,
making it ideal for high-throughput relation encoding.

IMPORTANT: Unlike CodeModel which requires projection (256D → 768D), GraphModel
outputs 384D natively which matches our target dimension. No projection layer needed.
</context>

<definition_of_done>
  <constants>
```rust
/// Graph model embedding dimension (native MiniLM output).
/// Unlike CodeModel, no projection is needed - 384D is the final output.
pub const GRAPH_DIMENSION: usize = 384;

/// Maximum tokens for MiniLM model (BERT-family default).
/// Optimized for short relation descriptions and entity contexts.
pub const GRAPH_MAX_TOKENS: usize = 512;

/// Latency budget per embedding operation in milliseconds.
pub const GRAPH_LATENCY_BUDGET_MS: u64 = 5;

/// HuggingFace model repository for Graph model.
pub const GRAPH_MODEL_NAME: &str = "sentence-transformers/paraphrase-MiniLM-L6-v2";

/// Maximum neighbors to include in context encoding.
pub const MAX_CONTEXT_NEIGHBORS: usize = 5;
```
  </constants>

  <signatures>
```rust
use std::path::Path;
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::RwLock;
use async_trait::async_trait;

use crate::error::{EmbeddingError, EmbeddingResult};
use crate::traits::EmbeddingModel;
use crate::types::{InputType, ModelEmbedding, ModelId, ModelInput};
use crate::config::SingleModelConfig;

/// Internal state for the Graph model.
enum ModelState {
    /// Model not yet loaded
    Unloaded,
    /// Model loaded and ready (stub or real)
    Loaded {
        /// Memory usage in bytes
        memory_bytes: usize,
    },
}

/// Graph embedding model using MiniLM for structural relation encoding.
///
/// This model encodes graph relationships (subject-predicate-object triples)
/// and node contexts for knowledge graph operations.
///
/// # Architecture
/// - Uses `sentence-transformers/paraphrase-MiniLM-L6-v2`
/// - 6-layer transformer with knowledge distillation
/// - 384D output dimension (native, no projection needed)
/// - BertWordpiece tokenizer
///
/// # Thread Safety
/// Uses `RwLock<ModelState>` for safe concurrent access.
/// The `loaded` `AtomicBool` provides lock-free status checks.
pub struct GraphModel {
    /// Model state (unloaded or loaded with memory info)
    state: RwLock<ModelState>,
    /// Atomic flag for lock-free loaded checks
    loaded: AtomicBool,
    /// Model configuration
    config: SingleModelConfig,
    /// Path to models directory
    models_dir: PathBuf,
}

impl GraphModel {
    /// Creates a new GraphModel instance.
    ///
    /// # Arguments
    /// * `models_dir` - Path to the models directory containing graph/ subfolder
    /// * `config` - Model configuration
    ///
    /// # Errors
    /// Returns `EmbeddingError::InvalidConfig` if configuration is invalid.
    ///
    /// # Panics
    /// Never panics - all errors are returned as Results.
    pub fn new(models_dir: &Path, config: SingleModelConfig) -> EmbeddingResult<Self>;

    /// Encodes a relation triple as text for embedding.
    ///
    /// # Arguments
    /// * `subject` - The subject entity (e.g., "Alice")
    /// * `predicate` - The relationship (e.g., "works_at")
    /// * `object` - The object entity (e.g., "Anthropic")
    ///
    /// # Returns
    /// Formatted string: "subject predicate object"
    /// Underscores in predicates are replaced with spaces.
    ///
    /// # Example
    /// ```rust
    /// let text = model.encode_relation("Alice", "works_at", "Anthropic");
    /// assert_eq!(text, "Alice works at Anthropic");
    /// ```
    pub fn encode_relation(&self, subject: &str, predicate: &str, object: &str) -> String;

    /// Encodes graph context around a node.
    ///
    /// # Arguments
    /// * `node` - The central node entity
    /// * `neighbors` - Slice of (relation, neighbor) pairs
    ///
    /// # Returns
    /// Formatted string: "node: rel1 neighbor1, rel2 neighbor2, ..."
    /// Limited to MAX_CONTEXT_NEIGHBORS (5) neighbors for token budget.
    ///
    /// # Example
    /// ```rust
    /// let neighbors = vec![
    ///     ("works_at".to_string(), "Anthropic".to_string()),
    ///     ("lives_in".to_string(), "SF".to_string()),
    /// ];
    /// let text = model.encode_context("Alice", &neighbors);
    /// assert_eq!(text, "Alice: works at Anthropic, lives in SF");
    /// ```
    pub fn encode_context(&self, node: &str, neighbors: &[(String, String)]) -> String;
}

#[async_trait]
impl EmbeddingModel for GraphModel {
    fn model_id(&self) -> ModelId { ModelId::Graph }
    fn dimension(&self) -> usize { GRAPH_DIMENSION }  // 384
    fn max_tokens(&self) -> usize { GRAPH_MAX_TOKENS }  // 512
    fn supported_inputs(&self) -> &[InputType] { &[InputType::Text] }

    fn is_loaded(&self) -> bool;
    async fn load(&self) -> EmbeddingResult<()>;
    async fn unload(&self) -> EmbeddingResult<()>;

    async fn embed(&self, input: &ModelInput) -> EmbeddingResult<ModelEmbedding>;
    async fn embed_batch(&self, inputs: &[ModelInput]) -> EmbeddingResult<Vec<ModelEmbedding>>;

    fn memory_usage_bytes(&self) -> usize;
    fn warmup_complete(&self) -> bool;
}
```
  </signatures>

  <constraints>
    <constraint>NO BACKWARDS COMPATIBILITY - fail fast with descriptive errors</constraint>
    <constraint>NO MOCK DATA in tests - use deterministic xxhash64 stubs only</constraint>
    <constraint>Uses candle-transformers for inference (stub in initial implementation)</constraint>
    <constraint>Model loaded from models/graph/ directory</constraint>
    <constraint>dimension() returns 384 (verified from model_id.rs)</constraint>
    <constraint>max_tokens() returns 512 (BERT-family default from model_id.rs)</constraint>
    <constraint>NO projection layer - native 384D output is final</constraint>
    <constraint>Thread-safe with Send + Sync bounds via RwLock + AtomicBool</constraint>
    <constraint>Latency target: less than 5ms per embedding</constraint>
    <constraint>Mean pooling for sentence representation</constraint>
    <constraint>L2 normalization produces unit vectors (norm ≈ 1.0)</constraint>
    <constraint>encode_relation() replaces underscores with spaces in predicates</constraint>
    <constraint>encode_context() limits to MAX_CONTEXT_NEIGHBORS (5) neighbors</constraint>
  </constraints>
</definition_of_done>

<files_to_modify>
  <file action="create">crates/context-graph-embeddings/src/models/pretrained/graph.rs</file>
  <file action="modify">crates/context-graph-embeddings/src/models/pretrained/mod.rs</file>
</files_to_modify>

<mod_rs_update>
Add to crates/context-graph-embeddings/src/models/pretrained/mod.rs:

```rust
mod graph;

pub use graph::{
    GraphModel,
    GRAPH_DIMENSION,
    GRAPH_LATENCY_BUDGET_MS,
    GRAPH_MAX_TOKENS,
    GRAPH_MODEL_NAME,
    MAX_CONTEXT_NEIGHBORS,
};
```
</mod_rs_update>

<stub_implementation>
The initial implementation uses deterministic xxhash64 stubs for testing.
This matches the pattern established in code.rs (CodeModel).

```rust
/// Generate deterministic stub embedding using xxhash64.
/// This ensures reproducible tests without real model weights.
fn generate_stub_embedding(text: &str, dimension: usize) -> Vec<f32> {
    let mut embedding = Vec::with_capacity(dimension);
    let base_hash = xxhash_rust::xxh64::xxh64(text.as_bytes(), 0);

    for i in 0..dimension {
        let seed = base_hash.wrapping_add(i as u64);
        let hash = xxhash_rust::xxh64::xxh64(&seed.to_le_bytes(), 0);
        // Map hash to [-1, 1] range
        let value = ((hash as f64) / (u64::MAX as f64) * 2.0 - 1.0) as f32;
        embedding.push(value);
    }

    // L2 normalize
    let norm: f32 = embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
    if norm > 1e-10 {
        for v in &mut embedding {
            *v /= norm;
        }
    }

    embedding
}
```
</stub_implementation>

<test_requirements>
  <minimum_tests>35</minimum_tests>
  <test_categories>
    <category name="construction">
      <test>test_new_creates_valid_instance</test>
      <test>test_new_with_invalid_config_fails</test>
      <test>test_new_sets_unloaded_state</test>
      <test>test_model_id_is_graph</test>
      <test>test_dimension_is_384</test>
      <test>test_max_tokens_is_512</test>
      <test>test_supported_inputs_text_only</test>
    </category>
    <category name="load_unload">
      <test>test_load_transitions_to_loaded</test>
      <test>test_load_twice_is_idempotent</test>
      <test>test_unload_transitions_to_unloaded</test>
      <test>test_unload_when_not_loaded_succeeds</test>
      <test>test_is_loaded_reflects_state</test>
      <test>test_load_sets_memory_usage</test>
    </category>
    <category name="embedding">
      <test>test_embed_requires_loaded</test>
      <test>test_embed_produces_384d_vector</test>
      <test>test_embed_is_normalized</test>
      <test>test_embed_is_deterministic</test>
      <test>test_embed_batch_produces_correct_count</test>
      <test>test_embed_batch_all_normalized</test>
      <test>test_embed_batch_all_384d</test>
      <test>test_embed_empty_batch_returns_empty</test>
      <test>test_embed_different_inputs_different_outputs</test>
      <test>test_embed_same_input_same_output</test>
    </category>
    <category name="encode_relation">
      <test>test_encode_relation_basic</test>
      <test>test_encode_relation_with_underscores</test>
      <test>test_encode_relation_empty_subject</test>
      <test>test_encode_relation_empty_predicate</test>
      <test>test_encode_relation_empty_object</test>
      <test>test_encode_relation_special_characters</test>
      <test>test_encode_relation_unicode</test>
    </category>
    <category name="encode_context">
      <test>test_encode_context_basic</test>
      <test>test_encode_context_empty_neighbors</test>
      <test>test_encode_context_single_neighbor</test>
      <test>test_encode_context_max_neighbors_limit</test>
      <test>test_encode_context_exceeds_limit_truncates</test>
      <test>test_encode_context_with_underscores</test>
      <test>test_encode_context_unicode</test>
    </category>
    <category name="thread_safety">
      <test>test_concurrent_embeds</test>
      <test>test_concurrent_load_unload</test>
      <test>test_send_sync_bounds</test>
    </category>
    <category name="edge_cases">
      <test>test_embed_very_long_text_truncates</test>
      <test>test_embed_only_whitespace</test>
      <test>test_embed_only_punctuation</test>
      <test>test_memory_usage_increases_after_load</test>
      <test>test_memory_usage_zero_when_unloaded</test>
      <test>test_warmup_complete_after_load</test>
    </category>
  </test_categories>
</test_requirements>

<validation_criteria>
  <criterion>cargo check passes with no warnings</criterion>
  <criterion>cargo test --lib passes all 35+ tests</criterion>
  <criterion>cargo clippy -- -D warnings passes</criterion>
  <criterion>GraphModel::new() creates valid instance</criterion>
  <criterion>Model loads from correct path (models/graph/)</criterion>
  <criterion>embed() produces exactly 384D vector</criterion>
  <criterion>All embeddings are L2 normalized (|v| ≈ 1.0)</criterion>
  <criterion>encode_relation() produces "subject predicate object" format</criterion>
  <criterion>encode_context() limits to 5 neighbors</criterion>
  <criterion>Latency under 5ms for typical inputs (measured in benchmarks)</criterion>
  <criterion>mod.rs exports all public constants and types</criterion>
</validation_criteria>
</task_spec>
```

---

## Implementation Reference

### Model Details (Verified from model_id.rs)
| Property | Value | Source |
|----------|-------|--------|
| ModelId | `Graph = 7` | model_id.rs:L7 |
| Dimension | 384 | model_id.rs:L95 |
| Max Tokens | 512 | model_id.rs:L212 (default) |
| Latency Budget | 5ms | model_id.rs:L280 |
| Model Repo | sentence-transformers/paraphrase-MiniLM-L6-v2 | model_id.rs:L148 |
| Tokenizer | BertWordpiece | model_id.rs:L227 |
| Model Dir | graph | model_id.rs:L170 |

### Comparison with CodeModel
| Aspect | CodeModel | GraphModel |
|--------|-----------|------------|
| Native Dimension | 256 | 384 |
| Final Dimension | 768 (projected) | 384 (no projection) |
| Projection Layer | Yes (256→768) | No |
| Tokenizer | Unigram | BertWordpiece |
| Max Tokens | 512 | 512 |
| Latency Budget | 50ms | 5ms |

### Relation Encoding Format
```rust
impl GraphModel {
    pub fn encode_relation(&self, subject: &str, predicate: &str, object: &str) -> String {
        // Format: "subject predicate object"
        // Example: encode_relation("Alice", "works_at", "Anthropic") -> "Alice works at Anthropic"
        format!("{} {} {}", subject, predicate.replace('_', " "), object)
    }

    pub fn encode_context(&self, node: &str, neighbors: &[(String, String)]) -> String {
        // Format: "node: rel1 neighbor1, rel2 neighbor2, ..."
        // Limited to MAX_CONTEXT_NEIGHBORS (5) for token budget
        let context: Vec<String> = neighbors.iter()
            .take(MAX_CONTEXT_NEIGHBORS)
            .map(|(rel, neighbor)| format!("{} {}", rel.replace('_', " "), neighbor))
            .collect();
        format!("{}: {}", node, context.join(", "))
    }
}
```

### Mean Pooling Strategy
Same as other sentence-transformer models:
```rust
fn mean_pool(hidden_states: &Tensor, attention_mask: &Tensor) -> Tensor {
    let mask_expanded = attention_mask.unsqueeze(-1).expand_as(&hidden_states);
    let sum = (hidden_states * mask_expanded).sum(1);
    let count = mask_expanded.sum(1).clamp_min(1e-9);
    sum / count
}
```

---

## Full State Verification Requirements

### 1. Source of Truth Verification
Before implementation, verify these values in `model_id.rs`:
```bash
# Run these commands and verify output:
grep "Self::Graph =>" crates/context-graph-embeddings/src/types/model_id.rs
```

Expected output must show:
- `Self::Graph => 384,` (dimension)
- `Self::Graph => Some("sentence-transformers/paraphrase-MiniLM-L6-v2"),`
- `Self::Graph => 5,` (latency_budget_ms)
- `Self::Graph => TokenizerFamily::BertWordpiece,`

### 2. Execute & Inspect Requirements
After implementation, run and verify:
```bash
# Build check
cargo check -p context-graph-embeddings 2>&1 | head -20

# Run all tests
cargo test -p context-graph-embeddings graph 2>&1 | tail -30

# Verify test count (must be 35+)
cargo test -p context-graph-embeddings graph 2>&1 | grep -E "^test result:"

# Clippy clean
cargo clippy -p context-graph-embeddings -- -D warnings 2>&1 | tail -10
```

### 3. Edge Case Tests (Mandatory)
Each edge case test must:
1. Print initial state
2. Execute operation
3. Print final state
4. Assert expected outcome

Example pattern:
```rust
#[tokio::test]
async fn test_embed_requires_loaded() {
    let model = create_test_model();

    // State: unloaded
    assert!(!model.is_loaded(), "Initial state must be unloaded");

    let input = ModelInput::text("test");
    let result = model.embed(&input).await;

    // Must fail with NotLoaded error
    assert!(matches!(result, Err(EmbeddingError::NotLoaded(_))));
}
```

### 4. Evidence Requirements
Implementation must produce verifiable evidence:
- [ ] Test output shows 35+ tests passing
- [ ] All embeddings verified as 384-dimensional
- [ ] All embeddings verified as L2-normalized (norm ≈ 1.0 ± 1e-6)
- [ ] encode_relation() output format verified with examples
- [ ] encode_context() neighbor limit verified

---

## Sherlock-Holmes Verification Checklist

After implementation, spawn `sherlock-holmes` subagent to verify:

```
/task sherlock-holmes "Forensic verification of GraphModel implementation:

1. VERIFY constants match model_id.rs:
   - GRAPH_DIMENSION == 384
   - GRAPH_MAX_TOKENS == 512
   - GRAPH_LATENCY_BUDGET_MS == 5

2. VERIFY struct implementation:
   - GraphModel uses RwLock<ModelState>
   - GraphModel uses AtomicBool for loaded
   - Implements EmbeddingModel trait correctly

3. VERIFY encoding methods:
   - encode_relation replaces underscores with spaces
   - encode_context limits to 5 neighbors

4. VERIFY test coverage:
   - Count tests (must be 35+)
   - Verify all categories covered
   - Verify edge cases tested

5. VERIFY exports in mod.rs:
   - GraphModel exported
   - All constants exported

6. RUN and CAPTURE output:
   cargo test -p context-graph-embeddings graph --no-fail-fast 2>&1

7. REPORT findings with PASS/FAIL for each item"
```

---

## Output Verification Requirements

### Dimensional Consistency
```rust
#[test]
fn test_dimension_matches_model_id() {
    let model = create_test_model();
    assert_eq!(model.dimension(), ModelId::Graph.dimension());
    assert_eq!(model.dimension(), GRAPH_DIMENSION);
    assert_eq!(model.dimension(), 384);
}
```

### Normalization Verification
```rust
#[tokio::test]
async fn test_embed_is_normalized() {
    let model = create_test_model();
    model.load().await.unwrap();

    let input = ModelInput::text("Alice works at Anthropic");
    let embedding = model.embed(&input).await.unwrap();

    let norm: f32 = embedding.values.iter().map(|x| x * x).sum::<f32>().sqrt();
    assert!((norm - 1.0).abs() < 1e-6, "L2 norm must be ~1.0, got {}", norm);
}
```

### Determinism Verification
```rust
#[tokio::test]
async fn test_embed_is_deterministic() {
    let model = create_test_model();
    model.load().await.unwrap();

    let input = ModelInput::text("test input");
    let embedding1 = model.embed(&input).await.unwrap();
    let embedding2 = model.embed(&input).await.unwrap();

    assert_eq!(embedding1.values, embedding2.values,
        "Same input must produce identical output");
}
```

---

## Implementation Notes

### NO BACKWARDS COMPATIBILITY
- Remove any deprecated methods immediately
- Fail fast with descriptive error messages
- No fallback behaviors or silent failures
- Use `EmbeddingError` variants for all error conditions

### NO MOCK DATA
- Use xxhash64 deterministic stubs for testing
- Stubs must produce consistent, verifiable output
- Real model weights loaded only with `candle` feature
- All test assertions must verify actual values

### Error Handling Pattern
```rust
impl GraphModel {
    pub fn new(models_dir: &Path, config: SingleModelConfig) -> EmbeddingResult<Self> {
        // Validate immediately - fail fast
        if !models_dir.exists() {
            return Err(EmbeddingError::ModelNotFound(
                format!("Models directory not found: {}", models_dir.display())
            ));
        }

        // ... rest of construction
    }

    async fn embed_internal(&self, text: &str) -> EmbeddingResult<Vec<f32>> {
        // Always check loaded state first
        if !self.is_loaded() {
            return Err(EmbeddingError::NotLoaded(
                "GraphModel must be loaded before embedding".into()
            ));
        }

        // ... embedding logic
    }
}
```

---

## ✅ COMPLETION VERIFICATION

**Completed**: 2026-01-01
**Verified by**: Sherlock-Holmes forensic investigation

### Implementation Evidence

| Verification Item | Expected | Actual | Status |
|-------------------|----------|--------|--------|
| GRAPH_DIMENSION constant | 384 | 384 | ✅ PASS |
| GRAPH_MAX_TOKENS constant | 512 | 512 | ✅ PASS |
| GRAPH_LATENCY_BUDGET_MS constant | 5 | 5 | ✅ PASS |
| GRAPH_MODEL_NAME constant | paraphrase-MiniLM-L6-v2 | paraphrase-MiniLM-L6-v2 | ✅ PASS |
| MAX_CONTEXT_NEIGHBORS constant | 5 | 5 | ✅ PASS |
| ModelId::Graph.dimension() | 384 | 384 | ✅ PASS |
| ModelId::Graph.max_tokens() | 512 | 512 | ✅ PASS |
| ModelId::Graph.latency_budget_ms() | 5 | 5 | ✅ PASS |
| encode_relation underscore replacement | yes | yes | ✅ PASS |
| encode_context MAX_CONTEXT_NEIGHBORS limit | 5 | .take(5) | ✅ PASS |
| xxhash64 seeding | yes | xxh64::xxh64 | ✅ PASS |
| L2 normalization | ~1.0 | 1.0000001 | ✅ PASS |
| EmbeddingModel trait | implemented | implemented | ✅ PASS |
| Send + Sync traits | implemented | unsafe impl | ✅ PASS |
| Tests passed | 35+ | 50 | ✅ PASS |
| Exports in mod.rs | 6 items | 6 items | ✅ PASS |

### Files Created/Modified

1. **Created**: `crates/context-graph-embeddings/src/models/pretrained/graph.rs` (1137 lines)
   - Full GraphModel implementation with encode_relation and encode_context
   - 50 comprehensive tests covering all categories
   - xxhash64 deterministic stub implementation
   - L2 normalized embeddings (384D)

2. **Modified**: `crates/context-graph-embeddings/src/models/pretrained/mod.rs`
   - Added `mod graph;`
   - Exported GraphModel, GRAPH_DIMENSION, GRAPH_LATENCY_BUDGET_MS, GRAPH_MAX_TOKENS, GRAPH_MODEL_NAME, MAX_CONTEXT_NEIGHBORS

### Test Results

```
cargo test --package context-graph-embeddings graph::
running 50 tests
test models::pretrained::graph::tests::test_constants_are_correct ... ok
test models::pretrained::graph::tests::test_edge_case_1_empty_text_content ... ok
test models::pretrained::graph::tests::test_edge_case_2_long_text_512_tokens ... ok
... (all 50 tests passed)
test result: ok. 50 passed; 0 failed; 0 ignored; 0 measured; 826 filtered out
```

### Verification Commands Run

```bash
cargo check --package context-graph-embeddings  # PASSED
cargo clippy --package context-graph-embeddings  # PASSED (no warnings)
cargo test --package context-graph-embeddings graph::  # 50/50 PASSED
```
