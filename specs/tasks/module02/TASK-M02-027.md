# TASK-M02-027: Create Module Integration Tests

```xml
<task_spec id="TASK-M02-027" version="1.0">
<metadata>
  <title>Create Module Integration Tests</title>
  <status>blocked</status>
  <layer>surface</layer>
  <module>module-02</module>
  <sequence>27</sequence>
  <priority>critical</priority>
  <estimated_hours>4</estimated_hours>
  <implements>
    <item>TECH-CORE-002 Section 4: Testing specification</item>
    <item>REQ-CORE-006: CRUD requirements verification</item>
  </implements>
  <depends_on>
    <task_ref>TASK-M02-017</task_ref>
    <task_ref>TASK-M02-018</task_ref>
    <task_ref>TASK-M02-022</task_ref>
    <task_ref>TASK-M02-023</task_ref>
  </depends_on>
  <estimated_complexity>high</estimated_complexity>
</metadata>

<context>
This task implements comprehensive integration tests for Module 2, verifying that all components work together correctly. The tests cover end-to-end workflows including node lifecycle, edge operations with Marblestone features, Johari quadrant transitions, Cognitive Pulse generation, index consistency, and concurrent access patterns. These tests ensure the storage layer meets performance targets and maintains data integrity.
</context>

<input_context_files>
  <file purpose="Node CRUD operations">crates/context-graph-storage/src/rocksdb_backend.rs</file>
  <file purpose="Edge CRUD operations">crates/context-graph-storage/src/rocksdb_backend.rs</file>
  <file purpose="Cognitive Pulse methods">crates/context-graph-core/src/pulse.rs</file>
  <file purpose="Index operations">crates/context-graph-storage/src/indexes.rs</file>
  <file purpose="Core types">crates/context-graph-core/src/lib.rs</file>
  <file purpose="Marblestone types">crates/context-graph-core/src/marblestone.rs</file>
</input_context_files>

<prerequisites>
  <check>TASK-M02-017 (Node CRUD Operations) completed</check>
  <check>TASK-M02-018 (Edge CRUD Operations) completed</check>
  <check>TASK-M02-022 (CognitivePulse Methods) completed</check>
  <check>TASK-M02-023 (Secondary Index Operations) completed</check>
</prerequisites>

<scope>
  <in_scope>
    - End-to-end node lifecycle tests (create, read, update, delete)
    - Edge creation with Marblestone features (NT weights, steering reward)
    - Johari quadrant transition verification
    - Cognitive Pulse generation and action computation
    - Index consistency after mutations
    - Concurrent read/write access patterns
    - Performance benchmark tests (<1ms store, <500us get)
    - Test coverage >80% for storage crate
  </in_scope>
  <out_of_scope>
    - MCP integration tests (future module)
    - Embedding pipeline tests (Module 3)
    - FAISS vector search tests (Module 4)
    - Unit tests (already in each module)
  </out_of_scope>
</scope>

<definition_of_done>
  <signatures>
    <signature file="crates/context-graph-storage/tests/integration_tests.rs">
use context_graph_core::{
    MemoryNode, GraphEdge, JohariQuadrant, EdgeType, Domain,
    NeurotransmitterWeights, CognitivePulse, EmotionalState,
};
use context_graph_storage::{RocksDbMemex, StorageError};
use tempfile::TempDir;
use tokio;
use std::sync::Arc;

/// Integration test module for Module 2 Core Infrastructure.
///
/// These tests verify end-to-end functionality of the storage layer,
/// including CRUD operations, index consistency, and concurrent access.

// === Node Lifecycle Tests ===

#[tokio::test]
async fn test_node_lifecycle_create_read_update_delete() {
    // Create temp directory for RocksDB
    // Open RocksDbMemex
    // Create MemoryNode with valid data
    // Store node -> verify success
    // Get node -> verify all fields match
    // Update node (change quadrant, add tags)
    // Get node again -> verify updates applied
    // Delete node (soft delete)
    // Get node -> verify deleted flag set
    // Hard delete node
    // Get node -> verify NotFound error
}

#[tokio::test]
async fn test_node_with_embedding_roundtrip() {
    // Create node with 1536D normalized embedding
    // Store and retrieve
    // Verify embedding values are exactly preserved
}

// === Edge Tests with Marblestone Features ===

#[tokio::test]
async fn test_edge_with_neurotransmitter_weights() {
    // Create two nodes
    // Create edge with NeurotransmitterWeights (Code domain)
    // Store edge
    // Retrieve edge
    // Verify NT weights preserved
    // Verify get_modulated_weight() returns correct value
}

#[tokio::test]
async fn test_edge_steering_reward_persistence() {
    // Create edge with steering_reward
    // Apply steering reward update
    // Store and retrieve
    // Verify steering_reward preserved
}

#[tokio::test]
async fn test_amortized_shortcut_edge() {
    // Create edge with is_amortized_shortcut = true
    // Store and retrieve
    // Verify is_amortized_shortcut flag preserved
}

// === Johari Quadrant Tests ===

#[tokio::test]
async fn test_johari_quadrant_index_consistency() {
    // Create nodes in each quadrant
    // Query by quadrant
    // Verify correct nodes returned for each
    // Update node quadrant
    // Verify old index removed, new index added
}

// === Cognitive Pulse Tests ===

#[tokio::test]
async fn test_cognitive_pulse_action_matrix() {
    // Test all decision matrix paths
    // Stabilize: entropy > 0.7, coherence < 0.4
    // Ready: entropy < 0.3, coherence > 0.7
    // Explore: curiosity > 0.7
    // Consolidate: entropy < 0.4, coherence 0.5-0.8
    // Review: coherence < 0.4 (not Stabilize)
    // Continue: default
}

// === Index Consistency Tests ===

#[tokio::test]
async fn test_tag_index_consistency_after_mutations() {
    // Create node with tags ["rust", "async"]
    // Query by tag "rust" -> verify node found
    // Update node: remove "rust", add "tokio"
    // Query by "rust" -> verify node NOT found
    // Query by "tokio" -> verify node found
}

#[tokio::test]
async fn test_temporal_index_consistency() {
    // Create nodes at different times
    // Query time range
    // Verify correct nodes returned in order
}

// === Concurrent Access Tests ===

#[tokio::test]
async fn test_concurrent_reads_same_node() {
    // Store a node
    // Spawn 100 concurrent read tasks
    // All should succeed with consistent data
}

#[tokio::test]
async fn test_concurrent_writes_different_nodes() {
    // Spawn 50 concurrent write tasks (different nodes)
    // All should succeed
    // Verify all nodes stored correctly
}

#[tokio::test]
async fn test_concurrent_read_write_isolation() {
    // Start a long read operation
    // Concurrent write should not corrupt read
    // Verify data integrity maintained
}

// === Performance Tests ===

#[tokio::test]
async fn test_store_node_latency_under_1ms() {
    // Store 1000 nodes
    // Measure individual latencies
    // Assert p99 < 1ms
}

#[tokio::test]
async fn test_get_node_latency_under_500us() {
    // Store nodes, warm cache
    // Get 1000 nodes
    // Measure individual latencies
    // Assert p99 < 500us
}

// === Error Handling Tests ===

#[tokio::test]
async fn test_get_nonexistent_node_returns_not_found() {
    // Open empty database
    // Get random UUID
    // Verify StorageError::NotFound returned
}

#[tokio::test]
async fn test_validation_errors_propagate() {
    // Create invalid node (wrong embedding dimension)
    // Attempt to store
    // Verify ValidationError returned
}
    </signature>
  </signatures>

  <constraints>
    - All tests must use tempfile::TempDir for isolation
    - Each test must clean up resources (RocksDB closed properly)
    - Concurrent tests must use Arc for shared state
    - Performance tests must run with release optimizations
    - Tests must not depend on execution order
    - Test coverage must be measurable via cargo tarpaulin
  </constraints>

  <verification>
    - cargo test --package context-graph-storage --test integration_tests passes
    - All tests complete in under 60 seconds
    - No test flakiness on repeated runs
    - cargo tarpaulin shows >80% coverage for storage crate
    - Performance assertions pass on standard hardware
  </verification>
</definition_of_done>

<pseudo_code>
tests/integration_tests.rs:

mod node_lifecycle {
    #[tokio::test]
    async fn test_create_read_update_delete():
        let temp_dir = TempDir::new()?
        let memex = RocksDbMemex::open(temp_dir.path()).await?

        // Create
        let node = MemoryNode::new("Test content", vec![0.0; 1536])
        memex.store_node(&node).await?

        // Read
        let retrieved = memex.get_node(&node.id).await?
        assert_eq!(retrieved.content, node.content)

        // Update
        let mut updated = retrieved.clone()
        updated.metadata.add_tag("test-tag")
        memex.update_node(&updated).await?

        // Verify update
        let after_update = memex.get_node(&node.id).await?
        assert!(after_update.metadata.has_tag("test-tag"))

        // Soft delete
        memex.delete_node(&node.id, true).await?
        let deleted = memex.get_node(&node.id).await?
        assert!(deleted.metadata.deleted)

        // Hard delete
        memex.delete_node(&node.id, false).await?
        let result = memex.get_node(&node.id).await
        assert!(matches!(result, Err(StorageError::NotFound { .. })))
}

mod marblestone_integration {
    #[tokio::test]
    async fn test_edge_with_nt_weights():
        let memex = setup_test_memex().await

        let node1 = create_test_node()
        let node2 = create_test_node()
        memex.store_node(&node1).await?
        memex.store_node(&node2).await?

        let edge = GraphEdge::new(
            node1.id, node2.id,
            EdgeType::Causal,
            Domain::Code,
        )
        assert!(edge.neurotransmitter_weights.is_some())
        assert_eq!(edge.neurotransmitter_weights.unwrap().excitatory, 0.6)

        memex.store_edge(&edge).await?
        let retrieved = memex.get_edge(&node1.id, &node2.id, EdgeType::Causal).await?

        assert_eq!(retrieved.weight, edge.weight)
        assert!(retrieved.neurotransmitter_weights.is_some())
}

mod cognitive_pulse_integration {
    #[tokio::test]
    async fn test_action_computation():
        // Test each decision path
        let crisis = CognitivePulse::new(0.8, 0.3, 0.5, 0.5, EmotionalState::Neutral)
        assert_eq!(crisis.compute_suggested_action(), SuggestedAction::Stabilize)

        let ready = CognitivePulse::new(0.2, 0.8, 0.5, 0.5, EmotionalState::Neutral)
        assert_eq!(ready.compute_suggested_action(), SuggestedAction::Ready)

        // ... test all paths
}

mod concurrent_access {
    #[tokio::test]
    async fn test_concurrent_reads():
        let memex = Arc::new(setup_test_memex().await)
        let node = create_and_store_node(&memex).await

        let handles: Vec<_> = (0..100).map(|_| {
            let memex = Arc::clone(&memex)
            let id = node.id
            tokio::spawn(async move {
                memex.get_node(&id).await
            })
        }).collect()

        for handle in handles:
            let result = handle.await?
            assert!(result.is_ok())
}

mod performance_benchmarks {
    #[tokio::test]
    async fn test_store_latency():
        let memex = setup_test_memex().await
        let mut latencies = Vec::with_capacity(1000)

        for _ in 0..1000:
            let node = create_test_node()
            let start = Instant::now()
            memex.store_node(&node).await?
            latencies.push(start.elapsed())

        latencies.sort()
        let p99 = latencies[990]
        assert!(p99 < Duration::from_millis(1), "P99 latency {} exceeds 1ms", p99.as_micros())
}
</pseudo_code>

<files_to_create>
  <file path="crates/context-graph-storage/tests/integration_tests.rs">Comprehensive integration test suite for Module 2</file>
</files_to_create>

<files_to_modify>
  <file path="crates/context-graph-storage/Cargo.toml">Add dev-dependencies: tempfile, criterion (for benchmarks)</file>
</files_to_modify>

<validation_criteria>
  <criterion>All CRUD operations tested end-to-end with assertions</criterion>
  <criterion>Marblestone edge features (NT weights, steering_reward, is_amortized_shortcut) verified</criterion>
  <criterion>Index consistency maintained after updates (verified by queries)</criterion>
  <criterion>Concurrent read/write test passes without deadlock or corruption</criterion>
  <criterion>Performance meets targets: store <1ms p99, get <500us p99</criterion>
  <criterion>Test coverage >80% for storage crate (verified by cargo tarpaulin)</criterion>
  <criterion>All tests pass on fresh database (isolation via TempDir)</criterion>
  <criterion>Error handling tested for NotFound and ValidationError cases</criterion>
</validation_criteria>

<test_commands>
  <command>cargo build --package context-graph-storage</command>
  <command>cargo test --package context-graph-storage --test integration_tests -- --nocapture</command>
  <command>cargo test --package context-graph-storage --test integration_tests --release -- performance</command>
  <command>cargo tarpaulin --package context-graph-storage --out Html</command>
  <command>cargo clippy --package context-graph-storage --tests -- -D warnings</command>
</test_commands>
</task_spec>
```

## Implementation Notes

### Test Isolation
Each test uses `tempfile::TempDir` to create an isolated RocksDB instance. This ensures:
1. Tests don't interfere with each other
2. No cleanup required between runs
3. Parallel test execution is safe

### Performance Testing
Performance tests should be run with `--release` flag for accurate measurements. The targets are:
- Store node: <1ms p99
- Get node: <500us p99

These match the requirements from TECH-CORE-002.

### Marblestone Feature Verification
The integration tests specifically verify:
- NeurotransmitterWeights are correctly stored and retrieved per domain
- steering_reward values persist through store/retrieve cycles
- is_amortized_shortcut edges are properly marked

### Coverage Measurement
Use `cargo tarpaulin` for coverage measurement:
```bash
cargo install cargo-tarpaulin
cargo tarpaulin --package context-graph-storage --out Html
```

Target: >80% coverage for the storage crate.

---

*Task ID: TASK-M02-027*
*Module: 02 - Core Infrastructure*
*Layer: Surface*
