# TASK-M02-015: Define Column Family Descriptors

## Task Metadata
| Field | Value |
|-------|-------|
| **Status** | ⏳ READY |
| **Layer** | logic |
| **Priority** | critical |
| **Depends On** | TASK-M02-013 ✅ (Storage crate structure complete) |
| **Estimated Hours** | 3 |
| **Implements** | REQ-CORE-005, TECH-CORE-002 Section 3.1 |

---

## Context for AI Agent

You are implementing RocksDB column family descriptors for the Context Graph storage layer. TASK-M02-013 created the storage crate structure and TASK-M02-014 implemented serialization (already complete with 50+ tests passing).

### Current State (Verified 2025-12-31)
- **Storage crate exists**: `crates/context-graph-storage/`
- **column_families.rs exists but is placeholder-only** (23 lines, just documentation)
- **serialization.rs is COMPLETE** with 50+ passing tests
- **Build passes**: `cargo build --package context-graph-storage` succeeds
- **Dependencies**: rocksdb = "0.22" already in Cargo.toml

### Files You Must Read First
1. `crates/context-graph-storage/src/column_families.rs` - Your target file (placeholder)
2. `crates/context-graph-storage/src/lib.rs` - Module exports
3. `crates/context-graph-core/src/types/johari.rs` - JohariQuadrant::column_family() returns CF names

---

## Exact Requirements

### 12 Column Families (Per constitution.yaml)
From constitution.yaml and PRD, the storage layer uses 12 column families:

| CF Name | Purpose | Key Format | Access Pattern | Optimization |
|---------|---------|------------|----------------|--------------|
| `nodes` | Primary node storage | UUID (16 bytes) | Point lookups | Bloom filter, cache |
| `edges` | Graph edge storage | UUID (16 bytes) | Range scans by source | Prefix extractor |
| `embeddings` | Embedding vectors (1536D×f32=6144 bytes) | UUID (16 bytes) | Sequential read | Large blocks |
| `metadata` | Node metadata | UUID (16 bytes) | Point lookups | Cache |
| `johari_open` | Open quadrant index | UUID | Range scans | Prefix extractor |
| `johari_hidden` | Hidden quadrant index | UUID | Range scans | Prefix extractor |
| `johari_blind` | Blind quadrant index | UUID | Range scans | Prefix extractor |
| `johari_unknown` | Unknown quadrant index | UUID | Range scans | Prefix extractor |
| `temporal` | Time-based index | timestamp_ms:UUID | Range scans | Prefix extractor |
| `tags` | Tag index | tag:UUID | Range scans | Prefix extractor |
| `sources` | Source index | source_uri:UUID | Range scans | Prefix extractor |
| `system` | System metadata | string key | Rare access | No compression |

### Shared Block Cache (constitution.yaml)
> "shared 256MB block cache with bloom filter"

All column families share a single 256MB block cache for efficient memory usage.

---

## Required Function Signatures

```rust
// crates/context-graph-storage/src/column_families.rs

use rocksdb::{BlockBasedOptions, Cache, ColumnFamilyDescriptor, Options, SliceTransform};

/// Column family name constants.
pub mod cf_names {
    pub const NODES: &str = "nodes";
    pub const EDGES: &str = "edges";
    pub const EMBEDDINGS: &str = "embeddings";
    pub const METADATA: &str = "metadata";
    pub const JOHARI_OPEN: &str = "johari_open";
    pub const JOHARI_HIDDEN: &str = "johari_hidden";
    pub const JOHARI_BLIND: &str = "johari_blind";
    pub const JOHARI_UNKNOWN: &str = "johari_unknown";
    pub const TEMPORAL: &str = "temporal";
    pub const TAGS: &str = "tags";
    pub const SOURCES: &str = "sources";
    pub const SYSTEM: &str = "system";

    /// All column family names as a slice (12 total).
    pub const ALL: &[&str] = &[
        NODES, EDGES, EMBEDDINGS, METADATA,
        JOHARI_OPEN, JOHARI_HIDDEN, JOHARI_BLIND, JOHARI_UNKNOWN,
        TEMPORAL, TAGS, SOURCES, SYSTEM,
    ];
}

/// Create options optimized for node storage (point lookups).
/// - Bloom filter: 10 bits per key
/// - Block cache enabled
/// - LZ4 compression
/// - Optimized for point lookups (256MB cache hint)
pub fn nodes_options(cache: &Cache) -> Options;

/// Create options optimized for edge storage (range scans with prefix).
/// - Prefix extractor: 16 bytes (UUID source_id)
/// - Block cache enabled
/// - LZ4 compression
pub fn edges_options(cache: &Cache) -> Options;

/// Create options optimized for embedding storage (large sequential reads).
/// - Block size: 64KB (larger blocks for sequential reads)
/// - Block cache enabled
/// - LZ4 compression
pub fn embeddings_options(cache: &Cache) -> Options;

/// Create options optimized for index column families.
/// - Prefix extractor: 16 bytes
/// - Block cache enabled
/// - LZ4 compression
pub fn index_options(cache: &Cache) -> Options;

/// Create options for system metadata (small, infrequent access).
/// - No compression (small data)
/// - No bloom filter needed
pub fn system_options() -> Options;

/// Get all column family descriptors with optimized options.
///
/// # Arguments
/// * `block_cache` - Shared block cache (recommended: 256MB via Cache::new_lru_cache)
///
/// # Returns
/// Vector of 12 ColumnFamilyDescriptors with optimized options per CF type.
pub fn get_column_family_descriptors(block_cache: &Cache) -> Vec<ColumnFamilyDescriptor>;
```

---

## Implementation Constraints

### MUST Follow
1. **Exactly 12 column families** - no more, no less
2. **CF names MUST match JohariQuadrant::column_family()** - use literal strings that match
3. **LZ4 compression** for all CFs except `system`
4. **Shared block cache** - pass `&Cache` to all option builders
5. **Prefix extractor = 16 bytes** for UUID-keyed range scans (edges, indexes)
6. **Bloom filter = 10 bits** for nodes CF

### MUST NOT Do
1. DO NOT use mock data in tests - use real RocksDB operations
2. DO NOT create backwards compatibility shims
3. DO NOT guess or assume - verify against constitution.yaml
4. DO NOT add extra features beyond specification

### RocksDB API Reference (rocksdb 0.22)
```rust
// Block-based options
let mut block_opts = BlockBasedOptions::default();
block_opts.set_block_cache(cache);
block_opts.set_bloom_filter(10.0, false);  // 10 bits, not block-based
block_opts.set_block_size(64 * 1024);      // 64KB for embeddings
block_opts.set_cache_index_and_filter_blocks(true);

// Options
let mut opts = Options::default();
opts.set_block_based_table_factory(&block_opts);
opts.set_compression_type(rocksdb::DBCompressionType::Lz4);
opts.set_prefix_extractor(SliceTransform::create_fixed_prefix(16));
opts.optimize_for_point_lookup(256);  // 256MB hint

// Create descriptor
ColumnFamilyDescriptor::new("name", opts)
```

---

## Required Tests

Create unit tests in the same file under `#[cfg(test)]`:

```rust
#[cfg(test)]
mod tests {
    use super::*;

    // =========================================================================
    // CF Names Module Tests
    // =========================================================================

    #[test]
    fn test_cf_names_count() {
        assert_eq!(cf_names::ALL.len(), 12, "Must have exactly 12 column families");
    }

    #[test]
    fn test_all_contains_all_names() {
        assert!(cf_names::ALL.contains(&cf_names::NODES));
        assert!(cf_names::ALL.contains(&cf_names::EDGES));
        assert!(cf_names::ALL.contains(&cf_names::EMBEDDINGS));
        assert!(cf_names::ALL.contains(&cf_names::METADATA));
        assert!(cf_names::ALL.contains(&cf_names::JOHARI_OPEN));
        assert!(cf_names::ALL.contains(&cf_names::JOHARI_HIDDEN));
        assert!(cf_names::ALL.contains(&cf_names::JOHARI_BLIND));
        assert!(cf_names::ALL.contains(&cf_names::JOHARI_UNKNOWN));
        assert!(cf_names::ALL.contains(&cf_names::TEMPORAL));
        assert!(cf_names::ALL.contains(&cf_names::TAGS));
        assert!(cf_names::ALL.contains(&cf_names::SOURCES));
        assert!(cf_names::ALL.contains(&cf_names::SYSTEM));
    }

    #[test]
    fn test_cf_names_match_johari() {
        use context_graph_core::types::JohariQuadrant;
        assert_eq!(cf_names::JOHARI_OPEN, JohariQuadrant::Open.column_family());
        assert_eq!(cf_names::JOHARI_HIDDEN, JohariQuadrant::Hidden.column_family());
        assert_eq!(cf_names::JOHARI_BLIND, JohariQuadrant::Blind.column_family());
        assert_eq!(cf_names::JOHARI_UNKNOWN, JohariQuadrant::Unknown.column_family());
    }

    #[test]
    fn test_cf_names_unique() {
        use std::collections::HashSet;
        let set: HashSet<_> = cf_names::ALL.iter().collect();
        assert_eq!(set.len(), 12, "All CF names must be unique");
    }

    // =========================================================================
    // Option Builders Tests
    // =========================================================================

    #[test]
    fn test_nodes_options_creates_valid_options() {
        let cache = Cache::new_lru_cache(256 * 1024 * 1024); // 256MB
        let opts = nodes_options(&cache);
        // Options object created successfully (no panic)
        drop(opts);
    }

    #[test]
    fn test_edges_options_creates_valid_options() {
        let cache = Cache::new_lru_cache(256 * 1024 * 1024);
        let opts = edges_options(&cache);
        drop(opts);
    }

    #[test]
    fn test_embeddings_options_creates_valid_options() {
        let cache = Cache::new_lru_cache(256 * 1024 * 1024);
        let opts = embeddings_options(&cache);
        drop(opts);
    }

    #[test]
    fn test_index_options_creates_valid_options() {
        let cache = Cache::new_lru_cache(256 * 1024 * 1024);
        let opts = index_options(&cache);
        drop(opts);
    }

    #[test]
    fn test_system_options_creates_valid_options() {
        let opts = system_options();
        drop(opts);
    }

    // =========================================================================
    // Descriptor Creation Tests
    // =========================================================================

    #[test]
    fn test_get_descriptors_returns_12() {
        let cache = Cache::new_lru_cache(256 * 1024 * 1024);
        let descriptors = get_column_family_descriptors(&cache);
        assert_eq!(descriptors.len(), 12, "Must return exactly 12 descriptors");
    }

    #[test]
    fn test_descriptors_have_correct_names() {
        let cache = Cache::new_lru_cache(256 * 1024 * 1024);
        let descriptors = get_column_family_descriptors(&cache);
        let names: Vec<_> = descriptors.iter().map(|d| d.name()).collect();

        for cf_name in cf_names::ALL {
            assert!(names.contains(cf_name), "Missing CF: {}", cf_name);
        }
    }

    // =========================================================================
    // Edge Case Tests (REQUIRED - print before/after state)
    // =========================================================================

    #[test]
    fn edge_case_multiple_cache_references() {
        println!("=== EDGE CASE: Multiple option builders sharing same cache ===");
        let cache = Cache::new_lru_cache(256 * 1024 * 1024);

        println!("BEFORE: Creating options with shared cache reference");
        let nodes = nodes_options(&cache);
        let edges = edges_options(&cache);
        let embeddings = embeddings_options(&cache);
        let index = index_options(&cache);

        println!("AFTER: All 4 option builders created successfully");
        drop(nodes);
        drop(edges);
        drop(embeddings);
        drop(index);
        println!("RESULT: PASS - Shared cache works across multiple Options");
    }

    #[test]
    fn edge_case_minimum_cache_size() {
        println!("=== EDGE CASE: Minimum cache size (1MB) ===");
        let cache = Cache::new_lru_cache(1024 * 1024); // 1MB minimum

        println!("BEFORE: Creating descriptors with 1MB cache");
        let descriptors = get_column_family_descriptors(&cache);

        println!("AFTER: {} descriptors created", descriptors.len());
        assert_eq!(descriptors.len(), 12);
        println!("RESULT: PASS - Works with minimum cache size");
    }

    #[test]
    fn edge_case_zero_cache_size() {
        println!("=== EDGE CASE: Zero cache size ===");
        // RocksDB requires minimum cache size, 0 should still create cache
        let cache = Cache::new_lru_cache(0);

        println!("BEFORE: Creating descriptors with 0-byte cache");
        let descriptors = get_column_family_descriptors(&cache);

        println!("AFTER: {} descriptors created", descriptors.len());
        assert_eq!(descriptors.len(), 12);
        println!("RESULT: PASS - Zero cache handled gracefully");
    }
}
```

---

## Verification Commands

```bash
# Build must succeed
cargo build --package context-graph-storage

# All tests must pass (no --nocapture needed for CI)
cargo test --package context-graph-storage column_families

# Verify 12 CF names exist
cargo test --package context-graph-storage test_cf_names_count -- --nocapture

# Run edge case tests with output
cargo test --package context-graph-storage edge_case -- --nocapture
```

---

## Full State Verification Protocol

After implementing, you MUST perform the following verification:

### 1. Source of Truth
The source of truth is the compiled Rust module. Verification is done by:
- Running tests that exercise every CF name constant
- Confirming descriptors can be created without panic
- Verifying names match `JohariQuadrant::column_family()` from core crate

### 2. Execute & Inspect
```bash
# Run tests with output
cargo test --package context-graph-storage column_families -- --nocapture 2>&1 | tee /tmp/cf_test_output.txt

# Verify output contains expected patterns
grep -E "test_cf_names_count.*ok" /tmp/cf_test_output.txt
grep -E "test_get_descriptors_returns_12.*ok" /tmp/cf_test_output.txt
grep -E "12 column families" /tmp/cf_test_output.txt
```

### 3. Boundary & Edge Case Audit
The following 3 edge cases MUST be tested with before/after state printed:

1. **Shared cache across multiple Options** - Verify cache reference works
2. **Minimum cache size (1MB)** - Verify degraded performance doesn't crash
3. **Zero cache size** - Verify graceful handling

### 4. Evidence of Success
Provide logs showing:
- All 12 CF names are defined
- All option builders create valid Options
- All descriptors are returned
- Edge cases pass with before/after output

---

## Definition of Done Checklist

- [ ] `cf_names` module defines exactly 12 CF name constants
- [ ] `cf_names::ALL` contains all 12 names
- [ ] CF names match `JohariQuadrant::column_family()` output
- [ ] `nodes_options()` enables bloom filter (10 bits), LZ4 compression
- [ ] `edges_options()` has prefix extractor (16 bytes), LZ4 compression
- [ ] `embeddings_options()` uses 64KB block size, LZ4 compression
- [ ] `index_options()` has prefix extractor (16 bytes), LZ4 compression
- [ ] `system_options()` has no compression
- [ ] `get_column_family_descriptors()` returns Vec with 12 descriptors
- [ ] All unit tests pass
- [ ] Edge case tests print before/after state
- [ ] `cargo build --package context-graph-storage` succeeds
- [ ] `cargo clippy --package context-graph-storage` has 0 warnings
- [ ] Sherlock-Holmes verification agent confirms implementation

---

## Final Verification Step (MANDATORY)

After completing all implementation and tests, you MUST spawn the `sherlock-holmes` subagent to perform forensic verification:

```
Use Task tool with subagent_type="sherlock-holmes" to:
1. Verify all 12 CF names are defined and unique
2. Verify CF names match JohariQuadrant::column_family()
3. Verify all option builders compile and don't panic
4. Verify get_column_family_descriptors returns exactly 12 descriptors
5. Run all tests and confirm 100% pass rate
6. Check for clippy warnings (must be 0)
7. Identify any discrepancies with specification
```

If Sherlock identifies any issues, FIX THEM before marking task complete.

---

*Task ID: TASK-M02-015*
*Module: 02 - Core Infrastructure*
*Layer: Logic*
*Last Updated: 2025-12-31*
