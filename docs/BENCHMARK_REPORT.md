# Context Graph MCP Benchmark Report

## TRUE MCP Benchmark: inject_context + search_graph

**Generated:** 2026-01-20T23:11:48.709819806+00:00
**Winner:** E1 Baseline (-4.5% average improvement)

---

## Executive Summary

This benchmark uses the **actual MCP tools** to compare retrieval approaches:

1. **E1 Baseline**: Single-embedder cosine similarity (traditional RAG)
2. **MCP Multi-Space**: Full search_graph with weighted 13-embedder similarity

### Key Differences from Previous Benchmark

- **Previous**: Bypassed MCP, computed similarity directly
- **Current**: Actually calls inject_context and search_graph MCP tools
- **Corpus**: Semantically overlapping topics (ML/Stats, Crypto/Security, etc.)

---

## Benchmark Configuration

| Parameter | Value |
|-----------|-------|
| Corpus Size | 100 documents |
| Topics | 10 (with semantic overlap) |
| Queries | 10 |
| Injection Time | 15.6s |
| Search Time | 2.7s |
| Avg Embedding | 156ms/doc |

---

## Topic Overlap Design

The corpus deliberately includes semantically similar topics to challenge single-embedder retrieval:

| Topic Pair | Why Challenging |
|------------|-----------------|
| ML ↔ Statistics | Shared vocabulary (optimization, variance, models) |
| Crypto ↔ Security | Overlapping concepts (encryption, authentication) |
| Algorithms ↔ ML | Similar techniques (optimization, gradient descent) |
| OS ↔ Distributed | Shared concerns (scheduling, concurrency) |

---

## Retrieval Results

| Metric | E1 Baseline | MCP Multi-Space | Improvement |
|--------|-------------|-----------------|-------------|
| **MRR** | 0.883 | 0.775 | -12.3% |
| **Precision@5** | 0.680 | 0.640 | -5.9% |
| **Precision@10** | 0.520 | 0.520 | +0.0% |
| **Recall@10** | 0.578 | 0.578 | +0.0% |

---

## Analysis

### Why MCP Multi-Space Loses

In this specific corpus and query set, E1 semantic embedding alone was sufficient to distinguish between topics. This may indicate the topics aren't overlapping enough to challenge single-embedder retrieval.

---

## Technical Details

### MCP inject_context
- Embeds content with all 13 embedders
- Stores TeleologicalFingerprint in RocksDB
- Computes UTL metrics (entropy, coherence, surprise)

### MCP search_graph
- Embeds query with all 13 embedders
- Searches using weighted multi-space similarity
- Returns results ranked by combined similarity score

### E1 Baseline
- Uses only e1_semantic (1024D) embedding
- Pure cosine similarity ranking
- No additional embedder signals

---

*Report generated by Context Graph TRUE MCP Benchmark*
